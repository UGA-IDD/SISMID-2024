[
  {
    "objectID": "modules/Module13-Iteration.html#learning-goals",
    "href": "modules/Module13-Iteration.html#learning-goals",
    "title": "Module 13: Iteration in R",
    "section": "Learning goals",
    "text": "Learning goals\n\nReplace repetitive code with a for loop\nUse vectorization to replace unnecessary loops",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#what-is-iteration",
    "href": "modules/Module13-Iteration.html#what-is-iteration",
    "title": "Module 13: Iteration in R",
    "section": "What is iteration?",
    "text": "What is iteration?\n\nWhenever you repeat something, that’s iteration.\nIn R, this means running the same code multiple times in a row.\n\n\ndata(\"penguins\", package = \"palmerpenguins\")\nfor (this_island in levels(penguins$island)) {\n    island_mean &lt;-\n        penguins$bill_depth_mm[penguins$island == this_island] |&gt;\n        mean(na.rm = TRUE) |&gt;\n        round(digits = 2)\n    \n    cat(paste(\"The mean bill depth on\", this_island, \"Island was\", island_mean,\n                            \"mm.\\n\"))\n}\n\nThe mean bill depth on Biscoe Island was 15.87 mm.\nThe mean bill depth on Dream Island was 18.34 mm.\nThe mean bill depth on Torgersen Island was 18.43 mm.",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#parts-of-a-loop",
    "href": "modules/Module13-Iteration.html#parts-of-a-loop",
    "title": "Module 13: Iteration in R",
    "section": "Parts of a loop",
    "text": "Parts of a loop\n\nfor (this_island in levels(penguins$island)) {\n    island_mean &lt;-\n        penguins$bill_depth_mm[penguins$island == this_island] |&gt;\n        mean(na.rm = TRUE) |&gt;\n        round(digits = 2)\n    \n    cat(paste(\"The mean bill depth on\", this_island, \"Island was\", island_mean,\n                            \"mm.\\n\"))\n}\n\nThe header declares how many times we will repeat the same code. The header contains a control variable that changes in each repetition and a sequence of values for the control variable to take.",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#parts-of-a-loop-1",
    "href": "modules/Module13-Iteration.html#parts-of-a-loop-1",
    "title": "Module 13: Iteration in R",
    "section": "Parts of a loop",
    "text": "Parts of a loop\n\nfor (this_island in levels(penguins$island)) {\n    island_mean &lt;-\n        penguins$bill_depth_mm[penguins$island == this_island] |&gt;\n        mean(na.rm = TRUE) |&gt;\n        round(digits = 2)\n    \n    cat(paste(\"The mean bill depth on\", this_island, \"Island was\", island_mean,\n                            \"mm.\\n\"))\n}\n\nThe body of the loop contains code that will be repeated a number of times based on the header instructions. In R, the body has to be surrounded by curly braces.",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#header-parts",
    "href": "modules/Module13-Iteration.html#header-parts",
    "title": "Module 13: Iteration in R",
    "section": "Header parts",
    "text": "Header parts\n\nfor (this_island in levels(penguins$island)) {...}\n\n\nfor: keyword that declares we are doing a for loop.\n(...): parentheses after for declare the control variable and sequence.\nthis_island: the control variable.\nin: keyword that separates the control varibale and sequence.\nlevels(penguins$island): the sequence.\n{}: curly braces will contain the body code.",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#header-parts-1",
    "href": "modules/Module13-Iteration.html#header-parts-1",
    "title": "Module 13: Iteration in R",
    "section": "Header parts",
    "text": "Header parts\n\nfor (this_island in levels(penguins$island)) {...}\n\n\nSince levels(penguins$island) evaluates to c(\"Biscoe\", \"Dream\", \"Torgersen\"), our loop will repeat 3 times.\n\n\n\n\nIteration\nthis_island\n\n\n\n\n1\n“Biscoe”\n\n\n2\n“Dream”\n\n\n3\n“Torgersen”\n\n\n\n\nEverything inside of {...} will be repeated three times.",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#loop-iteration-1",
    "href": "modules/Module13-Iteration.html#loop-iteration-1",
    "title": "Module 13: Iteration in R",
    "section": "Loop iteration 1",
    "text": "Loop iteration 1\n\nisland_mean &lt;-\n    penguins$bill_depth_mm[penguins$island == \"Biscoe\"] |&gt;\n    mean(na.rm = TRUE) |&gt;\n    round(digits = 2)\n\ncat(paste(\"The mean bill depth on\", \"Biscoe\", \"Island was\", island_mean,\n                    \"mm.\\n\"))\n\nThe mean bill depth on Biscoe Island was 15.87 mm.",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#loop-iteration-2",
    "href": "modules/Module13-Iteration.html#loop-iteration-2",
    "title": "Module 13: Iteration in R",
    "section": "Loop iteration 2",
    "text": "Loop iteration 2\n\nisland_mean &lt;-\n    penguins$bill_depth_mm[penguins$island == \"Dream\"] |&gt;\n    mean(na.rm = TRUE) |&gt;\n    round(digits = 2)\n\ncat(paste(\"The mean bill depth on\", \"Dream\", \"Island was\", island_mean,\n                    \"mm.\\n\"))\n\nThe mean bill depth on Dream Island was 18.34 mm.",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#loop-iteration-3",
    "href": "modules/Module13-Iteration.html#loop-iteration-3",
    "title": "Module 13: Iteration in R",
    "section": "Loop iteration 3",
    "text": "Loop iteration 3\n\nisland_mean &lt;-\n    penguins$bill_depth_mm[penguins$island == \"Torgersen\"] |&gt;\n    mean(na.rm = TRUE) |&gt;\n    round(digits = 2)\n\ncat(paste(\"The mean bill depth on\", \"Torgersen\", \"Island was\", island_mean,\n                    \"mm.\\n\"))\n\nThe mean bill depth on Torgersen Island was 18.43 mm.",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#the-loop-structure-automates-this-process-for-us-so-we-dont-have-to-copy-and-paste-our-code",
    "href": "modules/Module13-Iteration.html#the-loop-structure-automates-this-process-for-us-so-we-dont-have-to-copy-and-paste-our-code",
    "title": "Module 13: Iteration in R",
    "section": "The loop structure automates this process for us so we don’t have to copy and paste our code!",
    "text": "The loop structure automates this process for us so we don’t have to copy and paste our code!\n\nfor (this_island in levels(penguins$island)) {\n    island_mean &lt;-\n        penguins$bill_depth_mm[penguins$island == this_island] |&gt;\n        mean(na.rm = TRUE) |&gt;\n        round(digits = 2)\n    \n    cat(paste(\"The mean bill depth on\", this_island, \"Island was\", island_mean,\n                            \"mm.\\n\"))\n}\n\nThe mean bill depth on Biscoe Island was 15.87 mm.\nThe mean bill depth on Dream Island was 18.34 mm.\nThe mean bill depth on Torgersen Island was 18.43 mm.",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#side-note-the-pipe-operator",
    "href": "modules/Module13-Iteration.html#side-note-the-pipe-operator",
    "title": "Module 13: Iteration in R",
    "section": "Side note: the pipe operator |>",
    "text": "Side note: the pipe operator |&gt;\n\nThis operator allows us to chain commands together so the output of the previous statement is passed into the next statement.\nE.g. the code\n\n\nisland_mean &lt;-\n    penguins$bill_depth_mm[penguins$island == \"Torgersen\"] |&gt;\n    mean(na.rm = TRUE) |&gt;\n    round(digits = 2)\n\nwill be transformed by R into\n\nisland_mean &lt;-\n    round(\n        mean(\n            penguins$bill_depth_mm[penguins$island == \"Torgersen\"],\n            na.rm = TRUE\n        ),\n        digits = 2\n    )\n\nbefore it gets run. So using the pipe is a way to avoid deeply nested functions.\nNote that another alernative could be like this:\n\nisland_data &lt;- penguins$bill_depth_mm[penguins$island == \"Torgersen\"]\nisland_mean_raw &lt;- mean(island_data, na.rm = TRUE)\nisland_mean &lt;- round(island_mean_raw, digits = 2)\n\nSo using |&gt; can also help us to avoid a lot of assignments.\n\nWhichever style you prefer is fine! Some people like the pipe, some people like nesting, and some people like intermediate assignments. All three are perfectly fine as long as your code is neat and commented.\nIf you go on to the tidyverse class, you will use a lot of piping – it is a very popular coding style in R these days thanks to the inventors of the tidyverse packages.\nAlso note that you need R version 4.1.0 or better to use |&gt;. If you are on an older version of R, it will not be available.\n\nNow, back to loops!",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#remember-write-dry-code",
    "href": "modules/Module13-Iteration.html#remember-write-dry-code",
    "title": "Module 13: Iteration in R",
    "section": "Remember: write DRY code!",
    "text": "Remember: write DRY code!\n\nDRY = “Don’t Repeat Yourself”\nInstead of copying and pasting, write loops and functions.\nEasier to debug and change in the future!\n\n\n\nOf course, we all copy and paste code sometimes. If you are running on a tight deadline or can’t get a loop or function to work, you might need to. DRY code is good, but working code is best!",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#you-try-it",
    "href": "modules/Module13-Iteration.html#you-try-it",
    "title": "Module 13: Iteration in R",
    "section": "You try it!",
    "text": "You try it!\nWrite a loop that goes from 1 to 10, squares each of the numbers, and prints the squared number.\n\n\nfor (i in 1:10) {\n    cat(i ^ 2, \"\\n\")\n}\n\n1 \n4 \n9 \n16 \n25 \n36 \n49 \n64 \n81 \n100",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#wait-did-we-need-to-do-that",
    "href": "modules/Module13-Iteration.html#wait-did-we-need-to-do-that",
    "title": "Module 13: Iteration in R",
    "section": "Wait, did we need to do that?",
    "text": "Wait, did we need to do that?\n\nWell, yes, because you need to practice loops!\nBut technically no, because we can use vectorization.\nAlmost all basic operations in R are vectorized: they work on a vector of arguments all at the same time.",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#wait-did-we-need-to-do-that-1",
    "href": "modules/Module13-Iteration.html#wait-did-we-need-to-do-that-1",
    "title": "Module 13: Iteration in R",
    "section": "Wait, did we need to do that?",
    "text": "Wait, did we need to do that?\n\nWell, yes, because you need to practice loops!\nBut technically no, because we can use vectorization.\nAlmost all basic operations in R are vectorized: they work on a vector of arguments all at the same time.\n\n\n# No loop needed!\n(1:10)^2\n\n [1]   1   4   9  16  25  36  49  64  81 100\n\n\n\n\n# Get the first 10 odd numbers, a common CS 101 loop problem on exams\n(1:20)[which((1:20 %% 2) == 1)]\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\n\n\n\nSo you should really try vectorization first, then use loops only when you can’t use vectorization.",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#loop-walkthrough",
    "href": "modules/Module13-Iteration.html#loop-walkthrough",
    "title": "Module 13: Iteration in R",
    "section": "Loop walkthrough",
    "text": "Loop walkthrough\n\nLet’s walk through a complex but useful example where we can’t use vectorization.\nLoad the cleaned measles dataset, and subset it so you only have MCV1 records.\n\n\n\nmeas &lt;- readRDS(here::here(\"data\", \"measles_final.Rds\")) |&gt;\n    subset(vaccine_antigen == \"MCV1\")\nstr(meas)\n\n'data.frame':   7972 obs. of  7 variables:\n $ iso3c           : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ time            : int  1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 ...\n $ country         : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Cases           : int  2792 5166 2900 640 353 2012 1511 638 1154 492 ...\n $ vaccine_antigen : chr  \"MCV1\" \"MCV1\" \"MCV1\" \"MCV1\" ...\n $ vaccine_coverage: int  11 NA 8 9 14 14 14 31 34 22 ...\n $ total_pop       : chr  \"12486631\" \"11155195\" \"10088289\" \"9951449\" ...",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#loop-walkthrough-1",
    "href": "modules/Module13-Iteration.html#loop-walkthrough-1",
    "title": "Module 13: Iteration in R",
    "section": "Loop walkthrough",
    "text": "Loop walkthrough\n\nFirst, make an empty list. This is where we’ll store our results. Make it the same length as the number of countries in the dataset.\n\n\n\nres &lt;- vector(mode = \"list\", length = length(unique(meas$country)))\n\n\nThis is called preallocation and it can make your loops much faster.",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#loop-walkthrough-2",
    "href": "modules/Module13-Iteration.html#loop-walkthrough-2",
    "title": "Module 13: Iteration in R",
    "section": "Loop walkthrough",
    "text": "Loop walkthrough\n\nLoop through every country in the dataset, and get the median, first and third quartiles, and range for each country. Store those summary statistics in a data frame.\nWhat should the header look like?\n\n\n\ncountries &lt;- unique(meas$country)\nfor (i in 1:length(countries)) {...}\n\n\n\n\nNote that we use the index as the control variable. When you need to do complex operations inside a loop, this is easier than the for-each construction we used earlier.",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#loop-walkthrough-3",
    "href": "modules/Module13-Iteration.html#loop-walkthrough-3",
    "title": "Module 13: Iteration in R",
    "section": "Loop walkthrough",
    "text": "Loop walkthrough\n\nNow write out the body of the code. First we need to subset the data, to get only the data for the current country.\n\n\n\nfor (i in 1:length(countries)) {\n    # Get the data for the current country only\n    country_data &lt;- subset(meas, country == countries[i])\n}\n\n\n\n\nNext we need to get the summary of the cases for that country.\n\n\n\n\nfor (i in 1:length(countries)) {\n    # Get the data for the current country only\n    country_data &lt;- subset(meas, country == countries[i])\n    \n    # Get the summary statistics for this country\n    country_cases &lt;- country_data$Cases\n    country_quart &lt;- quantile(\n        country_cases, na.rm = TRUE, probs = c(0.25, 0.5, 0.75)\n    )\n    country_range &lt;- range(country_cases, na.rm = TRUE)\n}\n\n\n\n\nNext we save the summary statistics into a data frame.\n\n\nfor (i in 1:length(countries)) {\n    # Get the data for the current country only\n    country_data &lt;- subset(meas, country == countries[i])\n    \n    # Get the summary statistics for this country\n    country_cases &lt;- country_data$Cases\n    country_quart &lt;- quantile(\n        country_cases, na.rm = TRUE, probs = c(0.25, 0.5, 0.75)\n    )\n    country_range &lt;- range(country_cases, na.rm = TRUE)\n    \n    # Save the summary statistics into a data frame\n    country_summary &lt;- data.frame(\n        country = countries[[i]],\n        min = country_range[[1]],\n        Q1 = country_quart[[1]],\n        median = country_quart[[2]],\n        Q3 = country_quart[[3]],\n        max = country_range[[2]]\n    )\n}\n\n\n\n\nAnd finally, we save the data frame as the next element in our storage list.\n\n\nfor (i in 1:length(countries)) {\n    # Get the data for the current country only\n    country_data &lt;- subset(meas, country == countries[i])\n    \n    # Get the summary statistics for this country\n    country_cases &lt;- country_data$Cases\n    country_quart &lt;- quantile(\n        country_cases, na.rm = TRUE, probs = c(0.25, 0.5, 0.75)\n    )\n    country_range &lt;- range(country_cases, na.rm = TRUE)\n    \n    # Save the summary statistics into a data frame\n    country_summary &lt;- data.frame(\n        country = countries[[i]],\n        min = country_range[[1]],\n        Q1 = country_quart[[1]],\n        median = country_quart[[2]],\n        Q3 = country_quart[[3]],\n        max = country_range[[2]]\n    )\n    \n    # Save the results to our container\n    res[[i]] &lt;- country_summary\n}\n\nWarning in min(x): no non-missing arguments to min; returning Inf\n\n\nWarning in max(x): no non-missing arguments to max; returning -Inf\n\n\nWarning in min(x): no non-missing arguments to min; returning Inf\n\n\nWarning in max(x): no non-missing arguments to max; returning -Inf\n\n\nWarning in min(x): no non-missing arguments to min; returning Inf\n\n\nWarning in max(x): no non-missing arguments to max; returning -Inf\n\n\n\n\n\nLet’s take a look at the results.\n\n\nhead(res)\n\n[[1]]\n      country min   Q1 median   Q3   max\n1 Afghanistan 353 1154   2205 5166 31107\n\n[[2]]\n  country min  Q1 median    Q3   max\n1  Angola  29 700   3271 14474 30067\n\n[[3]]\n  country min Q1 median Q3    max\n1 Albania   0  1     12 29 136034\n\n[[4]]\n  country min Q1 median Q3 max\n1 Andorra   0  0      1  2   5\n\n[[5]]\n               country min    Q1 median   Q3  max\n1 United Arab Emirates  22 89.75    320 1128 2913\n\n[[6]]\n    country min Q1 median     Q3   max\n1 Argentina   0  0     17 4591.5 42093\n\n\n\nHow do we deal with this to get it into a nice form?\n\n\n\n\nWe can use a vectorization trick: the function do.call() seems like ancient computer science magic. And it is. But it will actually help us a lot.\n\n\nres_df &lt;- do.call(rbind, res)\nhead(res_df)\n\n\n\n\ncountry\nmin\nQ1\nmedian\nQ3\nmax\n\n\n\n\nAfghanistan\n353\n1154.00\n2205\n5166.0\n31107\n\n\nAngola\n29\n700.00\n3271\n14474.0\n30067\n\n\nAlbania\n0\n1.00\n12\n29.0\n136034\n\n\nAndorra\n0\n0.00\n1\n2.0\n5\n\n\nUnited Arab Emirates\n22\n89.75\n320\n1128.0\n2913\n\n\nArgentina\n0\n0.00\n17\n4591.5\n42093\n\n\n\n\n\n\nIt combined our data frames together! Let’s take a look at the rbind and do.call() help packages to see what happened.\n\n\n\n\n?rbind\n\nCombine R Objects by Rows or Columns\n\nDescription:\n\n     Take a sequence of vector, matrix or data-frame arguments and\n     combine by _c_olumns or _r_ows, respectively.  These are generic\n     functions with methods for other R classes.\n\nUsage:\n\n     cbind(..., deparse.level = 1)\n     rbind(..., deparse.level = 1)\n     ## S3 method for class 'data.frame'\n     rbind(..., deparse.level = 1, make.row.names = TRUE,\n           stringsAsFactors = FALSE, factor.exclude = TRUE)\n     \nArguments:\n\n     ...: (generalized) vectors or matrices.  These can be given as\n          named arguments.  Other R objects may be coerced as\n          appropriate, or S4 methods may be used: see sections\n          'Details' and 'Value'.  (For the '\"data.frame\"' method of\n          'cbind' these can be further arguments to 'data.frame' such\n          as 'stringsAsFactors'.)\n\ndeparse.level: integer controlling the construction of labels in the\n          case of non-matrix-like arguments (for the default method):\n          'deparse.level = 0' constructs no labels;\n          the default 'deparse.level = 1' typically and 'deparse.level\n          = 2' always construct labels from the argument names, see the\n          'Value' section below.\n\nmake.row.names: (only for data frame method:) logical indicating if\n          unique and valid 'row.names' should be constructed from the\n          arguments.\n\nstringsAsFactors: logical, passed to 'as.data.frame'; only has an\n          effect when the '...' arguments contain a (non-'data.frame')\n          'character'.\n\nfactor.exclude: if the data frames contain factors, the default 'TRUE'\n          ensures that 'NA' levels of factors are kept, see PR#17562\n          and the 'Data frame methods'.  In R versions up to 3.6.x,\n          'factor.exclude = NA' has been implicitly hardcoded (R &lt;=\n          3.6.0) or the default (R = 3.6.x, x &gt;= 1).\n\nDetails:\n\n     The functions 'cbind' and 'rbind' are S3 generic, with methods for\n     data frames.  The data frame method will be used if at least one\n     argument is a data frame and the rest are vectors or matrices.\n     There can be other methods; in particular, there is one for time\n     series objects.  See the section on 'Dispatch' for how the method\n     to be used is selected.  If some of the arguments are of an S4\n     class, i.e., 'isS4(.)' is true, S4 methods are sought also, and\n     the hidden 'cbind' / 'rbind' functions from package 'methods'\n     maybe called, which in turn build on 'cbind2' or 'rbind2',\n     respectively.  In that case, 'deparse.level' is obeyed, similarly\n     to the default method.\n\n     In the default method, all the vectors/matrices must be atomic\n     (see 'vector') or lists.  Expressions are not allowed.  Language\n     objects (such as formulae and calls) and pairlists will be coerced\n     to lists: other objects (such as names and external pointers) will\n     be included as elements in a list result.  Any classes the inputs\n     might have are discarded (in particular, factors are replaced by\n     their internal codes).\n\n     If there are several matrix arguments, they must all have the same\n     number of columns (or rows) and this will be the number of columns\n     (or rows) of the result.  If all the arguments are vectors, the\n     number of columns (rows) in the result is equal to the length of\n     the longest vector.  Values in shorter arguments are recycled to\n     achieve this length (with a 'warning' if they are recycled only\n     _fractionally_).\n\n     When the arguments consist of a mix of matrices and vectors the\n     number of columns (rows) of the result is determined by the number\n     of columns (rows) of the matrix arguments.  Any vectors have their\n     values recycled or subsetted to achieve this length.\n\n     For 'cbind' ('rbind'), vectors of zero length (including 'NULL')\n     are ignored unless the result would have zero rows (columns), for\n     S compatibility.  (Zero-extent matrices do not occur in S3 and are\n     not ignored in R.)\n\n     Matrices are restricted to less than 2^31 rows and columns even on\n     64-bit systems.  So input vectors have the same length\n     restriction: as from R 3.2.0 input matrices with more elements\n     (but meeting the row and column restrictions) are allowed.\n\nValue:\n\n     For the default method, a matrix combining the '...' arguments\n     column-wise or row-wise.  (Exception: if there are no inputs or\n     all the inputs are 'NULL', the value is 'NULL'.)\n\n     The type of a matrix result determined from the highest type of\n     any of the inputs in the hierarchy raw &lt; logical &lt; integer &lt;\n     double &lt; complex &lt; character &lt; list .\n\n     For 'cbind' ('rbind') the column (row) names are taken from the\n     'colnames' ('rownames') of the arguments if these are matrix-like.\n     Otherwise from the names of the arguments or where those are not\n     supplied and 'deparse.level &gt; 0', by deparsing the expressions\n     given, for 'deparse.level = 1' only if that gives a sensible name\n     (a 'symbol', see 'is.symbol').\n\n     For 'cbind' row names are taken from the first argument with\n     appropriate names: rownames for a matrix, or names for a vector of\n     length the number of rows of the result.\n\n     For 'rbind' column names are taken from the first argument with\n     appropriate names: colnames for a matrix, or names for a vector of\n     length the number of columns of the result.\n\nData frame methods:\n\n     The 'cbind' data frame method is just a wrapper for\n     'data.frame(..., check.names = FALSE)'.  This means that it will\n     split matrix columns in data frame arguments, and convert\n     character columns to factors unless 'stringsAsFactors = FALSE' is\n     specified.\n\n     The 'rbind' data frame method first drops all zero-column and\n     zero-row arguments.  (If that leaves none, it returns the first\n     argument with columns otherwise a zero-column zero-row data\n     frame.)  It then takes the classes of the columns from the first\n     data frame, and matches columns by name (rather than by position).\n     Factors have their levels expanded as necessary (in the order of\n     the levels of the level sets of the factors encountered) and the\n     result is an ordered factor if and only if all the components were\n     ordered factors.  Old-style categories (integer vectors with\n     levels) are promoted to factors.\n\n     Note that for result column 'j', 'factor(., exclude = X(j))' is\n     applied, where\n\n       X(j) := if(isTRUE(factor.exclude)) {\n                  if(!NA.lev[j]) NA # else NULL\n               } else factor.exclude\n     \n     where 'NA.lev[j]' is true iff any contributing data frame has had\n     a 'factor' in column 'j' with an explicit 'NA' level.\n\nDispatch:\n\n     The method dispatching is _not_ done via 'UseMethod()', but by\n     C-internal dispatching.  Therefore there is no need for, e.g.,\n     'rbind.default'.\n\n     The dispatch algorithm is described in the source file\n     ('.../src/main/bind.c') as\n\n       1. For each argument we get the list of possible class\n          memberships from the class attribute.\n\n       2. We inspect each class in turn to see if there is an\n          applicable method.\n\n       3. If we find a method, we use it.  Otherwise, if there was an\n          S4 object among the arguments, we try S4 dispatch; otherwise,\n          we use the default code.\n\n     If you want to combine other objects with data frames, it may be\n     necessary to coerce them to data frames first.  (Note that this\n     algorithm can result in calling the data frame method if all the\n     arguments are either data frames or vectors, and this will result\n     in the coercion of character vectors to factors.)\n\nReferences:\n\n     Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S\n     Language_.  Wadsworth & Brooks/Cole.\n\nSee Also:\n\n     'c' to combine vectors (and lists) as vectors, 'data.frame' to\n     combine vectors and matrices as a data frame.\n\nExamples:\n\n     m &lt;- cbind(1, 1:7) # the '1' (= shorter vector) is recycled\n     m\n     m &lt;- cbind(m, 8:14)[, c(1, 3, 2)] # insert a column\n     m\n     cbind(1:7, diag(3)) # vector is subset -&gt; warning\n     \n     cbind(0, rbind(1, 1:3))\n     cbind(I = 0, X = rbind(a = 1, b = 1:3))  # use some names\n     xx &lt;- data.frame(I = rep(0,2))\n     cbind(xx, X = rbind(a = 1, b = 1:3))   # named differently\n     \n     cbind(0, matrix(1, nrow = 0, ncol = 4)) #&gt; Warning (making sense)\n     dim(cbind(0, matrix(1, nrow = 2, ncol = 0))) #-&gt; 2 x 1\n     \n     ## deparse.level\n     dd &lt;- 10\n     rbind(1:4, c = 2, \"a++\" = 10, dd, deparse.level = 0) # middle 2 rownames\n     rbind(1:4, c = 2, \"a++\" = 10, dd, deparse.level = 1) # 3 rownames (default)\n     rbind(1:4, c = 2, \"a++\" = 10, dd, deparse.level = 2) # 4 rownames\n     \n     ## cheap row names:\n     b0 &lt;- gl(3,4, labels=letters[1:3])\n     bf &lt;- setNames(b0, paste0(\"o\", seq_along(b0)))\n     df  &lt;- data.frame(a = 1, B = b0, f = gl(4,3))\n     df. &lt;- data.frame(a = 1, B = bf, f = gl(4,3))\n     new &lt;- data.frame(a = 8, B =\"B\", f = \"1\")\n     (df1  &lt;- rbind(df , new))\n     (df.1 &lt;- rbind(df., new))\n     stopifnot(identical(df1, rbind(df,  new, make.row.names=FALSE)),\n               identical(df1, rbind(df., new, make.row.names=FALSE)))\n\n\n\n\n\n?do.call\n\nExecute a Function Call\n\nDescription:\n\n     'do.call' constructs and executes a function call from a name or a\n     function and a list of arguments to be passed to it.\n\nUsage:\n\n     do.call(what, args, quote = FALSE, envir = parent.frame())\n     \nArguments:\n\n    what: either a function or a non-empty character string naming the\n          function to be called.\n\n    args: a _list_ of arguments to the function call.  The 'names'\n          attribute of 'args' gives the argument names.\n\n   quote: a logical value indicating whether to quote the arguments.\n\n   envir: an environment within which to evaluate the call.  This will\n          be most useful if 'what' is a character string and the\n          arguments are symbols or quoted expressions.\n\nDetails:\n\n     If 'quote' is 'FALSE', the default, then the arguments are\n     evaluated (in the calling environment, not in 'envir').  If\n     'quote' is 'TRUE' then each argument is quoted (see 'quote') so\n     that the effect of argument evaluation is to remove the quotes -\n     leaving the original arguments unevaluated when the call is\n     constructed.\n\n     The behavior of some functions, such as 'substitute', will not be\n     the same for functions evaluated using 'do.call' as if they were\n     evaluated from the interpreter.  The precise semantics are\n     currently undefined and subject to change.\n\nValue:\n\n     The result of the (evaluated) function call.\n\nWarning:\n\n     This should not be used to attempt to evade restrictions on the\n     use of '.Internal' and other non-API calls.\n\nReferences:\n\n     Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S\n     Language_.  Wadsworth & Brooks/Cole.\n\nSee Also:\n\n     'call' which creates an unevaluated call.\n\nExamples:\n\n     do.call(\"complex\", list(imaginary = 1:3))\n     \n     ## if we already have a list (e.g., a data frame)\n     ## we need c() to add further arguments\n     tmp &lt;- expand.grid(letters[1:2], 1:3, c(\"+\", \"-\"))\n     do.call(\"paste\", c(tmp, sep = \"\"))\n     \n     do.call(paste, list(as.name(\"A\"), as.name(\"B\")), quote = TRUE)\n     \n     ## examples of where objects will be found.\n     A &lt;- 2\n     f &lt;- function(x) print(x^2)\n     env &lt;- new.env()\n     assign(\"A\", 10, envir = env)\n     assign(\"f\", f, envir = env)\n     f &lt;- function(x) print(x)\n     f(A)                                      # 2\n     do.call(\"f\", list(A))                     # 2\n     do.call(\"f\", list(A), envir = env)        # 4\n     do.call( f,  list(A), envir = env)        # 2\n     do.call(\"f\", list(quote(A)), envir = env) # 100\n     do.call( f,  list(quote(A)), envir = env) # 10\n     do.call(\"f\", list(as.name(\"A\")), envir = env) # 100\n     \n     eval(call(\"f\", A))                      # 2\n     eval(call(\"f\", quote(A)))               # 2\n     eval(call(\"f\", A), envir = env)         # 4\n     eval(call(\"f\", quote(A)), envir = env)  # 100\n\n\n\n\n\nOK, so basically what happened is that\n\n\ndo.call(rbind, list)\n\n\nGets transformed into\n\n\nrbind(list[[1]], list[[2]], list[[3]], ..., list[[length(list)]])\n\n\nThat’s vectorization magic!",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#you-try-it-if-we-have-time",
    "href": "modules/Module13-Iteration.html#you-try-it-if-we-have-time",
    "title": "Module 13: Iteration in R",
    "section": "You try it! (if we have time)",
    "text": "You try it! (if we have time)\n\nUse the code you wrote before the get the incidence per 1000 people on the entire measles data set (add a column for incidence to the full data).\nUse the code plot(NULL, NULL, ...) to make a blank plot. You will need to set the xlim and ylim arguments to sensible values, and specify the axis titles as “Year” and “Incidence per 1000 people”.\nUsing a for loop and the lines() function, make a plot that shows all of the incidence curves over time, overlapping on the plot.\nHINT: use col = adjustcolor(black, alpha.f = 0.25) to make the curves partially transparent, so you can see the overlap.\nBONUS PROBLEM: using the function cumsum(), make a plot of the cumulative cases (not standardized) over time for all of the countries. (Dealing with the NA’s here is tricky!!)",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#main-problem-solution",
    "href": "modules/Module13-Iteration.html#main-problem-solution",
    "title": "Module 13: Iteration in R",
    "section": "Main problem solution",
    "text": "Main problem solution\n\nmeas$cases_per_thousand &lt;- meas$Cases / as.numeric(meas$total_pop) * 1000\ncountries &lt;- unique(meas$country)\n\nplot(\n    NULL, NULL,\n    xlim = c(1980, 2022),\n    ylim = c(0, 50),\n    xlab = \"Year\",\n    ylab = \"Incidence per 1000 people\"\n)\n\nfor (i in 1:length(countries)) {\n    country_data &lt;- subset(meas, country == countries[[i]])\n    lines(\n        x = country_data$time,\n        y = country_data$cases_per_thousand,\n        col = adjustcolor(\"black\", alpha.f = 0.25)\n    )\n}",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#main-problem-solution-1",
    "href": "modules/Module13-Iteration.html#main-problem-solution-1",
    "title": "Module 13: Iteration in R",
    "section": "Main problem solution",
    "text": "Main problem solution",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#bonus-problem-solution",
    "href": "modules/Module13-Iteration.html#bonus-problem-solution",
    "title": "Module 13: Iteration in R",
    "section": "Bonus problem solution",
    "text": "Bonus problem solution\n\n# First calculate the cumulative cases, treating NA as zeroes\ncumulative_cases &lt;- ave(\n    x = ifelse(is.na(meas$Cases), 0, meas$Cases),\n    meas$country,\n    FUN = cumsum\n)\n\n# Now put the NAs back where they should be\nmeas$cumulative_cases &lt;- cumulative_cases + (meas$Cases * 0)\n\nplot(\n    NULL, NULL,\n    xlim = c(1980, 2022),\n    ylim = c(1, 6.2e6),\n    xlab = \"Year\",\n    ylab = paste0(\"Cumulative cases since\", min(meas$time))\n)\n\nfor (i in 1:length(countries)) {\n    country_data &lt;- subset(meas, country == countries[[i]])\n    lines(\n        x = country_data$time,\n        y = country_data$cumulative_cases,\n        col = adjustcolor(\"black\", alpha.f = 0.25)\n    )\n}\n\ntext(\n    x = 2020,\n    y = 6e6,\n    labels = \"China →\"\n)",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#bonus-problem-solution-1",
    "href": "modules/Module13-Iteration.html#bonus-problem-solution-1",
    "title": "Module 13: Iteration in R",
    "section": "Bonus problem solution",
    "text": "Bonus problem solution",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module13-Iteration.html#more-practice-on-your-own",
    "href": "modules/Module13-Iteration.html#more-practice-on-your-own",
    "title": "Module 13: Iteration in R",
    "section": "More practice on your own",
    "text": "More practice on your own\n\nMerge the countries-regions.csv data with the measles_final.Rds data. Reshape the measles data so that MCV1 and MCV2 vaccine coverage are two separate columns. Then use a loop to fit a poisson regression model for each continent where Cases is the outcome, and MCV1 coverage and MCV2 coverage are the predictors. Discuss your findings, and try adding an interation term.\nAssess the impact of age_months as a confounder in the Diphtheria serology data. First, write code to transform age_months into age ranges for each year. Then, using a loop, calculate the crude odds ratio for the effect of vaccination on infection for each of the age ranges. How does the odds ratio change as age increases? Can you formalize this analysis by fitting a logistic regression model with age_months and vaccination as predictors?",
    "crumbs": [
      "Day 3",
      "Module 13: Iteration in R"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#learning-objectives",
    "href": "modules/Module07-VarCreationClassesSummaries.html#learning-objectives",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter module 7, you should be able to…\n\nCreate new variables\nCharacterize variable classes\nManipulate the classes of variables\nConduct 1 variable data summaries",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#import-data-for-this-module",
    "href": "modules/Module07-VarCreationClassesSummaries.html#import-data-for-this-module",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Import data for this module",
    "text": "Import data for this module\nLet’s first read in the data from the previous module and look at it briefly with a new function head(). head() allows us to look at the first n observations.\n\n\ndf &lt;- read.csv(file = \"data/serodata.csv\") #relative path\nhead(x=df, n=3)\n\n  observation_id IgG_concentration age gender     slum\n1           5772         0.3176895   2 Female Non slum\n2           8095         3.4368231   4 Female Non slum\n3           9784         0.3000000   4   Male Non slum",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#adding-new-columns-with-operator",
    "href": "modules/Module07-VarCreationClassesSummaries.html#adding-new-columns-with-operator",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Adding new columns with $ operator",
    "text": "Adding new columns with $ operator\nYou can add a new column, called log_IgG to df, using the $ operator:\n\ndf$log_IgG &lt;- log(df$IgG_concentration)\nhead(df,3)\n\n  observation_id IgG_concentration age gender     slum   log_IgG\n1           5772         0.3176895   2 Female Non slum -1.146681\n2           8095         3.4368231   4 Female Non slum  1.234548\n3           9784         0.3000000   4   Male Non slum -1.203973\n\n\nNote, my use of the underscore in the variable name rather than a space. This is good coding practice and make calling variables much less prone to error.",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#adding-new-columns-with-transform",
    "href": "modules/Module07-VarCreationClassesSummaries.html#adding-new-columns-with-transform",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Adding new columns with transform()",
    "text": "Adding new columns with transform()\nWe can also add a new column using the transform() function:\n\n?transform\n\n\n\nRegistered S3 method overwritten by 'printr':\n  method                from     \n  knit_print.data.frame rmarkdown\n\n\nTransform an Object, for Example a Data Frame\n\nDescription:\n\n     'transform' is a generic function, which-at least currently-only\n     does anything useful with data frames.  'transform.default'\n     converts its first argument to a data frame if possible and calls\n     'transform.data.frame'.\n\nUsage:\n\n     transform(`_data`, ...)\n     \nArguments:\n\n   _data: The object to be transformed\n\n     ...: Further arguments of the form 'tag=value'\n\nDetails:\n\n     The '...' arguments to 'transform.data.frame' are tagged vector\n     expressions, which are evaluated in the data frame '_data'.  The\n     tags are matched against 'names(_data)', and for those that match,\n     the value replace the corresponding variable in '_data', and the\n     others are appended to '_data'.\n\nValue:\n\n     The modified value of '_data'.\n\nWarning:\n\n     This is a convenience function intended for use interactively.\n     For programming it is better to use the standard subsetting\n     arithmetic functions, and in particular the non-standard\n     evaluation of argument 'transform' can have unanticipated\n     consequences.\n\nNote:\n\n     If some of the values are not vectors of the appropriate length,\n     you deserve whatever you get!\n\nAuthor(s):\n\n     Peter Dalgaard\n\nSee Also:\n\n     'within' for a more flexible approach, 'subset', 'list',\n     'data.frame'\n\nExamples:\n\n     transform(airquality, Ozone = -Ozone)\n     transform(airquality, new = -Ozone, Temp = (Temp-32)/1.8)\n     \n     attach(airquality)\n     transform(Ozone, logOzone = log(Ozone)) # marginally interesting ...\n     detach(airquality)",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#adding-new-columns-with-transform-1",
    "href": "modules/Module07-VarCreationClassesSummaries.html#adding-new-columns-with-transform-1",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Adding new columns with transform()",
    "text": "Adding new columns with transform()\nFor example, adding a binary column for seropositivity called seropos:\n\ndf &lt;- transform(df, seropos = IgG_concentration &gt;= 10)\nhead(df)\n\n\n\n\n\n\n\n\n\n\n\n\n\nobservation_id\nIgG_concentration\nage\ngender\nslum\nlog_IgG\nseropos\n\n\n\n\n5772\n0.3176895\n2\nFemale\nNon slum\n-1.1466807\nFALSE\n\n\n8095\n3.4368231\n4\nFemale\nNon slum\n1.2345475\nFALSE\n\n\n9784\n0.3000000\n4\nMale\nNon slum\n-1.2039728\nFALSE\n\n\n9338\n143.2363014\n4\nMale\nNon slum\n4.9644957\nTRUE\n\n\n6369\n0.4476534\n1\nMale\nNon slum\n-0.8037359\nFALSE\n\n\n6885\n0.0252708\n4\nMale\nNon slum\n-3.6781074\nFALSE",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#creating-conditional-variables",
    "href": "modules/Module07-VarCreationClassesSummaries.html#creating-conditional-variables",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Creating conditional variables",
    "text": "Creating conditional variables\nOne frequently used tool is creating variables with conditions. A general function for creating new variables based on existing variables is the Base R ifelse() function, which “returns a value depending on whether the element of test is TRUE or FALSE or NA.\n\n?ifelse\n\nConditional Element Selection\nDescription:\n 'ifelse' returns a value with the same shape as 'test' which is\n filled with elements selected from either 'yes' or 'no' depending\n on whether the element of 'test' is 'TRUE' or 'FALSE'.\nUsage:\n ifelse(test, yes, no)\n \nArguments:\ntest: an object which can be coerced to logical mode.\n\n yes: return values for true elements of 'test'.\n\n  no: return values for false elements of 'test'.\nDetails:\n If 'yes' or 'no' are too short, their elements are recycled.\n 'yes' will be evaluated if and only if any element of 'test' is\n true, and analogously for 'no'.\n\n Missing values in 'test' give missing values in the result.\nValue:\n A vector of the same length and attributes (including dimensions\n and '\"class\"') as 'test' and data values from the values of 'yes'\n or 'no'.  The mode of the answer will be coerced from logical to\n accommodate first any values taken from 'yes' and then any values\n taken from 'no'.\nWarning:\n The mode of the result may depend on the value of 'test' (see the\n examples), and the class attribute (see 'oldClass') of the result\n is taken from 'test' and may be inappropriate for the values\n selected from 'yes' and 'no'.\n\n Sometimes it is better to use a construction such as\n\n   (tmp &lt;- yes; tmp[!test] &lt;- no[!test]; tmp)\n \n , possibly extended to handle missing values in 'test'.\n\n Further note that 'if(test) yes else no' is much more efficient\n and often much preferable to 'ifelse(test, yes, no)' whenever\n 'test' is a simple true/false result, i.e., when 'length(test) ==\n 1'.\n\n The 'srcref' attribute of functions is handled specially: if\n 'test' is a simple true result and 'yes' evaluates to a function\n with 'srcref' attribute, 'ifelse' returns 'yes' including its\n attribute (the same applies to a false 'test' and 'no' argument).\n This functionality is only for backwards compatibility, the form\n 'if(test) yes else no' should be used whenever 'yes' and 'no' are\n functions.\nReferences:\n Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S\n Language_.  Wadsworth & Brooks/Cole.\nSee Also:\n 'if'.\nExamples:\n x &lt;- c(6:-4)\n sqrt(x)  #- gives warning\n sqrt(ifelse(x &gt;= 0, x, NA))  # no warning\n \n ## Note: the following also gives the warning !\n ifelse(x &gt;= 0, sqrt(x), NA)\n \n \n ## ifelse() strips attributes\n ## This is important when working with Dates and factors\n x &lt;- seq(as.Date(\"2000-02-29\"), as.Date(\"2004-10-04\"), by = \"1 month\")\n ## has many \"yyyy-mm-29\", but a few \"yyyy-03-01\" in the non-leap years\n y &lt;- ifelse(as.POSIXlt(x)$mday == 29, x, NA)\n head(y) # not what you expected ... ==&gt; need restore the class attribute:\n class(y) &lt;- class(x)\n y\n ## This is a (not atypical) case where it is better *not* to use ifelse(),\n ## but rather the more efficient and still clear:\n y2 &lt;- x\n y2[as.POSIXlt(x)$mday != 29] &lt;- NA\n ## which gives the same as ifelse()+class() hack:\n stopifnot(identical(y2, y))\n \n \n ## example of different return modes (and 'test' alone determining length):\n yes &lt;- 1:3\n no  &lt;- pi^(1:4)\n utils::str( ifelse(NA,    yes, no) ) # logical, length 1\n utils::str( ifelse(TRUE,  yes, no) ) # integer, length 1\n utils::str( ifelse(FALSE, yes, no) ) # double,  length 1",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#ifelse-example",
    "href": "modules/Module07-VarCreationClassesSummaries.html#ifelse-example",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "ifelse example",
    "text": "ifelse example\nReminder of the first three arguments in the ifelse() function are ifelse(test, yes, no).\n\ndf$age_group &lt;- ifelse(df$age &lt;= 5, \"young\", \"old\")\nhead(df)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nobservation_id\nIgG_concentration\nage\ngender\nslum\nlog_IgG\nseropos\nage_group\n\n\n\n\n5772\n0.3176895\n2\nFemale\nNon slum\n-1.1466807\nFALSE\nyoung\n\n\n8095\n3.4368231\n4\nFemale\nNon slum\n1.2345475\nFALSE\nyoung\n\n\n9784\n0.3000000\n4\nMale\nNon slum\n-1.2039728\nFALSE\nyoung\n\n\n9338\n143.2363014\n4\nMale\nNon slum\n4.9644957\nTRUE\nyoung\n\n\n6369\n0.4476534\n1\nMale\nNon slum\n-0.8037359\nFALSE\nyoung\n\n\n6885\n0.0252708\n4\nMale\nNon slum\n-3.6781074\nFALSE\nyoung",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#ifelse-example-1",
    "href": "modules/Module07-VarCreationClassesSummaries.html#ifelse-example-1",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "ifelse example",
    "text": "ifelse example\nLet’s delve into what is actually happening, with a focus on the NA values in age variable.\n\ndf$age_group &lt;- ifelse(df$age &lt;= 5, \"young\", \"old\")\n\n\ndf$age &lt;= 5\n\n  [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE    NA  TRUE  TRUE  TRUE FALSE\n [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE\n [25]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE\n [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [49]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [61]  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n [73] FALSE  TRUE  TRUE  TRUE    NA  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE\n [85] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [97]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[109] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE    NA  TRUE  TRUE\n[121]    NA  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[133] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[145]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[157] FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE\n[169] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE\n[181]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE\n[193] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE\n[205]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[217] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[229]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[241] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE\n[253] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[265]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE\n[277] FALSE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[289]  TRUE    NA FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[301]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE\n[313]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE\n[325]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE\n[337] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE\n[349] FALSE    NA FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE\n[361]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE\n[373] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n[385]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[397] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[409]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[421] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[433]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[445] FALSE FALSE  TRUE  TRUE  TRUE  TRUE    NA    NA  TRUE  TRUE  TRUE  TRUE\n[457]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[469] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[481]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE\n[493]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n[505] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[517]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[529] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[541]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[553] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[565]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[577] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[589] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[601] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[613]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[625] FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[637]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE    NA FALSE FALSE FALSE\n[649] FALSE FALSE FALSE",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#nesting-two-ifelse-statements-example",
    "href": "modules/Module07-VarCreationClassesSummaries.html#nesting-two-ifelse-statements-example",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Nesting two ifelse statements example",
    "text": "Nesting two ifelse statements example\nifelse(test1, yes_to_test1, ifelse(test2, no_to_test2_yes_to_test2, no_to_test1_no_to_test2)).\n\ndf$age_group &lt;- ifelse(df$age &lt;= 5, \"young\", \n                       ifelse(df$age&lt;=10 & df$age&gt;5, \"middle\", \"old\"))\n\nLet’s use the table() function to check if it worked.\n\ntable(df$age, df$age_group, useNA=\"always\", dnn=list(\"age\", \"\"))\n\n\n\n\nage/\nmiddle\nold\nyoung\nNA\n\n\n\n\n1\n0\n0\n44\n0\n\n\n2\n0\n0\n72\n0\n\n\n3\n0\n0\n79\n0\n\n\n4\n0\n0\n80\n0\n\n\n5\n0\n0\n41\n0\n\n\n6\n38\n0\n0\n0\n\n\n7\n38\n0\n0\n0\n\n\n8\n39\n0\n0\n0\n\n\n9\n20\n0\n0\n0\n\n\n10\n44\n0\n0\n0\n\n\n11\n0\n41\n0\n0\n\n\n12\n0\n23\n0\n0\n\n\n13\n0\n35\n0\n0\n\n\n14\n0\n37\n0\n0\n\n\n15\n0\n11\n0\n0\n\n\nNA\n0\n0\n0\n9\n\n\n\n\n\nNote, it puts the variable levels in alphabetical order, we will show how to change this later.",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#overview---data-classes",
    "href": "modules/Module07-VarCreationClassesSummaries.html#overview---data-classes",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Overview - Data Classes",
    "text": "Overview - Data Classes\n\nOne dimensional types (i.e., vectors of characters, numeric, logical, or factor values)\nTwo dimensional types (e.g., matrix, data frame, tibble)\nSpecial data classes (e.g., lists, dates).",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#class-function",
    "href": "modules/Module07-VarCreationClassesSummaries.html#class-function",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "class() function",
    "text": "class() function\nThe class() function allows you to evaluate the class of an object.\n\nclass(df$IgG_concentration)\n\n[1] \"numeric\"\n\nclass(df$age)\n\n[1] \"integer\"\n\nclass(df$gender)\n\n[1] \"character\"",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#one-dimensional-data-types",
    "href": "modules/Module07-VarCreationClassesSummaries.html#one-dimensional-data-types",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "One dimensional data types",
    "text": "One dimensional data types\n\nCharacter: strings or individual characters, quoted\nNumeric: any real number(s)\n\nDouble: contains fractional values (i.e., double precision) - default numeric\nInteger: any integer(s)/whole numbers\n\nLogical: variables composed of TRUE or FALSE\nFactor: categorical/qualitative variables",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#character-and-numeric",
    "href": "modules/Module07-VarCreationClassesSummaries.html#character-and-numeric",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Character and numeric",
    "text": "Character and numeric\nThis can also be a bit tricky.\nIf only one character in the whole vector, the class is assumed to be character\n\nclass(c(1, 2, \"tree\")) \n\n[1] \"character\"\n\n\nHere because integers are in quotations, it is read as a character class by R.\n\nclass(c(\"1\", \"4\", \"7\")) \n\n[1] \"character\"\n\n\nNote, instead of creating a new vector object (e.g., x &lt;- c(\"1\", \"4\", \"7\")) and then feeding the vector object x into the first argument of the class() function (e.g., class(x)), we combined the two steps and directly fed a vector object into the class function.",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#numeric-subclasses",
    "href": "modules/Module07-VarCreationClassesSummaries.html#numeric-subclasses",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Numeric Subclasses",
    "text": "Numeric Subclasses\nThere are two major numeric subclasses\n\nDouble is a special subset of numeric that contains fractional values. Double stands for double-precision\nInteger is a special subset of numeric that contains only whole numbers.\n\ntypeof() identifies the vector type (double, integer, logical, or character), whereas class() identifies the root class. The difference between the two will be more clear when we look at two dimensional classes below.\n\nclass(df$IgG_concentration)\n\n[1] \"numeric\"\n\nclass(df$age)\n\n[1] \"integer\"\n\ntypeof(df$IgG_concentration)\n\n[1] \"double\"\n\ntypeof(df$age)\n\n[1] \"integer\"",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#logical",
    "href": "modules/Module07-VarCreationClassesSummaries.html#logical",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Logical",
    "text": "Logical\nReminder logical is a type that only has three possible elements: TRUE and FALSE and NA\n\nclass(c(TRUE, FALSE, TRUE, TRUE, FALSE))\n\n[1] \"logical\"\n\n\nNote that when creating logical object the TRUE and FALSE are NOT in quotes. Putting R special classes (e.g., NA or FALSE) in quotations turns them into character value.",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#other-useful-functions-for-evaluatingsetting-classes",
    "href": "modules/Module07-VarCreationClassesSummaries.html#other-useful-functions-for-evaluatingsetting-classes",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Other useful functions for evaluating/setting classes",
    "text": "Other useful functions for evaluating/setting classes\nThere are two useful functions associated with practically all R classes:\n\nis.CLASS_NAME(x) to logically check whether or not x is of certain class. For example, is.integer or is.character or is.numeric\nas.CLASS_NAME(x) to coerce between classes x from current x class into a another class. For example, as.integer or as.character or as.numeric. This is particularly useful is maybe integer variable was read in as a character variable, or when you need to change a character variable to a factor variable (more on this later).",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#examples-is.class_namex",
    "href": "modules/Module07-VarCreationClassesSummaries.html#examples-is.class_namex",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Examples is.CLASS_NAME(x)",
    "text": "Examples is.CLASS_NAME(x)\n\nis.numeric(df$IgG_concentration)\n\n[1] TRUE\n\nis.character(df$age)\n\n[1] FALSE\n\nis.character(df$gender)\n\n[1] TRUE",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#examples-as.class_namex",
    "href": "modules/Module07-VarCreationClassesSummaries.html#examples-as.class_namex",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Examples as.CLASS_NAME(x)",
    "text": "Examples as.CLASS_NAME(x)\nIn some cases, coercing is seamless\n\nas.character(c(1, 4, 7))\n\n[1] \"1\" \"4\" \"7\"\n\nas.numeric(c(\"1\", \"4\", \"7\"))\n\n[1] 1 4 7\n\nas.logical(c(\"TRUE\", \"FALSE\", \"FALSE\"))\n\n[1]  TRUE FALSE FALSE\n\n\nIn some cases the coercing is not possible; if executed, will return NA\n\nas.numeric(c(\"1\", \"4\", \"7a\"))\n\nWarning: NAs introduced by coercion\n\n\n[1]  1  4 NA\n\nas.logical(c(\"TRUE\", \"FALSE\", \"UNKNOWN\"))\n\n[1]  TRUE FALSE    NA",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#factors",
    "href": "modules/Module07-VarCreationClassesSummaries.html#factors",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Factors",
    "text": "Factors\nA factor is a special character vector where the elements have pre-defined groups or ‘levels’. You can think of these as qualitative or categorical variables. Use the factor() function to create factors from character values.\n\nclass(df$age_group)\n\n[1] \"character\"\n\ndf$age_group_factor &lt;- factor(df$age_group)\nclass(df$age_group_factor)\n\n[1] \"factor\"\n\nlevels(df$age_group_factor)\n\n[1] \"middle\" \"old\"    \"young\" \n\n\nNote 1, that levels are, by default, set to alphanumerical order! And, the first is always the “reference” group. However, we often prefer a different reference group.\nNote 2, we can also make ordered factors using factor(... ordered=TRUE), but we won’t talk more about that.",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#reference-groups",
    "href": "modules/Module07-VarCreationClassesSummaries.html#reference-groups",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Reference Groups",
    "text": "Reference Groups\nWhy do we care about reference groups?\nGeneralized linear regression allows you to compare the outcome of two or more groups. Your reference group is the group that everything else is compared to. Say we want to assess whether being &lt;5 years old is associated with higher IgG antibody concentrations\nBy default middle is the reference group therefore we will only generate beta coefficients comparing middle to young AND middle to old. But, we want young to be the reference group so we will generate beta coefficients comparing young to middle AND young to old.",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#changing-factor-reference",
    "href": "modules/Module07-VarCreationClassesSummaries.html#changing-factor-reference",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Changing factor reference",
    "text": "Changing factor reference\nChanging the reference group of a factor variable.\n\nIf the object is already a factor then use relevel() function and the ref argument to specify the reference.\nIf the object is a character then use factor() function and levels argument to specify the order of the values, the first being the reference.\n\nLet’s look at the relevel() help file\nReorder Levels of Factor\nDescription:\n The levels of a factor are re-ordered so that the level specified\n by 'ref' is first and the others are moved down. This is useful\n for 'contr.treatment' contrasts which take the first level as the\n reference.\nUsage:\n relevel(x, ref, ...)\n \nArguments:\n   x: an unordered factor.\n\n ref: the reference level, typically a string.\n\n ...: additional arguments for future methods.\nDetails:\n This, as 'reorder()', is a special case of simply calling\n 'factor(x, levels = levels(x)[....])'.\nValue:\n A factor of the same length as 'x'.\nSee Also:\n 'factor', 'contr.treatment', 'levels', 'reorder'.\nExamples:\n warpbreaks$tension &lt;- relevel(warpbreaks$tension, ref = \"M\")\n summary(lm(breaks ~ wool + tension, data = warpbreaks))\n\nLet’s look at the factor() help file\nFactors\nDescription:\n The function 'factor' is used to encode a vector as a factor (the\n terms 'category' and 'enumerated type' are also used for factors).\n If argument 'ordered' is 'TRUE', the factor levels are assumed to\n be ordered.  For compatibility with S there is also a function\n 'ordered'.\n\n 'is.factor', 'is.ordered', 'as.factor' and 'as.ordered' are the\n membership and coercion functions for these classes.\nUsage:\n factor(x = character(), levels, labels = levels,\n        exclude = NA, ordered = is.ordered(x), nmax = NA)\n \n ordered(x = character(), ...)\n \n is.factor(x)\n is.ordered(x)\n \n as.factor(x)\n as.ordered(x)\n \n addNA(x, ifany = FALSE)\n \n .valid.factor(object)\n \nArguments:\n   x: a vector of data, usually taking a small number of distinct\n      values.\nlevels: an optional vector of the unique values (as character strings) that ‘x’ might have taken. The default is the unique set of values taken by ‘as.character(x)’, sorted into increasing order of ‘x’. Note that this set can be specified as smaller than ‘sort(unique(x))’.\nlabels: either an optional character vector of labels for the levels (in the same order as ‘levels’ after removing those in ‘exclude’), or a character string of length 1. Duplicated values in ‘labels’ can be used to map different values of ‘x’ to the same factor level.\nexclude: a vector of values to be excluded when forming the set of levels. This may be factor with the same level set as ‘x’ or should be a ‘character’.\nordered: logical flag to determine if the levels should be regarded as ordered (in the order given).\nnmax: an upper bound on the number of levels; see 'Details'.\n\n ...: (in 'ordered(.)'): any of the above, apart from 'ordered'\n      itself.\nifany: only add an ‘NA’ level if it is used, i.e. if ‘any(is.na(x))’.\nobject: an R object.\nDetails:\n The type of the vector 'x' is not restricted; it only must have an\n 'as.character' method and be sortable (by 'order').\n\n Ordered factors differ from factors only in their class, but\n methods and model-fitting functions may treat the two classes\n quite differently, see 'options(\"contrasts\")'.\n\n The encoding of the vector happens as follows.  First all the\n values in 'exclude' are removed from 'levels'. If 'x[i]' equals\n 'levels[j]', then the 'i'-th element of the result is 'j'.  If no\n match is found for 'x[i]' in 'levels' (which will happen for\n excluded values) then the 'i'-th element of the result is set to\n 'NA'.\n\n Normally the 'levels' used as an attribute of the result are the\n reduced set of levels after removing those in 'exclude', but this\n can be altered by supplying 'labels'.  This should either be a set\n of new labels for the levels, or a character string, in which case\n the levels are that character string with a sequence number\n appended.\n\n 'factor(x, exclude = NULL)' applied to a factor without 'NA's is a\n no-operation unless there are unused levels: in that case, a\n factor with the reduced level set is returned.  If 'exclude' is\n used, since R version 3.4.0, excluding non-existing character\n levels is equivalent to excluding nothing, and when 'exclude' is a\n 'character' vector, that _is_ applied to the levels of 'x'.\n Alternatively, 'exclude' can be factor with the same level set as\n 'x' and will exclude the levels present in 'exclude'.\n\n The codes of a factor may contain 'NA'.  For a numeric 'x', set\n 'exclude = NULL' to make 'NA' an extra level (prints as '&lt;NA&gt;');\n by default, this is the last level.\n\n If 'NA' is a level, the way to set a code to be missing (as\n opposed to the code of the missing level) is to use 'is.na' on the\n left-hand-side of an assignment (as in 'is.na(f)[i] &lt;- TRUE';\n indexing inside 'is.na' does not work).  Under those circumstances\n missing values are currently printed as '&lt;NA&gt;', i.e., identical to\n entries of level 'NA'.\n\n 'is.factor' is generic: you can write methods to handle specific\n classes of objects, see InternalMethods.\n\n Where 'levels' is not supplied, 'unique' is called.  Since factors\n typically have quite a small number of levels, for large vectors\n 'x' it is helpful to supply 'nmax' as an upper bound on the number\n of unique values.\n\n When using 'c' to combine a (possibly ordered) factor with other\n objects, if all objects are (possibly ordered) factors, the result\n will be a factor with levels the union of the level sets of the\n elements, in the order the levels occur in the level sets of the\n elements (which means that if all the elements have the same level\n set, that is the level set of the result), equivalent to how\n 'unlist' operates on a list of factor objects.\nValue:\n 'factor' returns an object of class '\"factor\"' which has a set of\n integer codes the length of 'x' with a '\"levels\"' attribute of\n mode 'character' and unique ('!anyDuplicated(.)') entries.  If\n argument 'ordered' is true (or 'ordered()' is used) the result has\n class 'c(\"ordered\", \"factor\")'.  Undocumentedly for a long time,\n 'factor(x)' loses all 'attributes(x)' but '\"names\"', and resets\n '\"levels\"' and '\"class\"'.\n\n Applying 'factor' to an ordered or unordered factor returns a\n factor (of the same type) with just the levels which occur: see\n also '[.factor' for a more transparent way to achieve this.\n\n 'is.factor' returns 'TRUE' or 'FALSE' depending on whether its\n argument is of type factor or not.  Correspondingly, 'is.ordered'\n returns 'TRUE' when its argument is an ordered factor and 'FALSE'\n otherwise.\n\n 'as.factor' coerces its argument to a factor.  It is an\n abbreviated (sometimes faster) form of 'factor'.\n\n 'as.ordered(x)' returns 'x' if this is ordered, and 'ordered(x)'\n otherwise.\n\n 'addNA' modifies a factor by turning 'NA' into an extra level (so\n that 'NA' values are counted in tables, for instance).\n\n '.valid.factor(object)' checks the validity of a factor, currently\n only 'levels(object)', and returns 'TRUE' if it is valid,\n otherwise a string describing the validity problem.  This function\n is used for 'validObject(&lt;factor&gt;)'.\nWarning:\n The interpretation of a factor depends on both the codes and the\n '\"levels\"' attribute.  Be careful only to compare factors with the\n same set of levels (in the same order).  In particular,\n 'as.numeric' applied to a factor is meaningless, and may happen by\n implicit coercion.  To transform a factor 'f' to approximately its\n original numeric values, 'as.numeric(levels(f))[f]' is recommended\n and slightly more efficient than 'as.numeric(as.character(f))'.\n\n The levels of a factor are by default sorted, but the sort order\n may well depend on the locale at the time of creation, and should\n not be assumed to be ASCII.\n\n There are some anomalies associated with factors that have 'NA' as\n a level.  It is suggested to use them sparingly, e.g., only for\n tabulation purposes.\nComparison operators and group generic methods:\n There are '\"factor\"' and '\"ordered\"' methods for the group generic\n 'Ops' which provide methods for the Comparison operators, and for\n the 'min', 'max', and 'range' generics in 'Summary' of\n '\"ordered\"'.  (The rest of the groups and the 'Math' group\n generate an error as they are not meaningful for factors.)\n\n Only '==' and '!=' can be used for factors: a factor can only be\n compared to another factor with an identical set of levels (not\n necessarily in the same ordering) or to a character vector.\n Ordered factors are compared in the same way, but the general\n dispatch mechanism precludes comparing ordered and unordered\n factors.\n\n All the comparison operators are available for ordered factors.\n Collation is done by the levels of the operands: if both operands\n are ordered factors they must have the same level set.\nNote:\n In earlier versions of R, storing character data as a factor was\n more space efficient if there is even a small proportion of\n repeats.  However, identical character strings now share storage,\n so the difference is small in most cases.  (Integer values are\n stored in 4 bytes whereas each reference to a character string\n needs a pointer of 4 or 8 bytes.)\nReferences:\n Chambers, J. M. and Hastie, T. J. (1992) _Statistical Models in\n S_.  Wadsworth & Brooks/Cole.\nSee Also:\n '[.factor' for subsetting of factors.\n\n 'gl' for construction of balanced factors and 'C' for factors with\n specified contrasts.  'levels' and 'nlevels' for accessing the\n levels, and 'unclass' to get integer codes.\nExamples:\n (ff &lt;- factor(substring(\"statistics\", 1:10, 1:10), levels = letters))\n as.integer(ff)      # the internal codes\n (f. &lt;- factor(ff))  # drops the levels that do not occur\n ff[, drop = TRUE]   # the same, more transparently\n \n factor(letters[1:20], labels = \"letter\")\n \n class(ordered(4:1)) # \"ordered\", inheriting from \"factor\"\n z &lt;- factor(LETTERS[3:1], ordered = TRUE)\n ## and \"relational\" methods work:\n stopifnot(sort(z)[c(1,3)] == range(z), min(z) &lt; max(z))\n \n \n ## suppose you want \"NA\" as a level, and to allow missing values.\n (x &lt;- factor(c(1, 2, NA), exclude = NULL))\n is.na(x)[2] &lt;- TRUE\n x  # [1] 1    &lt;NA&gt; &lt;NA&gt;\n is.na(x)\n # [1] FALSE  TRUE FALSE\n \n ## More rational, since R 3.4.0 :\n factor(c(1:2, NA), exclude =  \"\" ) # keeps &lt;NA&gt; , as\n factor(c(1:2, NA), exclude = NULL) # always did\n ## exclude = &lt;character&gt;\n z # ordered levels 'A &lt; B &lt; C'\n factor(z, exclude = \"C\") # does exclude\n factor(z, exclude = \"B\") # ditto\n \n ## Now, labels maybe duplicated:\n ## factor() with duplicated labels allowing to \"merge levels\"\n x &lt;- c(\"Man\", \"Male\", \"Man\", \"Lady\", \"Female\")\n ## Map from 4 different values to only two levels:\n (xf &lt;- factor(x, levels = c(\"Male\", \"Man\" , \"Lady\",   \"Female\"),\n                  labels = c(\"Male\", \"Male\", \"Female\", \"Female\")))\n #&gt; [1] Male   Male   Male   Female Female\n #&gt; Levels: Male Female\n \n ## Using addNA()\n Month &lt;- airquality$Month\n table(addNA(Month))\n table(addNA(Month, ifany = TRUE))",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#changing-factor-reference-examples",
    "href": "modules/Module07-VarCreationClassesSummaries.html#changing-factor-reference-examples",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Changing factor reference examples",
    "text": "Changing factor reference examples\n\ndf$age_group_factor &lt;- relevel(df$age_group_factor, ref=\"young\")\nlevels(df$age_group_factor)\n\n[1] \"young\"  \"middle\" \"old\"   \n\n\nOR\n\ndf$age_group_factor &lt;- factor(df$age_group, levels=c(\"young\", \"middle\", \"old\"))\nlevels(df$age_group_factor)\n\n[1] \"young\"  \"middle\" \"old\"   \n\n\nArranging, tabulating, and plotting the data will reflect the new order",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#two-dimensional-data-classes",
    "href": "modules/Module07-VarCreationClassesSummaries.html#two-dimensional-data-classes",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Two-dimensional data classes",
    "text": "Two-dimensional data classes\nTwo-dimensional classes are those we would often use to store data read from a file\n\na matrix (matrix class)\na data frame (data.frame or tibble classes)",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#matrices",
    "href": "modules/Module07-VarCreationClassesSummaries.html#matrices",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Matrices",
    "text": "Matrices\nMatrices, like data frames are also composed of rows and columns. Matrices, unlike data.frame, the entire matrix is composed of one R class. For example: all entries are numeric, or all entries are character\nas.matrix() creates a matrix from a data frame (where all values are the same class). As a reminder, here is the matrix signature function to help remind us how to build a matrix\nmatrix(data = NA, nrow = 1, ncol = 1, byrow = FALSE, dimnames = NULL)\n\nmatrix(data=1:6, ncol = 2) \n\n\n\n\n1\n4\n\n\n2\n5\n\n\n3\n6\n\n\n\n\nmatrix(data=1:6, ncol=2, byrow=TRUE) \n\n\n\n\n1\n2\n\n\n3\n4\n\n\n5\n6\n\n\n\n\n\nNote, the first matrix filled in numbers 1-6 by columns first and then rows because default byrow argument is FALSE. In the second matrix, we changed the argument byrow to TRUE, and now numbers 1-6 are filled by rows first and then columns.",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#data-frame",
    "href": "modules/Module07-VarCreationClassesSummaries.html#data-frame",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Data frame",
    "text": "Data frame\nYou can transform an existing matrix into data frames using as.data.frame()\n\nas.data.frame(matrix(1:6, ncol = 2) ) \n\n\n\n\nV1\nV2\n\n\n\n\n1\n4\n\n\n2\n5\n\n\n3\n6\n\n\n\n\n\nYou can create a new data frame out of vectors (and potentially lists, but this is an advanced feature and unusual) by using the data.frame() function. Recall that all of the vectors that make up a data frame must be the same length.\n\nlotr &lt;- \n  data.frame(\n    name = c(\"Frodo\", \"Sam\", \"Aragorn\", \"Legolas\", \"Gimli\"),\n    race = c(\"Hobbit\", \"Hobbit\", \"Human\", \"Elf\", \"Dwarf\"),\n    age = c(53, 38, 87, 2931, 139)\n  )",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#numeric-variable-data-summary",
    "href": "modules/Module07-VarCreationClassesSummaries.html#numeric-variable-data-summary",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Numeric variable data summary",
    "text": "Numeric variable data summary\nData summarization on numeric vectors/variables:\n\nmean(): takes the mean of x\nsd(): takes the standard deviation of x\nmedian(): takes the median of x\nquantile(): displays sample quantiles of x. Default is min, IQR, max\nrange(): displays the range. Same as c(min(), max())\nsum(): sum of x\nmax(): maximum value in x\nmin(): minimum value in x\ncolSums(): get the columns sums of a data frame\nrowSums(): get the row sums of a data frame\ncolMeans(): get the columns means of a data frame\nrowMeans(): get the row means of a data frame\n\nNote, all of these functions have an na.rm argument for missing data.",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#numeric-variable-data-summary-1",
    "href": "modules/Module07-VarCreationClassesSummaries.html#numeric-variable-data-summary-1",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Numeric variable data summary",
    "text": "Numeric variable data summary\nLet’s look at a help file for range() to make note of the na.rm argument\n\n?range\n\nRange of Values\nDescription:\n 'range' returns a vector containing the minimum and maximum of all\n the given arguments.\nUsage:\n range(..., na.rm = FALSE)\n ## Default S3 method:\n range(..., na.rm = FALSE, finite = FALSE)\n ## same for classes 'Date' and 'POSIXct'\n \n .rangeNum(..., na.rm, finite, isNumeric)\n \nArguments:\n ...: any 'numeric' or character objects.\nna.rm: logical, indicating if ‘NA’’s should be omitted.\nfinite: logical, indicating if all non-finite elements should be omitted.\nisNumeric: a ‘function’ returning ‘TRUE’ or ‘FALSE’ when called on ‘c(…, recursive = TRUE)’, ‘is.numeric()’ for the default ‘range()’ method.\nDetails:\n 'range' is a generic function: methods can be defined for it\n directly or via the 'Summary' group generic.  For this to work\n properly, the arguments '...' should be unnamed, and dispatch is\n on the first argument.\n\n If 'na.rm' is 'FALSE', 'NA' and 'NaN' values in any of the\n arguments will cause 'NA' values to be returned, otherwise 'NA'\n values are ignored.\n\n If 'finite' is 'TRUE', the minimum and maximum of all finite\n values is computed, i.e., 'finite = TRUE' _includes_ 'na.rm =\n TRUE'.\n\n A special situation occurs when there is no (after omission of\n 'NA's) nonempty argument left, see 'min'.\nS4 methods:\n This is part of the S4 'Summary' group generic.  Methods for it\n must use the signature 'x, ..., na.rm'.\nReferences:\n Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S\n Language_.  Wadsworth & Brooks/Cole.\nSee Also:\n 'min', 'max'.\n\n The 'extendrange()' utility in package 'grDevices'.\nExamples:\n (r.x &lt;- range(stats::rnorm(100)))\n diff(r.x) # the SAMPLE range\n \n x &lt;- c(NA, 1:3, -1:1/0); x\n range(x)\n range(x, na.rm = TRUE)\n range(x, finite = TRUE)",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#numeric-variable-data-summary-examples",
    "href": "modules/Module07-VarCreationClassesSummaries.html#numeric-variable-data-summary-examples",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Numeric variable data summary examples",
    "text": "Numeric variable data summary examples\n\nsummary(df)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nobservation_id\nIgG_concentration\nage\ngender\nslum\nlog_IgG\nseropos\nage_group\nage_group_factor\n\n\n\n\n\nMin. :5006\nMin. : 0.0054\nMin. : 1.000\nLength:651\nLength:651\nMin. :-5.2231\nMode :logical\nLength:651\nyoung :316\n\n\n\n1st Qu.:6306\n1st Qu.: 0.3000\n1st Qu.: 3.000\nClass :character\nClass :character\n1st Qu.:-1.2040\nFALSE:360\nClass :character\nmiddle:179\n\n\n\nMedian :7495\nMedian : 1.6658\nMedian : 6.000\nMode :character\nMode :character\nMedian : 0.5103\nTRUE :281\nMode :character\nold :147\n\n\n\nMean :7492\nMean : 87.3683\nMean : 6.606\nNA\nNA\nMean : 1.6074\nNA’s :10\nNA\nNA’s : 9\n\n\n\n3rd Qu.:8749\n3rd Qu.:141.4405\n3rd Qu.:10.000\nNA\nNA\n3rd Qu.: 4.9519\nNA\nNA\nNA\n\n\n\nMax. :9982\nMax. :916.4179\nMax. :15.000\nNA\nNA\nMax. : 6.8205\nNA\nNA\nNA\n\n\n\nNA\nNA’s :10\nNA’s :9\nNA\nNA\nNA’s :10\nNA\nNA\nNA\n\n\n\n\nrange(df$age)\n\n[1] NA NA\n\nrange(df$age, na.rm=TRUE)\n\n[1]  1 15\n\nmedian(df$IgG_concentration, na.rm=TRUE)\n\n[1] 1.665753",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#character-variable-data-summaries",
    "href": "modules/Module07-VarCreationClassesSummaries.html#character-variable-data-summaries",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Character variable data summaries",
    "text": "Character variable data summaries\nData summarization on character or factor vectors/variables using table()\n\n?table\n\nCross Tabulation and Table Creation\nDescription:\n 'table' uses cross-classifying factors to build a contingency\n table of the counts at each combination of factor levels.\nUsage:\n table(...,\n       exclude = if (useNA == \"no\") c(NA, NaN),\n       useNA = c(\"no\", \"ifany\", \"always\"),\n       dnn = list.names(...), deparse.level = 1)\n \n as.table(x, ...)\n is.table(x)\n \n ## S3 method for class 'table'\n as.data.frame(x, row.names = NULL, ...,\n               responseName = \"Freq\", stringsAsFactors = TRUE,\n               sep = \"\", base = list(LETTERS))\n \nArguments:\n ...: one or more objects which can be interpreted as factors\n      (including numbers or character strings), or a 'list' (such\n      as a data frame) whose components can be so interpreted.\n      (For 'as.table', arguments passed to specific methods; for\n      'as.data.frame', unused.)\nexclude: levels to remove for all factors in ‘…’. If it does not contain ‘NA’ and ‘useNA’ is not specified, it implies ‘useNA = “ifany”’. See ‘Details’ for its interpretation for non-factor arguments.\nuseNA: whether to include ‘NA’ values in the table. See ‘Details’. Can be abbreviated.\n dnn: the names to be given to the dimensions in the result (the\n      _dimnames names_).\ndeparse.level: controls how the default ‘dnn’ is constructed. See ‘Details’.\n   x: an arbitrary R object, or an object inheriting from class\n      '\"table\"' for the 'as.data.frame' method. Note that\n      'as.data.frame.table(x, *)' may be called explicitly for\n      non-table 'x' for \"reshaping\" 'array's.\nrow.names: a character vector giving the row names for the data frame.\nresponseName: the name to be used for the column of table entries, usually counts.\nstringsAsFactors: logical: should the classifying factors be returned as factors (the default) or character vectors?\nsep, base: passed to ‘provideDimnames’.\nDetails:\n If the argument 'dnn' is not supplied, the internal function\n 'list.names' is called to compute the 'dimname names' as follows:\n If '...' is one 'list' with its own 'names()', these 'names' are\n used.  Otherwise, if the arguments in '...' are named, those names\n are used.  For the remaining arguments, 'deparse.level = 0' gives\n an empty name, 'deparse.level = 1' uses the supplied argument if\n it is a symbol, and 'deparse.level = 2' will deparse the argument.\n\n Only when 'exclude' is specified (i.e., not by default) and\n non-empty, will 'table' potentially drop levels of factor\n arguments.\n\n 'useNA' controls if the table includes counts of 'NA' values: the\n allowed values correspond to never ('\"no\"'), only if the count is\n positive ('\"ifany\"') and even for zero counts ('\"always\"').  Note\n the somewhat \"pathological\" case of two different kinds of 'NA's\n which are treated differently, depending on both 'useNA' and\n 'exclude', see 'd.patho' in the 'Examples:' below.\n\n Both 'exclude' and 'useNA' operate on an \"all or none\" basis.  If\n you want to control the dimensions of a multiway table separately,\n modify each argument using 'factor' or 'addNA'.\n\n Non-factor arguments 'a' are coerced via 'factor(a,\n exclude=exclude)'.  Since R 3.4.0, care is taken _not_ to count\n the excluded values (where they were included in the 'NA' count,\n previously).\n\n The 'summary' method for class '\"table\"' (used for objects created\n by 'table' or 'xtabs') which gives basic information and performs\n a chi-squared test for independence of factors (note that the\n function 'chisq.test' currently only handles 2-d tables).\nValue:\n 'table()' returns a _contingency table_, an object of class\n '\"table\"', an array of integer values.  Note that unlike S the\n result is always an 'array', a 1D array if one factor is given.\n\n 'as.table' and 'is.table' coerce to and test for contingency\n table, respectively.\n\n The 'as.data.frame' method for objects inheriting from class\n '\"table\"' can be used to convert the array-based representation of\n a contingency table to a data frame containing the classifying\n factors and the corresponding entries (the latter as component\n named by 'responseName').  This is the inverse of 'xtabs'.\nReferences:\n Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S\n Language_.  Wadsworth & Brooks/Cole.\nSee Also:\n 'tabulate' is the underlying function and allows finer control.\n\n Use 'ftable' for printing (and more) of multidimensional tables.\n 'margin.table', 'prop.table', 'addmargins'.\n\n 'addNA' for constructing factors with 'NA' as a level.\n\n 'xtabs' for cross tabulation of data frames with a formula\n interface.\nExamples:\n require(stats) # for rpois and xtabs\n ## Simple frequency distribution\n table(rpois(100, 5))\n ## Check the design:\n with(warpbreaks, table(wool, tension))\n table(state.division, state.region)\n \n # simple two-way contingency table\n with(airquality, table(cut(Temp, quantile(Temp)), Month))\n \n a &lt;- letters[1:3]\n table(a, sample(a))                    # dnn is c(\"a\", \"\")\n table(a, sample(a), dnn = NULL)        # dimnames() have no names\n table(a, sample(a), deparse.level = 0) # dnn is c(\"\", \"\")\n table(a, sample(a), deparse.level = 2) # dnn is c(\"a\", \"sample(a)\")\n \n ## xtabs() &lt;-&gt; as.data.frame.table() :\n UCBAdmissions ## already a contingency table\n DF &lt;- as.data.frame(UCBAdmissions)\n class(tab &lt;- xtabs(Freq ~ ., DF)) # xtabs & table\n ## tab *is* \"the same\" as the original table:\n all(tab == UCBAdmissions)\n all.equal(dimnames(tab), dimnames(UCBAdmissions))\n \n a &lt;- rep(c(NA, 1/0:3), 10)\n table(a)                 # does not report NA's\n table(a, exclude = NULL) # reports NA's\n b &lt;- factor(rep(c(\"A\",\"B\",\"C\"), 10))\n table(b)\n table(b, exclude = \"B\")\n d &lt;- factor(rep(c(\"A\",\"B\",\"C\"), 10), levels = c(\"A\",\"B\",\"C\",\"D\",\"E\"))\n table(d, exclude = \"B\")\n print(table(b, d), zero.print = \".\")\n \n ## NA counting:\n is.na(d) &lt;- 3:4\n d. &lt;- addNA(d)\n d.[1:7]\n table(d.) # \", exclude = NULL\" is not needed\n ## i.e., if you want to count the NA's of 'd', use\n table(d, useNA = \"ifany\")\n \n ## \"pathological\" case:\n d.patho &lt;- addNA(c(1,NA,1:2,1:3))[-7]; is.na(d.patho) &lt;- 3:4\n d.patho\n ## just 3 consecutive NA's ? --- well, have *two* kinds of NAs here :\n as.integer(d.patho) # 1 4 NA NA 1 2\n ##\n ## In R &gt;= 3.4.0, table() allows to differentiate:\n table(d.patho)                   # counts the \"unusual\" NA\n table(d.patho, useNA = \"ifany\")  # counts all three\n table(d.patho, exclude = NULL)   #  (ditto)\n table(d.patho, exclude = NA)     # counts none\n \n ## Two-way tables with NA counts. The 3rd variant is absurd, but shows\n ## something that cannot be done using exclude or useNA.\n with(airquality,\n    table(OzHi = Ozone &gt; 80, Month, useNA = \"ifany\"))\n with(airquality,\n    table(OzHi = Ozone &gt; 80, Month, useNA = \"always\"))\n with(airquality,\n    table(OzHi = Ozone &gt; 80, addNA(Month)))",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#character-variable-data-summary-examples",
    "href": "modules/Module07-VarCreationClassesSummaries.html#character-variable-data-summary-examples",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Character variable data summary examples",
    "text": "Character variable data summary examples\nNumber of observations in each category\n\ntable(df$gender)\n\n\n\n\nFemale\nMale\n\n\n\n\n325\n326\n\n\n\n\ntable(df$gender, useNA=\"always\")\n\n\n\n\nFemale\nMale\nNA\n\n\n\n\n325\n326\n0\n\n\n\n\ntable(df$age_group, useNA=\"always\")\n\n\n\n\nmiddle\nold\nyoung\nNA\n\n\n\n\n179\n147\n316\n9\n\n\n\n\n\n\ntable(df$gender)/nrow(df) #if no NA values\n\n\n\n\nFemale\nMale\n\n\n\n\n0.499232\n0.500768\n\n\n\n\ntable(df$age_group)/nrow(df[!is.na(df$age_group),]) #if there are NA values\n\n\n\n\nmiddle\nold\nyoung\n\n\n\n\n0.2788162\n0.228972\n0.4922118\n\n\n\n\ntable(df$age_group)/nrow(subset(df, !is.na(df$age_group),)) #if there are NA values\n\n\n\n\nmiddle\nold\nyoung\n\n\n\n\n0.2788162\n0.228972\n0.4922118",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#summary",
    "href": "modules/Module07-VarCreationClassesSummaries.html#summary",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Summary",
    "text": "Summary\n\nYou can create new columns/variable to a data frame by using $ or the transform() function\nOne useful function for creating new variables based on existing variables is the ifelse() function, which returns a value depending on whether the element of test is TRUE or FALSE\nThe class() function allows you to evaluate the class of an object.\nThere are two types of numeric class objects: integer and double\nLogical class objects only have TRUE or FALSE or NA (without quotes)\nis.CLASS_NAME(x) can be used to test the class of an object x\nas.CLASS_NAME(x) can be used to change the class of an object x\nFactors are a special character class that has levels\nThere are many fairly intuitive data summary functions you can perform on a vector (i.e., mean(), sd(), range()) or on rows or columns of a data frame (i.e., colSums(), colMeans(), rowSums())\nThe table() function builds frequency tables of the counts at each combination of categorical levels",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module07-VarCreationClassesSummaries.html#acknowledgements",
    "href": "modules/Module07-VarCreationClassesSummaries.html#acknowledgements",
    "title": "Module 7: Variable Creation, Classes, and Summaries",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese are the materials we looked through, modified, or extracted to complete this module’s lecture.\n\n“Introduction to R for Public Health Researchers” Johns Hopkins University",
    "crumbs": [
      "Day 1",
      "Module 7: Variable Creation, Classes, and Summaries"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#learning-objectives",
    "href": "modules/Module09-DataAnalysis.html#learning-objectives",
    "title": "Module 9: Data Analysis",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter module 9, you should be able to…\n\nDescriptively assess association between two variables\nCompute basic statistics\nFit a generalized linear model",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#import-data-for-this-module",
    "href": "modules/Module09-DataAnalysis.html#import-data-for-this-module",
    "title": "Module 9: Data Analysis",
    "section": "Import data for this module",
    "text": "Import data for this module\nLet’s read in our data (again) and take a quick look.\n\ndf &lt;- read.csv(file = \"data/serodata.csv\") #relative path\nhead(x=df, n=3)\n\n  observation_id IgG_concentration age gender     slum\n1           5772         0.3176895   2 Female Non slum\n2           8095         3.4368231   4 Female Non slum\n3           9784         0.3000000   4   Male Non slum",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#prep-data",
    "href": "modules/Module09-DataAnalysis.html#prep-data",
    "title": "Module 9: Data Analysis",
    "section": "Prep data",
    "text": "Prep data\nCreate age_group three level factor variable\n\ndf$age_group &lt;- ifelse(df$age &lt;= 5, \"young\", \n                       ifelse(df$age&lt;=10 & df$age&gt;5, \"middle\", \"old\"))\ndf$age_group &lt;- factor(df$age_group, levels=c(\"young\", \"middle\", \"old\"))\n\nCreate seropos binary variable representing seropositivity if antibody concentrations are &gt;10 IU/mL.\n\ndf$seropos &lt;- ifelse(df$IgG_concentration&lt;10, 0, 1)",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#grouped-analyses",
    "href": "modules/Module09-DataAnalysis.html#grouped-analyses",
    "title": "Module 9: Data Analysis",
    "section": "Grouped analyses",
    "text": "Grouped analyses\n\nMost of this module will discuss statistical analyses. But first we’ll discuss doing univariate analyses we’ve already used on multiple groups.\nWe can use the aggregate() function to do many analyses across groups.\n\n\n?aggregate\n\n\nlibrary(printr)\n\nRegistered S3 method overwritten by 'printr':\n  method                from     \n  knit_print.data.frame rmarkdown\n\n?aggregate\n\nCompute Summary Statistics of Data Subsets\n\nDescription:\n\n     Splits the data into subsets, computes summary statistics for\n     each, and returns the result in a convenient form.\n\nUsage:\n\n     aggregate(x, ...)\n     \n     ## Default S3 method:\n     aggregate(x, ...)\n     \n     ## S3 method for class 'data.frame'\n     aggregate(x, by, FUN, ..., simplify = TRUE, drop = TRUE)\n     \n     ## S3 method for class 'formula'\n     aggregate(x, data, FUN, ...,\n               subset, na.action = na.omit)\n     \n     ## S3 method for class 'ts'\n     aggregate(x, nfrequency = 1, FUN = sum, ndeltat = 1,\n               ts.eps = getOption(\"ts.eps\"), ...)\n     \nArguments:\n\n       x: an R object.  For the 'formula' method a 'formula', such as\n          'y ~ x' or 'cbind(y1, y2) ~ x1 + x2', where the 'y' variables\n          are numeric data to be split into groups according to the\n          grouping 'x' variables (usually factors).\n\n      by: a list of grouping elements, each as long as the variables in\n          the data frame 'x', or a formula.  The elements are coerced\n          to factors before use.\n\n     FUN: a function to compute the summary statistics which can be\n          applied to all data subsets.\n\nsimplify: a logical indicating whether results should be simplified to\n          a vector or matrix if possible.\n\n    drop: a logical indicating whether to drop unused combinations of\n          grouping values.  The non-default case 'drop=FALSE' has been\n          amended for R 3.5.0 to drop unused combinations.\n\n    data: a data frame (or list) from which the variables in the\n          formula should be taken.\n\n  subset: an optional vector specifying a subset of observations to be\n          used.\n\nna.action: a function which indicates what should happen when the data\n          contain 'NA' values. The default is to ignore missing values\n          in the given variables.\n\nnfrequency: new number of observations per unit of time; must be a\n          divisor of the frequency of 'x'.\n\n ndeltat: new fraction of the sampling period between successive\n          observations; must be a divisor of the sampling interval of\n          'x'.\n\n  ts.eps: tolerance used to decide if 'nfrequency' is a sub-multiple of\n          the original frequency.\n\n     ...: further arguments passed to or used by methods.\n\nDetails:\n\n     'aggregate' is a generic function with methods for data frames and\n     time series.\n\n     The default method, 'aggregate.default', uses the time series\n     method if 'x' is a time series, and otherwise coerces 'x' to a\n     data frame and calls the data frame method.\n\n     'aggregate.data.frame' is the data frame method.  If 'x' is not a\n     data frame, it is coerced to one, which must have a non-zero\n     number of rows.  Then, each of the variables (columns) in 'x' is\n     split into subsets of cases (rows) of identical combinations of\n     the components of 'by', and 'FUN' is applied to each such subset\n     with further arguments in '...' passed to it.  The result is\n     reformatted into a data frame containing the variables in 'by' and\n     'x'.  The ones arising from 'by' contain the unique combinations\n     of grouping values used for determining the subsets, and the ones\n     arising from 'x' the corresponding summaries for the subset of the\n     respective variables in 'x'.  If 'simplify' is true, summaries are\n     simplified to vectors or matrices if they have a common length of\n     one or greater than one, respectively; otherwise, lists of summary\n     results according to subsets are obtained.  Rows with missing\n     values in any of the 'by' variables will be omitted from the\n     result.  (Note that versions of R prior to 2.11.0 required 'FUN'\n     to be a scalar function.)\n\n     The formula method provides a standard formula interface to\n     'aggregate.data.frame'.  The latter invokes the formula method if\n     'by' is a formula, in which case 'aggregate(x, by, FUN)' is the\n     same as 'aggregate(by, x, FUN)' for a data frame 'x'.\n\n     'aggregate.ts' is the time series method, and requires 'FUN' to be\n     a scalar function.  If 'x' is not a time series, it is coerced to\n     one.  Then, the variables in 'x' are split into appropriate blocks\n     of length 'frequency(x) / nfrequency', and 'FUN' is applied to\n     each such block, with further (named) arguments in '...' passed to\n     it.  The result returned is a time series with frequency\n     'nfrequency' holding the aggregated values.  Note that this make\n     most sense for a quarterly or yearly result when the original\n     series covers a whole number of quarters or years: in particular\n     aggregating a monthly series to quarters starting in February does\n     not give a conventional quarterly series.\n\n     'FUN' is passed to 'match.fun', and hence it can be a function or\n     a symbol or character string naming a function.\n\nValue:\n\n     For the time series method, a time series of class '\"ts\"' or class\n     'c(\"mts\", \"ts\")'.\n\n     For the data frame method, a data frame with columns corresponding\n     to the grouping variables in 'by' followed by aggregated columns\n     from 'x'.  If the 'by' has names, the non-empty times are used to\n     label the columns in the results, with unnamed grouping variables\n     being named 'Group.i' for 'by[[i]]'.\n\nWarning:\n\n     The first argument of the '\"formula\"' method was named 'formula'\n     rather than 'x' prior to R 4.2.0.  Portable uses should not name\n     that argument.\n\nAuthor(s):\n\n     Kurt Hornik, with contributions by Arni Magnusson.\n\nReferences:\n\n     Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S\n     Language_.  Wadsworth & Brooks/Cole.\n\nSee Also:\n\n     'apply', 'lapply', 'tapply'.\n\nExamples:\n\n     ## Compute the averages for the variables in 'state.x77', grouped\n     ## according to the region (Northeast, South, North Central, West) that\n     ## each state belongs to.\n     aggregate(state.x77, list(Region = state.region), mean)\n     \n     ## Compute the averages according to region and the occurrence of more\n     ## than 130 days of frost.\n     aggregate(state.x77,\n               list(Region = state.region,\n                    Cold = state.x77[,\"Frost\"] &gt; 130),\n               mean)\n     ## (Note that no state in 'South' is THAT cold.)\n     \n     \n     ## example with character variables and NAs\n     testDF &lt;- data.frame(v1 = c(1,3,5,7,8,3,5,NA,4,5,7,9),\n                          v2 = c(11,33,55,77,88,33,55,NA,44,55,77,99) )\n     by1 &lt;- c(\"red\", \"blue\", 1, 2, NA, \"big\", 1, 2, \"red\", 1, NA, 12)\n     by2 &lt;- c(\"wet\", \"dry\", 99, 95, NA, \"damp\", 95, 99, \"red\", 99, NA, NA)\n     aggregate(x = testDF, by = list(by1, by2), FUN = \"mean\")\n     \n     # and if you want to treat NAs as a group\n     fby1 &lt;- factor(by1, exclude = \"\")\n     fby2 &lt;- factor(by2, exclude = \"\")\n     aggregate(x = testDF, by = list(fby1, fby2), FUN = \"mean\")\n     \n     \n     ## Formulas, one ~ one, one ~ many, many ~ one, and many ~ many:\n     aggregate(weight ~ feed, data = chickwts, mean)\n     aggregate(breaks ~ wool + tension, data = warpbreaks, mean)\n     aggregate(cbind(Ozone, Temp) ~ Month, data = airquality, mean)\n     aggregate(cbind(ncases, ncontrols) ~ alcgp + tobgp, data = esoph, sum)\n     \n     ## Dot notation:\n     aggregate(. ~ Species, data = iris, mean)\n     aggregate(len ~ ., data = ToothGrowth, mean)\n     \n     ## Often followed by xtabs():\n     ag &lt;- aggregate(len ~ ., data = ToothGrowth, mean)\n     xtabs(len ~ ., data = ag)\n     \n     ## Formula interface via 'by' (for pipe operations)\n     ToothGrowth |&gt; aggregate(len ~ ., FUN = mean)\n     \n     ## Compute the average annual approval ratings for American presidents.\n     aggregate(presidents, nfrequency = 1, FUN = mean)\n     ## Give the summer less weight.\n     aggregate(presidents, nfrequency = 1,\n               FUN = weighted.mean, w = c(1, 1, 0.5, 1))",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#grouped-analyses-1",
    "href": "modules/Module09-DataAnalysis.html#grouped-analyses-1",
    "title": "Module 9: Data Analysis",
    "section": "Grouped analyses",
    "text": "Grouped analyses\n\nLet’s calculate seropositivity rate across age groups using the variables we just created.\nThe easiest way to use aggregate() is with the formula option. The syntax is variable_of_intest ~ grouping_variables.\n\n\naggregate(\n    # Formula specifies we are calculating statistics on seropos, separately for\n    # each level of age_group\n    seropos ~ age_group,\n    data = df, # Data argument\n    FUN = mean # function for our calculation WITHOUT PARENTHESES\n)\n\n\n\n\nage_group\nseropos\n\n\n\n\nyoung\n0.1832797\n\n\nmiddle\n0.6000000\n\n\nold\n0.7945205\n\n\n\n\n\n\nWe can add as many things as we want on the RHS of the formula.\n\n\naggregate(\n    IgG_concentration ~ age_group + slum,\n    data = df,\n    FUN = sd # standard deviation\n)\n\n\n\n\nage_group\nslum\nIgG_concentration\n\n\n\n\nyoung\nMixed\n174.89797\n\n\nmiddle\nMixed\n162.08188\n\n\nold\nMixed\n150.07063\n\n\nyoung\nNon slum\n114.68422\n\n\nmiddle\nNon slum\n177.62113\n\n\nold\nNon slum\n141.22330\n\n\nyoung\nSlum\n61.85705\n\n\nmiddle\nSlum\n202.42018\n\n\nold\nSlum\n74.75217\n\n\n\n\n\n\nWe can also add multiple variables on the LHS at the same time using cbind() syntax.\n\n\naggregate(\n    cbind(age, IgG_concentration) ~ gender + slum,\n    data = df,\n    FUN = median\n)\n\n\n\n\ngender\nslum\nage\nIgG_concentration\n\n\n\n\nFemale\nMixed\n5.0\n2.0117423\n\n\nMale\nMixed\n6.0\n2.2082192\n\n\nFemale\nNon slum\n6.0\n2.5040431\n\n\nMale\nNon slum\n5.0\n1.1245846\n\n\nFemale\nSlum\n3.0\n5.1482480\n\n\nMale\nSlum\n5.5\n0.7753834",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#variable-contingency-tables",
    "href": "modules/Module09-DataAnalysis.html#variable-contingency-tables",
    "title": "Module 9: Data Analysis",
    "section": "2 variable contingency tables",
    "text": "2 variable contingency tables\nWe use table() prior to look at one variable, now we can generate frequency tables for 2 plus variables. To get cell percentages, the prop.table() is useful.\n\n?prop.table\n\n\nlibrary(printr)\n?prop.table\n\nExpress Table Entries as Fraction of Marginal Table\n\nDescription:\n\n     Returns conditional proportions given 'margins', i.e. entries of\n     'x', divided by the appropriate marginal sums.\n\nUsage:\n\n     proportions(x, margin = NULL)\n     prop.table(x, margin = NULL)\n     \nArguments:\n\n       x: table\n\n  margin: a vector giving the margins to split by.  E.g., for a matrix\n          '1' indicates rows, '2' indicates columns, 'c(1, 2)'\n          indicates rows and columns.  When 'x' has named dimnames, it\n          can be a character vector selecting dimension names.\n\nValue:\n\n     Table like 'x' expressed relative to 'margin'\n\nNote:\n\n     'prop.table' is an earlier name, retained for back-compatibility.\n\nAuthor(s):\n\n     Peter Dalgaard\n\nSee Also:\n\n     'marginSums'. 'apply', 'sweep' are a more general mechanism for\n     sweeping out marginal statistics.\n\nExamples:\n\n     m &lt;- matrix(1:4, 2)\n     m\n     proportions(m, 1)\n     \n     DF &lt;- as.data.frame(UCBAdmissions)\n     tbl &lt;- xtabs(Freq ~ Gender + Admit, DF)\n     \n     proportions(tbl, \"Gender\")",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#variable-contingency-tables-1",
    "href": "modules/Module09-DataAnalysis.html#variable-contingency-tables-1",
    "title": "Module 9: Data Analysis",
    "section": "2 variable contingency tables",
    "text": "2 variable contingency tables\nLet’s practice\n\nfreq &lt;- table(df$age_group, df$seropos)\nfreq\n\n\n\n\n/\n0\n1\n\n\n\n\nyoung\n254\n57\n\n\nmiddle\n70\n105\n\n\nold\n30\n116\n\n\n\n\n\nNow, lets move to percentages\n\nprop.cell.percentages &lt;- prop.table(freq)\nprop.cell.percentages\n\n\n\n\n/\n0\n1\n\n\n\n\nyoung\n0.4018987\n0.0901899\n\n\nmiddle\n0.1107595\n0.1661392\n\n\nold\n0.0474684\n0.1835443\n\n\n\n\nprop.column.percentages &lt;- prop.table(freq, margin=2)\nprop.column.percentages\n\n\n\n\n/\n0\n1\n\n\n\n\nyoung\n0.7175141\n0.2050360\n\n\nmiddle\n0.1977401\n0.3776978\n\n\nold\n0.0847458\n0.4172662",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#chi-square-test",
    "href": "modules/Module09-DataAnalysis.html#chi-square-test",
    "title": "Module 9: Data Analysis",
    "section": "Chi-Square test",
    "text": "Chi-Square test\nThe chisq.test() function test of independence of factor variables from stats package.\n\n?chisq.test\n\nPearson’s Chi-squared Test for Count Data\nDescription:\n 'chisq.test' performs chi-squared contingency table tests and\n goodness-of-fit tests.\nUsage:\n chisq.test(x, y = NULL, correct = TRUE,\n            p = rep(1/length(x), length(x)), rescale.p = FALSE,\n            simulate.p.value = FALSE, B = 2000)\n \nArguments:\n   x: a numeric vector or matrix. 'x' and 'y' can also both be\n      factors.\n\n   y: a numeric vector; ignored if 'x' is a matrix.  If 'x' is a\n      factor, 'y' should be a factor of the same length.\ncorrect: a logical indicating whether to apply continuity correction when computing the test statistic for 2 by 2 tables: one half is subtracted from all |O - E| differences; however, the correction will not be bigger than the differences themselves. No correction is done if ‘simulate.p.value = TRUE’.\n   p: a vector of probabilities of the same length as 'x'.  An\n      error is given if any entry of 'p' is negative.\nrescale.p: a logical scalar; if TRUE then ‘p’ is rescaled (if necessary) to sum to 1. If ‘rescale.p’ is FALSE, and ‘p’ does not sum to 1, an error is given.\nsimulate.p.value: a logical indicating whether to compute p-values by Monte Carlo simulation.\n   B: an integer specifying the number of replicates used in the\n      Monte Carlo test.\nDetails:\n If 'x' is a matrix with one row or column, or if 'x' is a vector\n and 'y' is not given, then a _goodness-of-fit test_ is performed\n ('x' is treated as a one-dimensional contingency table).  The\n entries of 'x' must be non-negative integers.  In this case, the\n hypothesis tested is whether the population probabilities equal\n those in 'p', or are all equal if 'p' is not given.\n\n If 'x' is a matrix with at least two rows and columns, it is taken\n as a two-dimensional contingency table: the entries of 'x' must be\n non-negative integers.  Otherwise, 'x' and 'y' must be vectors or\n factors of the same length; cases with missing values are removed,\n the objects are coerced to factors, and the contingency table is\n computed from these.  Then Pearson's chi-squared test is performed\n of the null hypothesis that the joint distribution of the cell\n counts in a 2-dimensional contingency table is the product of the\n row and column marginals.\n\n If 'simulate.p.value' is 'FALSE', the p-value is computed from the\n asymptotic chi-squared distribution of the test statistic;\n continuity correction is only used in the 2-by-2 case (if\n 'correct' is 'TRUE', the default).  Otherwise the p-value is\n computed for a Monte Carlo test (Hope, 1968) with 'B' replicates.\n The default 'B = 2000' implies a minimum p-value of about 0.0005\n (1/(B+1)).\n\n In the contingency table case, simulation is done by random\n sampling from the set of all contingency tables with given\n marginals, and works only if the marginals are strictly positive.\n Continuity correction is never used, and the statistic is quoted\n without it.  Note that this is not the usual sampling situation\n assumed for the chi-squared test but rather that for Fisher's\n exact test.\n\n In the goodness-of-fit case simulation is done by random sampling\n from the discrete distribution specified by 'p', each sample being\n of size 'n = sum(x)'.  This simulation is done in R and may be\n slow.\nValue:\n A list with class '\"htest\"' containing the following components:\nstatistic: the value the chi-squared test statistic.\nparameter: the degrees of freedom of the approximate chi-squared distribution of the test statistic, ‘NA’ if the p-value is computed by Monte Carlo simulation.\np.value: the p-value for the test.\nmethod: a character string indicating the type of test performed, and whether Monte Carlo simulation or continuity correction was used.\ndata.name: a character string giving the name(s) of the data.\nobserved: the observed counts.\nexpected: the expected counts under the null hypothesis.\nresiduals: the Pearson residuals, ‘(observed - expected) / sqrt(expected)’.\nstdres: standardized residuals, ‘(observed - expected) / sqrt(V)’, where ‘V’ is the residual cell variance (Agresti, 2007, section 2.4.5 for the case where ‘x’ is a matrix, ‘n * p * (1 - p)’ otherwise).\nSource:\n The code for Monte Carlo simulation is a C translation of the\n Fortran algorithm of Patefield (1981).\nReferences:\n Hope, A. C. A. (1968).  A simplified Monte Carlo significance test\n procedure.  _Journal of the Royal Statistical Society Series B_,\n *30*, 582-598.  doi:10.1111/j.2517-6161.1968.tb00759.x\n &lt;https://doi.org/10.1111/j.2517-6161.1968.tb00759.x&gt;.\n\n Patefield, W. M. (1981).  Algorithm AS 159: An efficient method of\n generating r x c tables with given row and column totals.\n _Applied Statistics_, *30*, 91-97.  doi:10.2307/2346669\n &lt;https://doi.org/10.2307/2346669&gt;.\n\n Agresti, A. (2007).  _An Introduction to Categorical Data\n Analysis_, 2nd ed.  New York: John Wiley & Sons.  Page 38.\nSee Also:\n For goodness-of-fit testing, notably of continuous distributions,\n 'ks.test'.\nExamples:\n ## From Agresti(2007) p.39\n M &lt;- as.table(rbind(c(762, 327, 468), c(484, 239, 477)))\n dimnames(M) &lt;- list(gender = c(\"F\", \"M\"),\n                     party = c(\"Democrat\",\"Independent\", \"Republican\"))\n (Xsq &lt;- chisq.test(M))  # Prints test summary\n Xsq$observed   # observed counts (same as M)\n Xsq$expected   # expected counts under the null\n Xsq$residuals  # Pearson residuals\n Xsq$stdres     # standardized residuals\n \n \n ## Effect of simulating p-values\n x &lt;- matrix(c(12, 5, 7, 7), ncol = 2)\n chisq.test(x)$p.value           # 0.4233\n chisq.test(x, simulate.p.value = TRUE, B = 10000)$p.value\n                                 # around 0.29!\n \n ## Testing for population probabilities\n ## Case A. Tabulated data\n x &lt;- c(A = 20, B = 15, C = 25)\n chisq.test(x)\n chisq.test(as.table(x))             # the same\n x &lt;- c(89,37,30,28,2)\n p &lt;- c(40,20,20,15,5)\n try(\n chisq.test(x, p = p)                # gives an error\n )\n chisq.test(x, p = p, rescale.p = TRUE)\n                                 # works\n p &lt;- c(0.40,0.20,0.20,0.19,0.01)\n                                 # Expected count in category 5\n                                 # is 1.86 &lt; 5 ==&gt; chi square approx.\n chisq.test(x, p = p)            #               maybe doubtful, but is ok!\n chisq.test(x, p = p, simulate.p.value = TRUE)\n \n ## Case B. Raw data\n x &lt;- trunc(5 * runif(100))\n chisq.test(table(x))            # NOT 'chisq.test(x)'!",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#chi-square-test-1",
    "href": "modules/Module09-DataAnalysis.html#chi-square-test-1",
    "title": "Module 9: Data Analysis",
    "section": "Chi-Square test",
    "text": "Chi-Square test\n\nchisq.test(freq)\n\n\n    Pearson's Chi-squared test\n\ndata:  freq\nX-squared = 175.85, df = 2, p-value &lt; 2.2e-16\n\n\nWe reject the null hypothesis that the proportion of seropositive individuals in the young, middle, and old age groups are the same.",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#correlation",
    "href": "modules/Module09-DataAnalysis.html#correlation",
    "title": "Module 9: Data Analysis",
    "section": "Correlation",
    "text": "Correlation\nFirst, we compute correlation by providing two vectors.\nLike other functions, if there are NAs, you get NA as the result. But if you specify use only the complete observations, then it will give you correlation using the non-missing data.\n\ncor(df$age, df$IgG_concentration, method=\"pearson\")\n\n[1] NA\n\ncor(df$age, df$IgG_concentration, method=\"pearson\", use = \"complete.obs\") #IF have missing data\n\n[1] 0.2604783\n\n\nSmall positive correlation between IgG concentration and age.",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#correlation-confidence-interval",
    "href": "modules/Module09-DataAnalysis.html#correlation-confidence-interval",
    "title": "Module 9: Data Analysis",
    "section": "Correlation confidence interval",
    "text": "Correlation confidence interval\nThe function cor.test() also gives you the confidence interval of the correlation statistic. Note, it uses complete observations by default.\n\ncor.test(df$age, df$IgG_concentration, method=\"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  df$age and df$IgG_concentration\nt = 6.7717, df = 630, p-value = 2.921e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.1862722 0.3317295\nsample estimates:\n      cor \n0.2604783",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#t-test",
    "href": "modules/Module09-DataAnalysis.html#t-test",
    "title": "Module 9: Data Analysis",
    "section": "T-test",
    "text": "T-test\nThe commonly used are:\n\none-sample t-test – used to test mean of a variable in one group (to the null hypothesis mean)\ntwo-sample t-test – used to test difference in means of a variable between two groups (null hypothesis - the group means are the same)",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#t-test-1",
    "href": "modules/Module09-DataAnalysis.html#t-test-1",
    "title": "Module 9: Data Analysis",
    "section": "T-test",
    "text": "T-test\nWe can use the t.test() function from the stats package.\n\n?t.test\n\nStudent’s t-Test\nDescription:\n Performs one and two sample t-tests on vectors of data.\nUsage:\n t.test(x, ...)\n \n ## Default S3 method:\n t.test(x, y = NULL,\n        alternative = c(\"two.sided\", \"less\", \"greater\"),\n        mu = 0, paired = FALSE, var.equal = FALSE,\n        conf.level = 0.95, ...)\n \n ## S3 method for class 'formula'\n t.test(formula, data, subset, na.action, ...)\n \nArguments:\n   x: a (non-empty) numeric vector of data values.\n\n   y: an optional (non-empty) numeric vector of data values.\nalternative: a character string specifying the alternative hypothesis, must be one of ‘“two.sided”’ (default), ‘“greater”’ or ‘“less”’. You can specify just the initial letter.\n  mu: a number indicating the true value of the mean (or difference\n      in means if you are performing a two sample test).\npaired: a logical indicating whether you want a paired t-test.\nvar.equal: a logical variable indicating whether to treat the two variances as being equal. If ‘TRUE’ then the pooled variance is used to estimate the variance otherwise the Welch (or Satterthwaite) approximation to the degrees of freedom is used.\nconf.level: confidence level of the interval.\nformula: a formula of the form ‘lhs ~ rhs’ where ‘lhs’ is a numeric variable giving the data values and ‘rhs’ either ‘1’ for a one-sample or paired test or a factor with two levels giving the corresponding groups. If ‘lhs’ is of class ‘“Pair”’ and ‘rhs’ is ‘1’, a paired test is done.\ndata: an optional matrix or data frame (or similar: see\n      'model.frame') containing the variables in the formula\n      'formula'.  By default the variables are taken from\n      'environment(formula)'.\nsubset: an optional vector specifying a subset of observations to be used.\nna.action: a function which indicates what should happen when the data contain ‘NA’s. Defaults to ’getOption(“na.action”)’.\n ...: further arguments to be passed to or from methods.\nDetails:\n 'alternative = \"greater\"' is the alternative that 'x' has a larger\n mean than 'y'. For the one-sample case: that the mean is positive.\n\n If 'paired' is 'TRUE' then both 'x' and 'y' must be specified and\n they must be the same length.  Missing values are silently removed\n (in pairs if 'paired' is 'TRUE').  If 'var.equal' is 'TRUE' then\n the pooled estimate of the variance is used.  By default, if\n 'var.equal' is 'FALSE' then the variance is estimated separately\n for both groups and the Welch modification to the degrees of\n freedom is used.\n\n If the input data are effectively constant (compared to the larger\n of the two means) an error is generated.\nValue:\n A list with class '\"htest\"' containing the following components:\nstatistic: the value of the t-statistic.\nparameter: the degrees of freedom for the t-statistic.\np.value: the p-value for the test.\nconf.int: a confidence interval for the mean appropriate to the specified alternative hypothesis.\nestimate: the estimated mean or difference in means depending on whether it was a one-sample test or a two-sample test.\nnull.value: the specified hypothesized value of the mean or mean difference depending on whether it was a one-sample test or a two-sample test.\nstderr: the standard error of the mean (difference), used as denominator in the t-statistic formula.\nalternative: a character string describing the alternative hypothesis.\nmethod: a character string indicating what type of t-test was performed.\ndata.name: a character string giving the name(s) of the data.\nSee Also:\n 'prop.test'\nExamples:\n require(graphics)\n \n t.test(1:10, y = c(7:20))      # P = .00001855\n t.test(1:10, y = c(7:20, 200)) # P = .1245    -- NOT significant anymore\n \n ## Classical example: Student's sleep data\n plot(extra ~ group, data = sleep)\n ## Traditional interface\n with(sleep, t.test(extra[group == 1], extra[group == 2]))\n \n ## Formula interface\n t.test(extra ~ group, data = sleep)\n \n ## Formula interface to one-sample test\n t.test(extra ~ 1, data = sleep)\n \n ## Formula interface to paired test\n ## The sleep data are actually paired, so could have been in wide format:\n sleep2 &lt;- reshape(sleep, direction = \"wide\", \n                   idvar = \"ID\", timevar = \"group\")\n t.test(Pair(extra.1, extra.2) ~ 1, data = sleep2)",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#running-two-sample-t-test",
    "href": "modules/Module09-DataAnalysis.html#running-two-sample-t-test",
    "title": "Module 9: Data Analysis",
    "section": "Running two-sample t-test",
    "text": "Running two-sample t-test\nThe base R - t.test() function from the stats package. It tests test difference in means of a variable between two groups. By default:\n\ntests whether difference in means of a variable is equal to 0 (default mu=0)\nuses “two sided” alternative (alternative = \"two.sided\")\nreturns result assuming confidence level 0.95 (conf.level = 0.95)\nassumes data are not paired (paired = FALSE)\nassumes true variance in the two groups is not equal (var.equal = FALSE)",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#running-two-sample-t-test-1",
    "href": "modules/Module09-DataAnalysis.html#running-two-sample-t-test-1",
    "title": "Module 9: Data Analysis",
    "section": "Running two-sample t-test",
    "text": "Running two-sample t-test\n\nIgG_young &lt;- df$IgG_concentration[df$age_group==\"young\"]\nIgG_old &lt;- df$IgG_concentration[df$age_group==\"old\"]\n\nt.test(IgG_young, IgG_old)\n\n\n    Welch Two Sample t-test\n\ndata:  IgG_young and IgG_old\nt = -6.1969, df = 259.54, p-value = 2.25e-09\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -111.09281  -57.51515\nsample estimates:\nmean of x mean of y \n 45.05056 129.35454 \n\n\nThe mean IgG concenration of young and old is 45.05 and 129.35 IU/mL, respectively. We reject null hypothesis that the difference in the mean IgG concentration of young and old is 0 IU/mL.",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#linear-regression-fit-in-r",
    "href": "modules/Module09-DataAnalysis.html#linear-regression-fit-in-r",
    "title": "Module 9: Data Analysis",
    "section": "Linear regression fit in R",
    "text": "Linear regression fit in R\nTo fit regression models in R, we use the function glm() (Generalized Linear Model).\n\n?glm\n\nFitting Generalized Linear Models\nDescription:\n 'glm' is used to fit generalized linear models, specified by\n giving a symbolic description of the linear predictor and a\n description of the error distribution.\nUsage:\n glm(formula, family = gaussian, data, weights, subset,\n     na.action, start = NULL, etastart, mustart, offset,\n     control = list(...), model = TRUE, method = \"glm.fit\",\n     x = FALSE, y = TRUE, singular.ok = TRUE, contrasts = NULL, ...)\n \n glm.fit(x, y, weights = rep.int(1, nobs),\n         start = NULL, etastart = NULL, mustart = NULL,\n         offset = rep.int(0, nobs), family = gaussian(),\n         control = list(), intercept = TRUE, singular.ok = TRUE)\n \n ## S3 method for class 'glm'\n weights(object, type = c(\"prior\", \"working\"), ...)\n \nArguments:\nformula: an object of class ‘“formula”’ (or one that can be coerced to that class): a symbolic description of the model to be fitted. The details of model specification are given under ‘Details’.\nfamily: a description of the error distribution and link function to be used in the model. For ‘glm’ this can be a character string naming a family function, a family function or the result of a call to a family function. For ‘glm.fit’ only the third option is supported. (See ‘family’ for details of family functions.)\ndata: an optional data frame, list or environment (or object\n      coercible by 'as.data.frame' to a data frame) containing the\n      variables in the model.  If not found in 'data', the\n      variables are taken from 'environment(formula)', typically\n      the environment from which 'glm' is called.\nweights: an optional vector of ‘prior weights’ to be used in the fitting process. Should be ‘NULL’ or a numeric vector.\nsubset: an optional vector specifying a subset of observations to be used in the fitting process.\nna.action: a function which indicates what should happen when the data contain ‘NA’s. The default is set by the ’na.action’ setting of ‘options’, and is ‘na.fail’ if that is unset. The ‘factory-fresh’ default is ‘na.omit’. Another possible value is ‘NULL’, no action. Value ‘na.exclude’ can be useful.\nstart: starting values for the parameters in the linear predictor.\netastart: starting values for the linear predictor.\nmustart: starting values for the vector of means.\noffset: this can be used to specify an a priori known component to be included in the linear predictor during fitting. This should be ‘NULL’ or a numeric vector of length equal to the number of cases. One or more ‘offset’ terms can be included in the formula instead or as well, and if more than one is specified their sum is used. See ‘model.offset’.\ncontrol: a list of parameters for controlling the fitting process. For ‘glm.fit’ this is passed to ‘glm.control’.\nmodel: a logical value indicating whether model frame should be included as a component of the returned value.\nmethod: the method to be used in fitting the model. The default method ‘“glm.fit”’ uses iteratively reweighted least squares (IWLS): the alternative ‘“model.frame”’ returns the model frame and does no fitting.\n      User-supplied fitting functions can be supplied either as a\n      function or a character string naming a function, with a\n      function which takes the same arguments as 'glm.fit'.  If\n      specified as a character string it is looked up from within\n      the 'stats' namespace.\n\nx, y: For 'glm': logical values indicating whether the response\n      vector and model matrix used in the fitting process should be\n      returned as components of the returned value.\n\n      For 'glm.fit': 'x' is a design matrix of dimension 'n * p',\n      and 'y' is a vector of observations of length 'n'.\nsingular.ok: logical; if ‘FALSE’ a singular fit is an error.\ncontrasts: an optional list. See the ‘contrasts.arg’ of ‘model.matrix.default’.\nintercept: logical. Should an intercept be included in the null model?\nobject: an object inheriting from class ‘“glm”’.\ntype: character, partial matching allowed.  Type of weights to\n      extract from the fitted model object.  Can be abbreviated.\n\n ...: For 'glm': arguments to be used to form the default 'control'\n      argument if it is not supplied directly.\n\n      For 'weights': further arguments passed to or from other\n      methods.\nDetails:\n A typical predictor has the form 'response ~ terms' where\n 'response' is the (numeric) response vector and 'terms' is a\n series of terms which specifies a linear predictor for 'response'.\n For 'binomial' and 'quasibinomial' families the response can also\n be specified as a 'factor' (when the first level denotes failure\n and all others success) or as a two-column matrix with the columns\n giving the numbers of successes and failures.  A terms\n specification of the form 'first + second' indicates all the terms\n in 'first' together with all the terms in 'second' with any\n duplicates removed.\n\n A specification of the form 'first:second' indicates the set of\n terms obtained by taking the interactions of all terms in 'first'\n with all terms in 'second'.  The specification 'first*second'\n indicates the _cross_ of 'first' and 'second'.  This is the same\n as 'first + second + first:second'.\n\n The terms in the formula will be re-ordered so that main effects\n come first, followed by the interactions, all second-order, all\n third-order and so on: to avoid this pass a 'terms' object as the\n formula.\n\n Non-'NULL' 'weights' can be used to indicate that different\n observations have different dispersions (with the values in\n 'weights' being inversely proportional to the dispersions); or\n equivalently, when the elements of 'weights' are positive integers\n w_i, that each response y_i is the mean of w_i unit-weight\n observations.  For a binomial GLM prior weights are used to give\n the number of trials when the response is the proportion of\n successes: they would rarely be used for a Poisson GLM.\n\n 'glm.fit' is the workhorse function: it is not normally called\n directly but can be more efficient where the response vector,\n design matrix and family have already been calculated.\n\n If more than one of 'etastart', 'start' and 'mustart' is\n specified, the first in the list will be used.  It is often\n advisable to supply starting values for a 'quasi' family, and also\n for families with unusual links such as 'gaussian(\"log\")'.\n\n All of 'weights', 'subset', 'offset', 'etastart' and 'mustart' are\n evaluated in the same way as variables in 'formula', that is first\n in 'data' and then in the environment of 'formula'.\n\n For the background to warning messages about 'fitted probabilities\n numerically 0 or 1 occurred' for binomial GLMs, see Venables &\n Ripley (2002, pp. 197-8).\nValue:\n 'glm' returns an object of class inheriting from '\"glm\"' which\n inherits from the class '\"lm\"'. See later in this section.  If a\n non-standard 'method' is used, the object will also inherit from\n the class (if any) returned by that function.\n\n The function 'summary' (i.e., 'summary.glm') can be used to obtain\n or print a summary of the results and the function 'anova' (i.e.,\n 'anova.glm') to produce an analysis of variance table.\n\n The generic accessor functions 'coefficients', 'effects',\n 'fitted.values' and 'residuals' can be used to extract various\n useful features of the value returned by 'glm'.\n\n 'weights' extracts a vector of weights, one for each case in the\n fit (after subsetting and 'na.action').\n\n An object of class '\"glm\"' is a list containing at least the\n following components:\ncoefficients: a named vector of coefficients\nresiduals: the working residuals, that is the residuals in the final iteration of the IWLS fit. Since cases with zero weights are omitted, their working residuals are ‘NA’.\nfitted.values: the fitted mean values, obtained by transforming the linear predictors by the inverse of the link function.\nrank: the numeric rank of the fitted linear model.\nfamily: the ‘family’ object used.\nlinear.predictors: the linear fit on link scale.\ndeviance: up to a constant, minus twice the maximized log-likelihood. Where sensible, the constant is chosen so that a saturated model has deviance zero.\n aic: A version of Akaike's _An Information Criterion_, minus twice\n      the maximized log-likelihood plus twice the number of\n      parameters, computed via the 'aic' component of the family.\n      For binomial and Poison families the dispersion is fixed at\n      one and the number of parameters is the number of\n      coefficients.  For gaussian, Gamma and inverse gaussian\n      families the dispersion is estimated from the residual\n      deviance, and the number of parameters is the number of\n      coefficients plus one.  For a gaussian family the MLE of the\n      dispersion is used so this is a valid value of AIC, but for\n      Gamma and inverse gaussian families it is not.  For families\n      fitted by quasi-likelihood the value is 'NA'.\nnull.deviance: The deviance for the null model, comparable with ‘deviance’. The null model will include the offset, and an intercept if there is one in the model. Note that this will be incorrect if the link function depends on the data other than through the fitted mean: specify a zero offset to force a correct calculation.\niter: the number of iterations of IWLS used.\nweights: the working weights, that is the weights in the final iteration of the IWLS fit.\nprior.weights: the weights initially supplied, a vector of ’1’s if none were.\ndf.residual: the residual degrees of freedom.\ndf.null: the residual degrees of freedom for the null model.\n   y: if requested (the default) the 'y' vector used. (It is a\n      vector even for a binomial model.)\n\n   x: if requested, the model matrix.\nmodel: if requested (the default), the model frame.\nconverged: logical. Was the IWLS algorithm judged to have converged?\nboundary: logical. Is the fitted value on the boundary of the attainable values?\ncall: the matched call.\nformula: the formula supplied.\nterms: the ‘terms’ object used.\ndata: the 'data argument'.\noffset: the offset vector used.\ncontrol: the value of the ‘control’ argument used.\nmethod: the name of the fitter function used (when provided as a ‘character’ string to ‘glm()’) or the fitter ‘function’ (when provided as that).\ncontrasts: (where relevant) the contrasts used.\nxlevels: (where relevant) a record of the levels of the factors used in fitting.\nna.action: (where relevant) information returned by ‘model.frame’ on the special handling of ’NA’s.\n In addition, non-empty fits will have components 'qr', 'R' and\n 'effects' relating to the final weighted linear fit.\n\n Objects of class '\"glm\"' are normally of class 'c(\"glm\", \"lm\")',\n that is inherit from class '\"lm\"', and well-designed methods for\n class '\"lm\"' will be applied to the weighted linear model at the\n final iteration of IWLS.  However, care is needed, as extractor\n functions for class '\"glm\"' such as 'residuals' and 'weights' do\n *not* just pick out the component of the fit with the same name.\n\n If a 'binomial' 'glm' model was specified by giving a two-column\n response, the weights returned by 'prior.weights' are the total\n numbers of cases (factored by the supplied case weights) and the\n component 'y' of the result is the proportion of successes.\nFitting functions:\n The argument 'method' serves two purposes.  One is to allow the\n model frame to be recreated with no fitting.  The other is to\n allow the default fitting function 'glm.fit' to be replaced by a\n function which takes the same arguments and uses a different\n fitting algorithm.  If 'glm.fit' is supplied as a character string\n it is used to search for a function of that name, starting in the\n 'stats' namespace.\n\n The class of the object return by the fitter (if any) will be\n prepended to the class returned by 'glm'.\nAuthor(s):\n The original R implementation of 'glm' was written by Simon Davies\n working for Ross Ihaka at the University of Auckland, but has\n since been extensively re-written by members of the R Core team.\n\n The design was inspired by the S function of the same name\n described in Hastie & Pregibon (1992).\nReferences:\n Dobson, A. J. (1990) _An Introduction to Generalized Linear\n Models._ London: Chapman and Hall.\n\n Hastie, T. J. and Pregibon, D. (1992) _Generalized linear models._\n Chapter 6 of _Statistical Models in S_ eds J. M. Chambers and T.\n J. Hastie, Wadsworth & Brooks/Cole.\n\n McCullagh P. and Nelder, J. A. (1989) _Generalized Linear Models._\n London: Chapman and Hall.\n\n Venables, W. N. and Ripley, B. D. (2002) _Modern Applied\n Statistics with S._ New York: Springer.\nSee Also:\n 'anova.glm', 'summary.glm', etc. for 'glm' methods, and the\n generic functions 'anova', 'summary', 'effects', 'fitted.values',\n and 'residuals'.\n\n 'lm' for non-generalized _linear_ models (which SAS calls GLMs,\n for 'general' linear models).\n\n 'loglin' and 'loglm' (package 'MASS') for fitting log-linear\n models (which binomial and Poisson GLMs are) to contingency\n tables.\n\n 'bigglm' in package 'biglm' for an alternative way to fit GLMs to\n large datasets (especially those with many cases).\n\n 'esoph', 'infert' and 'predict.glm' have examples of fitting\n binomial glms.\nExamples:\n ## Dobson (1990) Page 93: Randomized Controlled Trial :\n counts &lt;- c(18,17,15,20,10,20,25,13,12)\n outcome &lt;- gl(3,1,9)\n treatment &lt;- gl(3,3)\n data.frame(treatment, outcome, counts) # showing data\n glm.D93 &lt;- glm(counts ~ outcome + treatment, family = poisson())\n anova(glm.D93)\n summary(glm.D93)\n ## Computing AIC [in many ways]:\n (A0 &lt;- AIC(glm.D93))\n (ll &lt;- logLik(glm.D93))\n A1 &lt;- -2*c(ll) + 2*attr(ll, \"df\")\n A2 &lt;- glm.D93$family$aic(counts, mu=fitted(glm.D93), wt=1) +\n         2 * length(coef(glm.D93))\n stopifnot(exprs = {\n   all.equal(A0, A1)\n   all.equal(A1, A2)\n   all.equal(A1, glm.D93$aic)\n })\n \n \n ## an example with offsets from Venables & Ripley (2002, p.189)\n utils::data(anorexia, package = \"MASS\")\n \n anorex.1 &lt;- glm(Postwt ~ Prewt + Treat + offset(Prewt),\n                 family = gaussian, data = anorexia)\n summary(anorex.1)\n \n \n # A Gamma example, from McCullagh & Nelder (1989, pp. 300-2)\n clotting &lt;- data.frame(\n     u = c(5,10,15,20,30,40,60,80,100),\n     lot1 = c(118,58,42,35,27,25,21,19,18),\n     lot2 = c(69,35,26,21,18,16,13,12,12))\n summary(glm(lot1 ~ log(u), data = clotting, family = Gamma))\n summary(glm(lot2 ~ log(u), data = clotting, family = Gamma))\n ## Aliased (\"S\"ingular) -&gt; 1 NA coefficient\n (fS &lt;- glm(lot2 ~ log(u) + log(u^2), data = clotting, family = Gamma))\n tools::assertError(update(fS, singular.ok=FALSE), verbose=interactive())\n ## -&gt; .. \"singular fit encountered\"\n \n ## Not run:\n \n ## for an example of the use of a terms object as a formula\n demo(glm.vr)\n ## End(Not run)",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#linear-regression-fit-in-r-1",
    "href": "modules/Module09-DataAnalysis.html#linear-regression-fit-in-r-1",
    "title": "Module 9: Data Analysis",
    "section": "Linear regression fit in R",
    "text": "Linear regression fit in R\nWe tend to focus on three arguments:\n\nformula – model formula written using names of columns in our data\ndata – our data frame\nfamily – error distribution and link function\n\n\nfit1 &lt;- glm(IgG_concentration~age+gender+slum, data=df, family=gaussian())\nfit2 &lt;- glm(seropos~age_group+gender+slum, data=df, family = binomial(link = \"logit\"))",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#summary.glm",
    "href": "modules/Module09-DataAnalysis.html#summary.glm",
    "title": "Module 9: Data Analysis",
    "section": "summary.glm()",
    "text": "summary.glm()\nThe summary() function when applied to a fit object based on a glm is technically the summary.glm() function and produces details of the model fit. Note on object oriented code.\n\nSummarizing Generalized Linear Model Fits\nDescription:\n These functions are all 'methods' for class 'glm' or 'summary.glm'\n objects.\nUsage:\n ## S3 method for class 'glm'\n summary(object, dispersion = NULL, correlation = FALSE,\n         symbolic.cor = FALSE, ...)\n \n ## S3 method for class 'summary.glm'\n print(x, digits = max(3, getOption(\"digits\") - 3),\n       symbolic.cor = x$symbolic.cor,\n       signif.stars = getOption(\"show.signif.stars\"),\n       show.residuals = FALSE, ...)\n \nArguments:\nobject: an object of class ‘“glm”’, usually, a result of a call to ‘glm’.\n   x: an object of class '\"summary.glm\"', usually, a result of a\n      call to 'summary.glm'.\ndispersion: the dispersion parameter for the family used. Either a single numerical value or ‘NULL’ (the default), when it is inferred from ‘object’ (see ‘Details’).\ncorrelation: logical; if ‘TRUE’, the correlation matrix of the estimated parameters is returned and printed.\ndigits: the number of significant digits to use when printing.\nsymbolic.cor: logical. If ‘TRUE’, print the correlations in a symbolic form (see ‘symnum’) rather than as numbers.\nsignif.stars: logical. If ‘TRUE’, ‘significance stars’ are printed for each coefficient.\nshow.residuals: logical. If ‘TRUE’ then a summary of the deviance residuals is printed at the head of the output.\n ...: further arguments passed to or from other methods.\nDetails:\n 'print.summary.glm' tries to be smart about formatting the\n coefficients, standard errors, etc. and additionally gives\n 'significance stars' if 'signif.stars' is 'TRUE'.  The\n 'coefficients' component of the result gives the estimated\n coefficients and their estimated standard errors, together with\n their ratio.  This third column is labelled 't ratio' if the\n dispersion is estimated, and 'z ratio' if the dispersion is known\n (or fixed by the family).  A fourth column gives the two-tailed\n p-value corresponding to the t or z ratio based on a Student t or\n Normal reference distribution.  (It is possible that the\n dispersion is not known and there are no residual degrees of\n freedom from which to estimate it.  In that case the estimate is\n 'NaN'.)\n\n Aliased coefficients are omitted in the returned object but\n restored by the 'print' method.\n\n Correlations are printed to two decimal places (or symbolically):\n to see the actual correlations print 'summary(object)$correlation'\n directly.\n\n The dispersion of a GLM is not used in the fitting process, but it\n is needed to find standard errors.  If 'dispersion' is not\n supplied or 'NULL', the dispersion is taken as '1' for the\n 'binomial' and 'Poisson' families, and otherwise estimated by the\n residual Chisquared statistic (calculated from cases with non-zero\n weights) divided by the residual degrees of freedom.\n\n 'summary' can be used with Gaussian 'glm' fits to handle the case\n of a linear regression with known error variance, something not\n handled by 'summary.lm'.\nValue:\n 'summary.glm' returns an object of class '\"summary.glm\"', a list\n with components\n\ncall: the component from 'object'.\nfamily: the component from ‘object’.\ndeviance: the component from ‘object’.\ncontrasts: the component from ‘object’.\ndf.residual: the component from ‘object’.\nnull.deviance: the component from ‘object’.\ndf.null: the component from ‘object’.\ndeviance.resid: the deviance residuals: see ‘residuals.glm’.\ncoefficients: the matrix of coefficients, standard errors, z-values and p-values. Aliased coefficients are omitted.\naliased: named logical vector showing if the original coefficients are aliased.\ndispersion: either the supplied argument or the inferred/estimated dispersion if the former is ‘NULL’.\n  df: a 3-vector of the rank of the model and the number of\n      residual degrees of freedom, plus number of coefficients\n      (including aliased ones).\ncov.unscaled: the unscaled (‘dispersion = 1’) estimated covariance matrix of the estimated coefficients.\ncov.scaled: ditto, scaled by ‘dispersion’.\ncorrelation: (only if ‘correlation’ is true.) The estimated correlations of the estimated coefficients.\nsymbolic.cor: (only if ‘correlation’ is true.) The value of the argument ‘symbolic.cor’.\nSee Also:\n 'glm', 'summary'.\nExamples:\n ## For examples see example(glm)",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#linear-regression-fit-in-r-2",
    "href": "modules/Module09-DataAnalysis.html#linear-regression-fit-in-r-2",
    "title": "Module 9: Data Analysis",
    "section": "Linear regression fit in R",
    "text": "Linear regression fit in R\nLets look at the output…\n\nsummary(fit1)\n\n\nCall:\nglm(formula = IgG_concentration ~ age + gender + slum, family = gaussian(), \n    data = df)\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    46.132     16.774   2.750  0.00613 ** \nage             9.324      1.388   6.718 4.15e-11 ***\ngenderMale     -9.655     11.543  -0.836  0.40321    \nslumNon slum  -20.353     14.299  -1.423  0.15513    \nslumSlum      -29.705     25.009  -1.188  0.23536    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 20918.39)\n\n    Null deviance: 14141483  on 631  degrees of freedom\nResidual deviance: 13115831  on 627  degrees of freedom\n  (19 observations deleted due to missingness)\nAIC: 8087.9\n\nNumber of Fisher Scoring iterations: 2\n\nsummary(fit2)\n\n\nCall:\nglm(formula = seropos ~ age_group + gender + slum, family = binomial(link = \"logit\"), \n    data = df)\n\nCoefficients:\n                Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)      -1.3220     0.2516  -5.254 1.49e-07 ***\nage_groupmiddle   1.9020     0.2133   8.916  &lt; 2e-16 ***\nage_groupold      2.8443     0.2522  11.278  &lt; 2e-16 ***\ngenderMale       -0.1725     0.1895  -0.910    0.363    \nslumNon slum     -0.1099     0.2329  -0.472    0.637    \nslumSlum         -0.1073     0.4118  -0.261    0.794    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 866.98  on 631  degrees of freedom\nResidual deviance: 679.10  on 626  degrees of freedom\n  (19 observations deleted due to missingness)\nAIC: 691.1\n\nNumber of Fisher Scoring iterations: 4",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#summary",
    "href": "modules/Module09-DataAnalysis.html#summary",
    "title": "Module 9: Data Analysis",
    "section": "Summary",
    "text": "Summary\n\nthe aggregate() function can be used to conduct analyses across groups (i.e., categorical variables in the data(\nthe table() function can generate frequency tables for 2 plus variables, but to get percentage tables, the prop.table() is useful\nthe chisq.test() function tests independence of factor variables\nthe cor() or cor.test() functions can be used to calculate correlation between two numeric vectors\nthe t.test() functions conducts one and two sample (paired or unpaired) t-tests\nthe function glm() fits generalized linear modules to data and returns a fit object that can be read with the summary() function\nchanging the family argument in the glm() function allows you to fit models with different link functions",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module09-DataAnalysis.html#acknowledgements",
    "href": "modules/Module09-DataAnalysis.html#acknowledgements",
    "title": "Module 9: Data Analysis",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese are the materials we looked through, modified, or extracted to complete this module’s lecture.\n\n“Introduction to R for Public Health Researchers” Johns Hopkins University",
    "crumbs": [
      "Day 2",
      "Module 9: Data Analysis"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#learning-objectives",
    "href": "modules/Module01-Intro.html#learning-objectives",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter module 1, you should be able to…\n\nCreate and save an R script\nDescribe the utility and differences b/w the Console and the Source panes\nModify R Studio panes\nCreate objects\nDescribe the difference b/w character, numeric, list, and matrix objects\nReference objects in the RStudio Environment pane\nUse basic arithmetic operators in R\nUse comments within an R script to create header, sections, and make notes",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#working-with-r-rstudio",
    "href": "modules/Module01-Intro.html#working-with-r-rstudio",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Working with R – RStudio",
    "text": "Working with R – RStudio\nRStudio is an Integrated Development Environment (IDE) for R\n\nIt helps the user effectively use R\nMakes things easier\nIs NOT a dropdown statistical tool (such as Stata)\n\nSee jamovi or also Rcmdr, Radiant",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#rstudio",
    "href": "modules/Module01-Intro.html#rstudio",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "RStudio",
    "text": "RStudio\nEasier working with R\n\nSyntax highlighting, code completion, and smart indentation\nEasily manage multiple working directories and projects\n\nMore information\n\nWorkspace browser and data viewer\nPlot history, zooming, and flexible image and file export\nIntegrated R help and documentation\nSearchable command history",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#rstudio-1",
    "href": "modules/Module01-Intro.html#rstudio-1",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "RStudio",
    "text": "RStudio",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#getting-the-editor",
    "href": "modules/Module01-Intro.html#getting-the-editor",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Getting the editor",
    "text": "Getting the editor",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#working-with-r-in-rstudio---2-major-panes",
    "href": "modules/Module01-Intro.html#working-with-r-in-rstudio---2-major-panes",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Working with R in RStudio - 2 major panes:",
    "text": "Working with R in RStudio - 2 major panes:\n\nThe Source/Editor:\n\n\n\n“Analysis” Script\nStatic copy of what you did (reproducibility)\nTop by default\n\n\nThe R Console: “interprets” whatever you type:\n\n\nCalculator\nTry things out interactively, then add to your editor\nBottom by default",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#source-editor",
    "href": "modules/Module01-Intro.html#source-editor",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Source / Editor",
    "text": "Source / Editor\n\nWhere files open to\nHave R code and comments in them\nWhere code is saved",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#r-console",
    "href": "modules/Module01-Intro.html#r-console",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "R Console",
    "text": "R Console\n\nWhere code is executed (where things happen)\nYou can type here for things interactively\nCode is not saved",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#rstudio-2",
    "href": "modules/Module01-Intro.html#rstudio-2",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "RStudio",
    "text": "RStudio\nUseful RStudio “cheat sheet”: https://github.com/rstudio/cheatsheets/blob/main/rstudio-ide.pdf",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#rstudio-layout",
    "href": "modules/Module01-Intro.html#rstudio-layout",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "RStudio Layout",
    "text": "RStudio Layout\nIf RStudio doesn’t look the way you want (or like our RStudio), then do:\nIn R Studio Menu Bar go to View Menu –&gt; Panes –&gt; Pane Layout",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#workspaceenvironment",
    "href": "modules/Module01-Intro.html#workspaceenvironment",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Workspace/Environment",
    "text": "Workspace/Environment\n\nTells you what objects are in R\nWhat exists in memory/what is loaded?/what did I read in?",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#workspacehistory",
    "href": "modules/Module01-Intro.html#workspacehistory",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Workspace/History",
    "text": "Workspace/History\n\nShows previous commands. Good to look at for debugging, but don’t rely on it.\nAlso type the “up” and “down” key in the Console to scroll through previous commands",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#workspaceother-panes",
    "href": "modules/Module01-Intro.html#workspaceother-panes",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Workspace/Other Panes",
    "text": "Workspace/Other Panes\n\nFiles - shows the files on your computer of the directory you are working in\nViewer - can view data or R objects\nHelp - shows help of R commands\nPlots - pictures and figures\nPackages - list of R packages that are loaded in memory",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#getting-started",
    "href": "modules/Module01-Intro.html#getting-started",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Getting Started",
    "text": "Getting Started\n\nIn R Studio Menu Bar go to File Menu –&gt; New File –&gt; R Script\nSave the blank R script as Module1.R",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#explaining-output-on-slides",
    "href": "modules/Module01-Intro.html#explaining-output-on-slides",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Explaining output on slides",
    "text": "Explaining output on slides\nIn slides, the R command/code will be in a box, and then directly after it, will be the output of the code starting with [1]\n\nprint(\"I'm code\")\n\n[1] \"I'm code\"\n\n\nSo print(\"I'm code\") is the command and [1] \"I'm code\" is the output.\n\nCommands/code and output written as inline text will be typewriter blue font. For example code",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#r-as-a-calculator",
    "href": "modules/Module01-Intro.html#r-as-a-calculator",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "R as a calculator",
    "text": "R as a calculator\nYou can do basic arithmetic in R, which I surprisingly use all the time.\n\n2 + 2\n\n[1] 4\n\n2 * 4\n\n[1] 8\n\n2^3\n\n[1] 8",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#r-as-a-calculator-1",
    "href": "modules/Module01-Intro.html#r-as-a-calculator-1",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "R as a calculator",
    "text": "R as a calculator\n\nThe R console is a full calculator\nArithmetic operators:\n\n+, -, /, * are add, subtract, divide and multiply\n^ or ** is power\nparentheses – ( and ) – work with order of operations\n%% finds the remainder",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#execute-run-code",
    "href": "modules/Module01-Intro.html#execute-run-code",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Execute / Run Code",
    "text": "Execute / Run Code\nTo execute or run a line of code (i.e., command), you just put your cursor on the command and then:\n\nPress Run (which you will find at the top of your Console pane)\n\nOR\n\nPress Cmd + Return (iOS) OR Ctrl + Enter (Windows).\n\nTo execute or run multiple lines of code, you need to highlight the code you want to run and then follow option 1 or 2.",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#mini-exercise",
    "href": "modules/Module01-Intro.html#mini-exercise",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Mini exercise",
    "text": "Mini exercise\nExecute 5+4 from your .R file, and then find the answer 9 in the Console.",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#commenting-in-scripts",
    "href": "modules/Module01-Intro.html#commenting-in-scripts",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Commenting in Scripts",
    "text": "Commenting in Scripts\nThe syntax # creates a comment, which means anything to the right of # will not be executed / run\nCommenting is useful to:\n\nCreate headers for R Scripts\nCreate sections within an R Script\nExplain what is happening in your code",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#commenting-an-r-script-header",
    "href": "modules/Module01-Intro.html#commenting-an-r-script-header",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Commenting an R Script header",
    "text": "Commenting an R Script header\nAdd a comment header to Module1.R. This is the one I typically use, but you may have your own preference. The goal is that you are consistent so that future you / collaborators can make sense of your code.\n\n### Title: Module 1\n### Author: Amy Winter \n### Objective: Mini Exercise - Developing first R Script\n### Date: 15 July 2024",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#commenting-to-create-sections",
    "href": "modules/Module01-Intro.html#commenting-to-create-sections",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Commenting to create sections",
    "text": "Commenting to create sections\nYou can also create sections within your code by ending a comment with 4 hash marks. This is very useful for creating an outline of your R Script. The “Outline” can be found in the top right of the your Source pane\n\n# Section 1 Header ####\n## Section 2 Sub-header ####\n### Section 3 Sub-sub-header ####\n#### Section 4 Sub-sub-sub-header ####",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#commenting-to-explain-code",
    "href": "modules/Module01-Intro.html#commenting-to-explain-code",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Commenting to explain code",
    "text": "Commenting to explain code\n\n## this # is still a comment\n### you can use many #'s as you want\n\n# sometimes you have a really long comment,\n#    like explaining what you are doing\n#    for a step in analysis. \n# Take it to another line\n\nI tend to use:\n\nOne hash mark with a space to describe what is happening in the following few lines of code\nOne hash mark with no space after a command to list specifics\n\n\n# Practicing my arithmetic\n5+2\n3*5\n9/8\n\n5+2 #5 plus 2",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#object---basic-terms",
    "href": "modules/Module01-Intro.html#object---basic-terms",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Object - Basic terms",
    "text": "Object - Basic terms\nObject - an object is something that can be worked with in R - can be lots of different things!\n\na scalar / number\na vector\na matrix of numbers\na list\na plot\na function\n\n… many more",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#objects",
    "href": "modules/Module01-Intro.html#objects",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Objects",
    "text": "Objects\n\nYou can create objects from within the R environment and from files on your computer\nR uses &lt;- to assign values to an object name\nNote: Object names are case-sensitive, i.e. X and x are different\nHere are examples of creating five different objects:\n\n\nnumber.object &lt;- 3\ncharacter.object &lt;- \"blue\"\nvector.object1 &lt;- c(2,3,4,5)\nvector.object2 &lt;- paste0(c(\"b\", \"t\", \"u\"), c(8,4,2))\nmatrix.object &lt;- matrix(data=vector.object1, nrow=2, ncol=2, byrow=TRUE)\n\nNote, c(), paste0(), and matrix() are functions, which we will talk more about in module 2.",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#object-names---good-coding",
    "href": "modules/Module01-Intro.html#object-names---good-coding",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Object names - Good coding",
    "text": "Object names - Good coding\n\nIn general, any object name can be typed into R.\nHowever, only some are considered “valid”. If you use a non-valid object name, you will have to enclose it in backticks `like this` for R to recognize it.\nFrom the R documentation:\n\n\nA syntactically valid name consists of letters, numbers and the dot or underline characters and starts with a letter or the dot not followed by a number. Names such as “.2way” are not valid, and neither are the reserved words.\n\n\nReserved words: if, else, repeat, while, function, for, in, next, break, TRUE, FALSE, NULL, Inf, NaN, NA, NA_integer_, NA_real_, NA_Complex_, _NA_Character, ..., ..1, ..2, ..3, and so on.",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#object-names---good-coding-1",
    "href": "modules/Module01-Intro.html#object-names---good-coding-1",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Object names - Good coding",
    "text": "Object names - Good coding\n\n\n\nValid\nInvalid\n\n\n\n\nmy_object\nmy-data\n\n\nthe.vector\n2data\n\n\nnum12\nfor\n\n\nmeasles_data\n.9data\n\n\n.calc\nxX~mŷ_δätą~Xx",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#object-assingment---good-coding",
    "href": "modules/Module01-Intro.html#object-assingment---good-coding",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Object assingment - Good coding",
    "text": "Object assingment - Good coding\n= and &lt;- can both be used for assignment, but &lt;- is better coding practice, because sometimes = doesn’t work and we want to distinguish between the logical operator ==. We will talk about this more, later.",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#mini-exercise-1",
    "href": "modules/Module01-Intro.html#mini-exercise-1",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Mini Exercise",
    "text": "Mini Exercise\nTry creating one or two of these objects in your R script\n\nnumber.object &lt;- 3\ncharacter.object &lt;- \"blue\"\nvector.object1 &lt;- c(2,3,4,5)\nvector.object2 &lt;- paste0(c(\"b\", \"t\", \"u\"), c(8,4,2))\nmatrix.object &lt;- matrix(data=vector.object1, nrow=2, ncol=2, byrow=TRUE)",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#objects-1",
    "href": "modules/Module01-Intro.html#objects-1",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Objects",
    "text": "Objects\nNote, you can find these objects now in your Environment pane.\n\nAlso, you can print them anytime (i.e, see them in the Console) by executing (running) the object. For example,\n\ncharacter.object\n\n[1] \"blue\"\n\n\n\nmatrix.object\n\n     [,1] [,2]\n[1,]    2    3\n[2,]    4    5",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#lists",
    "href": "modules/Module01-Intro.html#lists",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Lists",
    "text": "Lists\nList is a special data class, that can hold vectors, strings, matrices, models, list of other lists.\n\nlist.object &lt;- list(number.object, vector.object2, matrix.object)\nlist.object\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] \"b8\" \"t4\" \"u2\"\n\n[[3]]\n     [,1] [,2]\n[1,]    2    3\n[2,]    4    5",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#useful-r-studio-shortcuts",
    "href": "modules/Module01-Intro.html#useful-r-studio-shortcuts",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Useful R Studio Shortcuts",
    "text": "Useful R Studio Shortcuts\nWill certainly save you time\n\nCmd + Return (iOS) OR Ctrl + Enter (Windows) in your script evaluates current line/selection\n\nIt’s like copying and pasting the code into the console for it to run.\n\npressing Up/Down in the Console allows you to navigate command history\n\nSee http://www.rstudio.com/ide/docs/using/keyboard_shortcuts for many more",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#rstudio-helps-with-tab-completion",
    "href": "modules/Module01-Intro.html#rstudio-helps-with-tab-completion",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "RStudio helps with “tab completion”",
    "text": "RStudio helps with “tab completion”\nIf you start typing a object, RStudio will show you options that you can choose without typing out the whole object.",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#summary",
    "href": "modules/Module01-Intro.html#summary",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Summary",
    "text": "Summary\n\nRStudio makes working in R easier\nThe Editor is for static code like R Scripts\nThe Console is for testing code that can’t be saved\nCommenting is your new best friend\nIn R we create objects that can be viewed in the Environment pane and used anytime\nAn object is something that can be worked with in R\nUse &lt;- syntax to create objects",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#mini-exercise-2",
    "href": "modules/Module01-Intro.html#mini-exercise-2",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Mini Exercise",
    "text": "Mini Exercise\n\nCreate a new number object and name it my.object\nCreate a vector of 4 numbers and name it my.vector using the c() function\nAdd my.object and my.vector together using an arithmetic operator",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module01-Intro.html#acknowledgements",
    "href": "modules/Module01-Intro.html#acknowledgements",
    "title": "Module 1: Introduction to RStudio and R Basics",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese are the materials we looked through, modified, or extracted to complete this module’s lecture.\n\n“Introduction to R for Public Health Researchers” Johns Hopkins University\nSome RStudio snapshots were pulled from http://ayeimanol-r.net/2013/04/21/289/",
    "crumbs": [
      "Day 1",
      "Module 1: Introduction to RStudio and R Basics"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#learning-objectives",
    "href": "modules/Module02-Functions.html#learning-objectives",
    "title": "Module 2: Functions",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter module 2, you should be able to…\n\nDescribe and execute functions in R\nModify default behavior of functions using arguments in R\nUse R-specific sources of help to get more information about functions and packages\nDifferentiate between Base R functions and functions that come from other packages",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#function---basic-term",
    "href": "modules/Module02-Functions.html#function---basic-term",
    "title": "Module 2: Functions",
    "section": "Function - Basic term",
    "text": "Function - Basic term\nFunction - Functions are “self contained” modules of code that accomplish specific tasks. Functions usually take in some sort of object (e.g., vector, list), process it, and return a result. You can write your own, use functions that come directly from installing R (i.e., Base R functions), or use functions from external packages.\nA function might help you add numbers together, create a plot, or organize your data. In fact, we have already used three functions in the Module 1, including c(), matrix(), list(). Here is another one, sum()\n\nsum(1, 20234)\n\n[1] 20235",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#function",
    "href": "modules/Module02-Functions.html#function",
    "title": "Module 2: Functions",
    "section": "Function",
    "text": "Function\nThe general usage for a function is the name of the function followed by parentheses (i.e., the function signature). Within the parentheses are arguments.\n\nfunction_name(argument1, argument2, ...)",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#arguments---basic-term",
    "href": "modules/Module02-Functions.html#arguments---basic-term",
    "title": "Module 2: Functions",
    "section": "Arguments - Basic term",
    "text": "Arguments - Basic term\nArguments are what you pass to the function and can include:\n\nthe physical object on which the function carries out a task (e.g., can be data such as a number 1 or 20234)\n\n\nsum(1, 20234)\n\n[1] 20235\n\n\n\noptions that alter the way the function operates (e.g., such as the base argument in the function log())\n\n\nlog(10, base = 10)\n\n[1] 1\n\nlog(10, base = 2)\n\n[1] 3.321928\n\nlog(10, base=exp(1))\n\n[1] 2.302585",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#arguments",
    "href": "modules/Module02-Functions.html#arguments",
    "title": "Module 2: Functions",
    "section": "Arguments",
    "text": "Arguments\nMost functions are created with default argument options. The defaults represent standard values that the author of the function specified as being “good enough in standard cases”. This means if you don’t specify an argument when calling the function, it will use a default.\n\nIf you want something specific, simply change the argument yourself with a value of your choice.\nIf an argument is required but you did not specify it and there is no default argument specified when the function was created, you will receive an error.",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#example",
    "href": "modules/Module02-Functions.html#example",
    "title": "Module 2: Functions",
    "section": "Example",
    "text": "Example\nWhat is the default in the base argument of the log() function?\n\nlog(10)\n\n[1] 2.302585",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#sure-that-is-easy-enough-but-how-do-you-know",
    "href": "modules/Module02-Functions.html#sure-that-is-easy-enough-but-how-do-you-know",
    "title": "Module 2: Functions",
    "section": "Sure that is easy enough, but how do you know",
    "text": "Sure that is easy enough, but how do you know\n\nthe purpose of a function?\nwhat arguments a function includes?\nhow to specify the arguments?",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#seeking-help-for-using-functions",
    "href": "modules/Module02-Functions.html#seeking-help-for-using-functions",
    "title": "Module 2: Functions",
    "section": "Seeking help for using functions (*)",
    "text": "Seeking help for using functions (*)\nThe best way of finding out this information is to use the ? followed by the name of the function. Doing this will open up the help manual in the bottom RStudio Help panel. It provides a description of the function, usage, arguments, details, and examples. Lets look at the help file for the function round()",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#how-to-specify-arguments",
    "href": "modules/Module02-Functions.html#how-to-specify-arguments",
    "title": "Module 2: Functions",
    "section": "How to specify arguments",
    "text": "How to specify arguments\n\nArguments are separated with a comma\nYou can specify arguments by either including them in the correct order OR by assigning the argument within the function parentheses.\n\n\n\nlog(10, 2)\n\n[1] 3.321928\n\nlog(base=2, x=10)\n\n[1] 3.321928\n\nlog(x=10, 2)\n\n[1] 3.321928\n\nlog(10, base=2)\n\n[1] 3.321928",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#package---basic-term",
    "href": "modules/Module02-Functions.html#package---basic-term",
    "title": "Module 2: Functions",
    "section": "Package - Basic term",
    "text": "Package - Basic term\nWhen you download R, it has a “base” set of functions, that are associated with a “base” set of packages including: ‘base’, ‘datasets’, ‘graphics’, ‘grDevices’, ‘methods’, ‘stats’ (typically just referred to as Base R).\n\ne.g., the log() function comes from the ‘base’ package\n\nPackage - a package in R is a bundle or “package” of code (and or possibly data) that can be loaded together for easy repeated use or for sharing with others.\nPackages are analogous to software applications like Microsoft Word. After installation, your operating system allows you to use it, just like having Word installed allows you to use it.",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#packages",
    "href": "modules/Module02-Functions.html#packages",
    "title": "Module 2: Functions",
    "section": "Packages",
    "text": "Packages\nThe Packages pane in RStudio can help you identify what have been installed (listed), and which one have been attached (check mark).\nLets go look at the Packages pane, find the base package and find the log() function. It automatically loads the help file that we looked at earlier using ?log.",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#additional-packages",
    "href": "modules/Module02-Functions.html#additional-packages",
    "title": "Module 2: Functions",
    "section": "Additional Packages",
    "text": "Additional Packages\nYou can install additional packages for your use from CRAN or GitHub. These additional packages are written by RStudio or R users/developers (like us)\n\nNot all packages available on CRAN or GitHub are trustworthy\nRStudio (the company) makes a lot of great packages\nWho wrote it? Hadley Wickham is a major authority on R (Employee and Developer at RStudio)\nHow to trust an R package",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#installing-and-attaching-packages",
    "href": "modules/Module02-Functions.html#installing-and-attaching-packages",
    "title": "Module 2: Functions",
    "section": "Installing and attaching packages",
    "text": "Installing and attaching packages\nTo use the bundle or “package” of code (and or possibly data) from a package, you need to install and also attach the package.\nTo install a package you can\n\ngo to R Studio Menu Bar Tools Menu —&gt; Install Packages in the RStudio header\n\nOR\n\nuse the following code:\n\n\ninstall.packages(\"package_name\")",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#installing-and-attaching-packages-1",
    "href": "modules/Module02-Functions.html#installing-and-attaching-packages-1",
    "title": "Module 2: Functions",
    "section": "Installing and attaching packages",
    "text": "Installing and attaching packages\nTo attach (i.e., be able to use the package) you can use the following code:\n\nrequire(package_name) #library(package_name) also works\n\nMore on installing and attaching packages later…",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#mini-exercise",
    "href": "modules/Module02-Functions.html#mini-exercise",
    "title": "Module 2: Functions",
    "section": "Mini exercise",
    "text": "Mini exercise\nFind and execute a Base R function that will round the number 0.86424 to two digits.",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#functions-from-module-1",
    "href": "modules/Module02-Functions.html#functions-from-module-1",
    "title": "Module 2: Functions",
    "section": "Functions from Module 1",
    "text": "Functions from Module 1\nThe combine function c() concatenate/collects/combines single R objects into a vector of R objects. It is mostly used for creating vectors of numbers, character strings, and other data types.\n\n?c\n\n\n\nRegistered S3 method overwritten by 'printr':\n  method                from     \n  knit_print.data.frame rmarkdown\n\n\nCombine Values into a Vector or List\n\nDescription:\n\n     This is a generic function which combines its arguments.\n\n     The default method combines its arguments to form a vector.  All\n     arguments are coerced to a common type which is the type of the\n     returned value, and all attributes except names are removed.\n\nUsage:\n\n     ## S3 Generic function\n     c(...)\n     \n     ## Default S3 method:\n     c(..., recursive = FALSE, use.names = TRUE)\n     \nArguments:\n\n     ...: objects to be concatenated.  All 'NULL' entries are dropped\n          before method dispatch unless at the very beginning of the\n          argument list.\n\nrecursive: logical.  If 'recursive = TRUE', the function recursively\n          descends through lists (and pairlists) combining all their\n          elements into a vector.\n\nuse.names: logical indicating if 'names' should be preserved.\n\nDetails:\n\n     The output type is determined from the highest type of the\n     components in the hierarchy NULL &lt; raw &lt; logical &lt; integer &lt;\n     double &lt; complex &lt; character &lt; list &lt; expression.  Pairlists are\n     treated as lists, whereas non-vector components (such as 'name's /\n     'symbol's and 'call's) are treated as one-element 'list's which\n     cannot be unlisted even if 'recursive = TRUE'.\n\n     There is a 'c.factor' method which combines factors into a factor.\n\n     'c' is sometimes used for its side effect of removing attributes\n     except names, for example to turn an 'array' into a vector.\n     'as.vector' is a more intuitive way to do this, but also drops\n     names.  Note that methods other than the default are not required\n     to do this (and they will almost certainly preserve a class\n     attribute).\n\n     This is a primitive function.\n\nValue:\n\n     'NULL' or an expression or a vector of an appropriate mode.  (With\n     no arguments the value is 'NULL'.)\n\nS4 methods:\n\n     This function is S4 generic, but with argument list '(x, ...)'.\n\nReferences:\n\n     Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S\n     Language_.  Wadsworth & Brooks/Cole.\n\nSee Also:\n\n     'unlist' and 'as.vector' to produce attribute-free vectors.\n\nExamples:\n\n     c(1,7:9)\n     c(1:5, 10.5, \"next\")\n     \n     ## uses with a single argument to drop attributes\n     x &lt;- 1:4\n     names(x) &lt;- letters[1:4]\n     x\n     c(x)          # has names\n     as.vector(x)  # no names\n     dim(x) &lt;- c(2,2)\n     x\n     c(x)\n     as.vector(x)\n     \n     ## append to a list:\n     ll &lt;- list(A = 1, c = \"C\")\n     ## do *not* use\n     c(ll, d = 1:3) # which is == c(ll, as.list(c(d = 1:3)))\n     ## but rather\n     c(ll, d = list(1:3))  # c() combining two lists\n     \n     c(list(A = c(B = 1)), recursive = TRUE)\n     \n     c(options(), recursive = TRUE)\n     c(list(A = c(B = 1, C = 2), B = c(E = 7)), recursive = TRUE)",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#functions-from-module-1-1",
    "href": "modules/Module02-Functions.html#functions-from-module-1-1",
    "title": "Module 2: Functions",
    "section": "Functions from Module 1",
    "text": "Functions from Module 1\nThe paste0() function concatenate/combines vectors after converting to character.\n\nvector.object2 &lt;- paste0(c(\"b\", \"t\", \"u\"), c(8,4,2))\nvector.object2\n?paste0\n\n\n\nConcatenate Strings\n\nDescription:\n\n     Concatenate vectors after converting to character.\n\nUsage:\n\n     paste (..., sep = \" \", collapse = NULL, recycle0 = FALSE)\n     paste0(...,            collapse = NULL, recycle0 = FALSE)\n     \nArguments:\n\n     ...: one or more R objects, to be converted to character vectors.\n\n     sep: a character string to separate the terms.  Not\n          'NA_character_'.\n\ncollapse: an optional character string to separate the results.  Not\n          'NA_character_'.\n\nrecycle0: 'logical' indicating if zero-length character arguments\n          should lead to the zero-length 'character(0)' after the\n          'sep'-phase (which turns into '\"\"' in the 'collapse'-phase,\n          i.e., when 'collapse' is not 'NULL').\n\nDetails:\n\n     'paste' converts its arguments (_via_ 'as.character') to character\n     strings, and concatenates them (separating them by the string\n     given by 'sep').  If the arguments are vectors, they are\n     concatenated term-by-term to give a character vector result.\n     Vector arguments are recycled as needed, with zero-length\n     arguments being recycled to '\"\"' only if 'recycle0' is not true\n     _or_ 'collapse' is not 'NULL'.\n\n     Note that 'paste()' coerces 'NA_character_', the character missing\n     value, to '\"NA\"' which may seem undesirable, e.g., when pasting\n     two character vectors, or very desirable, e.g. in 'paste(\"the\n     value of p is \", p)'.\n\n     'paste0(..., collapse)' is equivalent to 'paste(..., sep = \"\",\n     collapse)', slightly more efficiently.\n\n     If a value is specified for 'collapse', the values in the result\n     are then concatenated into a single string, with the elements\n     being separated by the value of 'collapse'.\n\nValue:\n\n     A character vector of the concatenated values.  This will be of\n     length zero if all the objects are, unless 'collapse' is non-NULL,\n     in which case it is '\"\"' (a single empty string).\n\n     If any input into an element of the result is in UTF-8 (and none\n     are declared with encoding '\"bytes\"', see 'Encoding'), that\n     element will be in UTF-8, otherwise in the current encoding in\n     which case the encoding of the element is declared if the current\n     locale is either Latin-1 or UTF-8, at least one of the\n     corresponding inputs (including separators) had a declared\n     encoding and all inputs were either ASCII or declared.\n\n     If an input into an element is declared with encoding '\"bytes\"',\n     no translation will be done of any of the elements and the\n     resulting element will have encoding '\"bytes\"'.  If 'collapse' is\n     non-NULL, this applies also to the second, collapsing, phase, but\n     some translation may have been done in pasting object together in\n     the first phase.\n\nReferences:\n\n     Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S\n     Language_.  Wadsworth & Brooks/Cole.\n\nSee Also:\n\n     'toString' typically calls 'paste(*, collapse=\", \")'.  String\n     manipulation with 'as.character', 'substr', 'nchar', 'strsplit';\n     further, 'cat' which concatenates and writes to a file, and\n     'sprintf' for C like string construction.\n\n     'plotmath' for the use of 'paste' in plot annotation.\n\nExamples:\n\n     ## When passing a single vector, paste0 and paste work like as.character.\n     paste0(1:12)\n     paste(1:12)        # same\n     as.character(1:12) # same\n     \n     ## If you pass several vectors to paste0, they are concatenated in a\n     ## vectorized way.\n     (nth &lt;- paste0(1:12, c(\"st\", \"nd\", \"rd\", rep(\"th\", 9))))\n     \n     ## paste works the same, but separates each input with a space.\n     ## Notice that the recycling rules make every input as long as the longest input.\n     paste(month.abb, \"is the\", nth, \"month of the year.\")\n     paste(month.abb, letters)\n     \n     ## You can change the separator by passing a sep argument\n     ## which can be multiple characters.\n     paste(month.abb, \"is the\", nth, \"month of the year.\", sep = \"_*_\")\n     \n     ## To collapse the output into a single string, pass a collapse argument.\n     paste0(nth, collapse = \", \")\n     \n     ## For inputs of length 1, use the sep argument rather than collapse\n     paste(\"1st\", \"2nd\", \"3rd\", collapse = \", \") # probably not what you wanted\n     paste(\"1st\", \"2nd\", \"3rd\", sep = \", \")\n     \n     ## You can combine the sep and collapse arguments together.\n     paste(month.abb, nth, sep = \": \", collapse = \"; \")\n     \n     ## Using paste() in combination with strwrap() can be useful\n     ## for dealing with long strings.\n     (title &lt;- paste(strwrap(\n         \"Stopping distance of cars (ft) vs. speed (mph) from Ezekiel (1930)\",\n         width = 30), collapse = \"\\n\"))\n     plot(dist ~ speed, cars, main = title)\n     \n     ## 'recycle0 = TRUE' allows more vectorized behaviour, i.e. zero-length recycling :\n     valid &lt;- FALSE\n     val &lt;- pi\n     paste(\"The value is\", val[valid], \"-- not so good!\")\n     paste(\"The value is\", val[valid], \"-- good: empty!\", recycle0=TRUE) # -&gt; character(0)\n     ## When  'collapse = &lt;string&gt;',  the result is a length-1 string :\n     paste(\"foo\", {}, \"bar\", collapse=\"|\")                  # |--&gt;  \"foo  bar\"\n     paste(\"foo\", {}, \"bar\", collapse=\"|\", recycle0 = TRUE) # |--&gt;  \"\"\n     ## all empty args\n     paste(    collapse=\"|\")                  # |--&gt;  \"\"  as do all these:\n     paste(    collapse=\"|\", recycle0 = TRUE)\n     paste({}, collapse=\"|\")\n     paste({}, collapse=\"|\", recycle0 = TRUE)",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#functions-from-module-1-2",
    "href": "modules/Module02-Functions.html#functions-from-module-1-2",
    "title": "Module 2: Functions",
    "section": "Functions from Module 1",
    "text": "Functions from Module 1\nThe matrix() function creates a matrix from the given set of values.\n\nmatrix.object &lt;- matrix(data=vector.object1, nrow=2, ncol=2, byrow=TRUE)\nmatrix.object\n?matrix\n\n\n\nMatrices\n\nDescription:\n\n     'matrix' creates a matrix from the given set of values.\n\n     'as.matrix' attempts to turn its argument into a matrix.\n\n     'is.matrix' tests if its argument is a (strict) matrix.\n\nUsage:\n\n     matrix(data = NA, nrow = 1, ncol = 1, byrow = FALSE,\n            dimnames = NULL)\n     \n     as.matrix(x, ...)\n     ## S3 method for class 'data.frame'\n     as.matrix(x, rownames.force = NA, ...)\n     \n     is.matrix(x)\n     \nArguments:\n\n    data: an optional data vector (including a list or 'expression'\n          vector).  Non-atomic classed R objects are coerced by\n          'as.vector' and all attributes discarded.\n\n    nrow: the desired number of rows.\n\n    ncol: the desired number of columns.\n\n   byrow: logical. If 'FALSE' (the default) the matrix is filled by\n          columns, otherwise the matrix is filled by rows.\n\ndimnames: A 'dimnames' attribute for the matrix: 'NULL' or a 'list' of\n          length 2 giving the row and column names respectively.  An\n          empty list is treated as 'NULL', and a list of length one as\n          row names.  The list can be named, and the list names will be\n          used as names for the dimensions.\n\n       x: an R object.\n\n     ...: additional arguments to be passed to or from methods.\n\nrownames.force: logical indicating if the resulting matrix should have\n          character (rather than 'NULL') 'rownames'.  The default,\n          'NA', uses 'NULL' rownames if the data frame has 'automatic'\n          row.names or for a zero-row data frame.\n\nDetails:\n\n     If one of 'nrow' or 'ncol' is not given, an attempt is made to\n     infer it from the length of 'data' and the other parameter.  If\n     neither is given, a one-column matrix is returned.\n\n     If there are too few elements in 'data' to fill the matrix, then\n     the elements in 'data' are recycled.  If 'data' has length zero,\n     'NA' of an appropriate type is used for atomic vectors ('0' for\n     raw vectors) and 'NULL' for lists.\n\n     'is.matrix' returns 'TRUE' if 'x' is a vector and has a '\"dim\"'\n     attribute of length 2 and 'FALSE' otherwise.  Note that a\n     'data.frame' is *not* a matrix by this test.  The function is\n     generic: you can write methods to handle specific classes of\n     objects, see InternalMethods.\n\n     'as.matrix' is a generic function.  The method for data frames\n     will return a character matrix if there is only atomic columns and\n     any non-(numeric/logical/complex) column, applying 'as.vector' to\n     factors and 'format' to other non-character columns.  Otherwise,\n     the usual coercion hierarchy (logical &lt; integer &lt; double &lt;\n     complex) will be used, e.g., all-logical data frames will be\n     coerced to a logical matrix, mixed logical-integer will give a\n     integer matrix, etc.\n\n     The default method for 'as.matrix' calls 'as.vector(x)', and hence\n     e.g. coerces factors to character vectors.\n\n     When coercing a vector, it produces a one-column matrix, and\n     promotes the names (if any) of the vector to the rownames of the\n     matrix.\n\n     'is.matrix' is a primitive function.\n\n     The 'print' method for a matrix gives a rectangular layout with\n     dimnames or indices.  For a list matrix, the entries of length not\n     one are printed in the form 'integer,7' indicating the type and\n     length.\n\nNote:\n\n     If you just want to convert a vector to a matrix, something like\n\n       dim(x) &lt;- c(nx, ny)\n       dimnames(x) &lt;- list(row_names, col_names)\n     \n     will avoid duplicating 'x' _and_ preserve 'class(x)' which may be\n     useful, e.g., for 'Date' objects.\n\nReferences:\n\n     Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S\n     Language_.  Wadsworth & Brooks/Cole.\n\nSee Also:\n\n     'data.matrix', which attempts to convert to a numeric matrix.\n\n     A matrix is the special case of a two-dimensional 'array'.\n     'inherits(m, \"array\")' is true for a 'matrix' 'm'.\n\nExamples:\n\n     is.matrix(as.matrix(1:10))\n     !is.matrix(warpbreaks)  # data.frame, NOT matrix!\n     warpbreaks[1:10,]\n     as.matrix(warpbreaks[1:10,])  # using as.matrix.data.frame(.) method\n     \n     ## Example of setting row and column names\n     mdat &lt;- matrix(c(1,2,3, 11,12,13), nrow = 2, ncol = 3, byrow = TRUE,\n                    dimnames = list(c(\"row1\", \"row2\"),\n                                    c(\"C.1\", \"C.2\", \"C.3\")))\n     mdat",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#summary",
    "href": "modules/Module02-Functions.html#summary",
    "title": "Module 2: Functions",
    "section": "Summary",
    "text": "Summary\n\nFunctions are “self contained” modules of code that accomplish specific tasks.\nArguments are what you pass to functions (e.g., objects on which you carry out the task or options for how to carry out the task)\nArguments may include defaults that the author of the function specified as being “good enough in standard cases”, but that can be changed.\nAn R Package is a bundle or “package” of code (and or possibly data) that can be used by installing it once and attaching it (using require()`) each time R/Rstudio is opened\nThe Help pane in RStudio is useful for to get more information about functions and packages",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module02-Functions.html#acknowledgements",
    "href": "modules/Module02-Functions.html#acknowledgements",
    "title": "Module 2: Functions",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese are the materials we looked through, modified, or extracted to complete this module’s lecture.\n\n“Introduction to R - ARCHIVED” from Harvard Chan Bioinformatics Core (HBC)",
    "crumbs": [
      "Day 1",
      "Module 2: Functions"
    ]
  },
  {
    "objectID": "modules/Module095-DataAnalysisWalkthrough.html#learning-goals",
    "href": "modules/Module095-DataAnalysisWalkthrough.html#learning-goals",
    "title": "Data Analysis Walkthrough",
    "section": "Learning goals",
    "text": "Learning goals\n\nUse logical operators, subsetting functions, and math calculations in R\nTranslate human-understandable problem descriptions into instructions that R can understand.",
    "crumbs": [
      "Day 2",
      "Data Analysis Walkthrough"
    ]
  },
  {
    "objectID": "modules/Module095-DataAnalysisWalkthrough.html#instructions",
    "href": "modules/Module095-DataAnalysisWalkthrough.html#instructions",
    "title": "Data Analysis Walkthrough",
    "section": "Instructions",
    "text": "Instructions\n\nMake a new R script for this case study, and save it to your code folder.\nWe’ll use the diphtheria serosample data from Exercise 1 for this case study. Load it into R and use the functions we’ve learned to look at it.",
    "crumbs": [
      "Day 2",
      "Data Analysis Walkthrough"
    ]
  },
  {
    "objectID": "modules/Module095-DataAnalysisWalkthrough.html#instructions-1",
    "href": "modules/Module095-DataAnalysisWalkthrough.html#instructions-1",
    "title": "Data Analysis Walkthrough",
    "section": "Instructions",
    "text": "Instructions\n\nMake a new R script for this case study, and save it to your code folder.\nWe’ll use the diphtheria serosample data from Exercise 1 for this case study. Load it into R and use the functions we’ve learned to look at it.\nThe str() of your dataset should look like this.\n\n\n\ntibble [250 × 5] (S3: tbl_df/tbl/data.frame)\n $ age_months  : num [1:250] 15 44 103 88 88 118 85 19 78 112 ...\n $ group       : chr [1:250] \"urban\" \"rural\" \"urban\" \"urban\" ...\n $ DP_antibody : num [1:250] 0.481 0.657 1.368 1.218 0.333 ...\n $ DP_infection: num [1:250] 1 1 1 1 1 1 1 1 1 1 ...\n $ DP_vacc     : num [1:250] 0 1 1 1 1 1 1 1 1 1 ...",
    "crumbs": [
      "Day 2",
      "Data Analysis Walkthrough"
    ]
  },
  {
    "objectID": "modules/Module095-DataAnalysisWalkthrough.html#q1-was-the-overall-prevalence-higher-in-urban-or-rural-areas",
    "href": "modules/Module095-DataAnalysisWalkthrough.html#q1-was-the-overall-prevalence-higher-in-urban-or-rural-areas",
    "title": "Data Analysis Walkthrough",
    "section": "Q1: Was the overall prevalence higher in urban or rural areas?",
    "text": "Q1: Was the overall prevalence higher in urban or rural areas?\n\n\nHow do we calculate the prevalence from the data?\nHow do we calculate the prevalence separately for urban and rural areas?\nHow do we determine which prevalence is higher and if the difference is meaningful?",
    "crumbs": [
      "Day 2",
      "Data Analysis Walkthrough"
    ]
  },
  {
    "objectID": "modules/Module095-DataAnalysisWalkthrough.html#q1-how-do-we-calculate-the-prevalence-from-the-data",
    "href": "modules/Module095-DataAnalysisWalkthrough.html#q1-how-do-we-calculate-the-prevalence-from-the-data",
    "title": "Data Analysis Walkthrough",
    "section": "Q1: How do we calculate the prevalence from the data?",
    "text": "Q1: How do we calculate the prevalence from the data?\n\n\nThe variable DP_infection in our dataset is binary / dichotomous.\nThe prevalence is the number or percent of people who had the disease over some duration.\nThe average of a binary variable gives the prevalence!\n\n\n\n\nmean(diph$DP_infection)\n\n[1] 0.8",
    "crumbs": [
      "Day 2",
      "Data Analysis Walkthrough"
    ]
  },
  {
    "objectID": "modules/Module095-DataAnalysisWalkthrough.html#q1-how-do-we-calculate-the-prevalence-separately-for-urban-and-rural-areas",
    "href": "modules/Module095-DataAnalysisWalkthrough.html#q1-how-do-we-calculate-the-prevalence-separately-for-urban-and-rural-areas",
    "title": "Data Analysis Walkthrough",
    "section": "Q1: How do we calculate the prevalence separately for urban and rural areas?",
    "text": "Q1: How do we calculate the prevalence separately for urban and rural areas?\n\n\nmean(diph[diph$group == \"urban\", ]$DP_infection)\n\n[1] 0.8235294\n\nmean(diph[diph$group == \"rural\", ]$DP_infection)\n\n[1] 0.778626\n\n\n\n\n\nThere are many ways you could write this code! You can use subset() or you can write the indices many ways.\nUsing tbl_df objects from haven uses different [[ rules than a base R data frame.",
    "crumbs": [
      "Day 2",
      "Data Analysis Walkthrough"
    ]
  },
  {
    "objectID": "modules/Module095-DataAnalysisWalkthrough.html#q1-how-do-we-calculate-the-prevalence-separately-for-urban-and-rural-areas-1",
    "href": "modules/Module095-DataAnalysisWalkthrough.html#q1-how-do-we-calculate-the-prevalence-separately-for-urban-and-rural-areas-1",
    "title": "Data Analysis Walkthrough",
    "section": "Q1: How do we calculate the prevalence separately for urban and rural areas?",
    "text": "Q1: How do we calculate the prevalence separately for urban and rural areas?\n\nOne easy way is to use the aggregate() function.\n\n\naggregate(DP_infection ~ group, data = diph, FUN = mean)\n\n  group DP_infection\n1 rural    0.7786260\n2 urban    0.8235294",
    "crumbs": [
      "Day 2",
      "Data Analysis Walkthrough"
    ]
  },
  {
    "objectID": "modules/Module095-DataAnalysisWalkthrough.html#q1-how-do-we-determine-which-prevalence-is-higher-and-if-the-difference-is-meaningful",
    "href": "modules/Module095-DataAnalysisWalkthrough.html#q1-how-do-we-determine-which-prevalence-is-higher-and-if-the-difference-is-meaningful",
    "title": "Data Analysis Walkthrough",
    "section": "Q1: How do we determine which prevalence is higher and if the difference is meaningful?",
    "text": "Q1: How do we determine which prevalence is higher and if the difference is meaningful?\n\n\nWe probably need to include a confidence interval in our calculation.\nThis is actually not so easy without more advanced tools that we will learn in upcoming modules.\nRight now the best options are to do it by hand or google a function.",
    "crumbs": [
      "Day 2",
      "Data Analysis Walkthrough"
    ]
  },
  {
    "objectID": "modules/Module095-DataAnalysisWalkthrough.html#q1-by-hand",
    "href": "modules/Module095-DataAnalysisWalkthrough.html#q1-by-hand",
    "title": "Data Analysis Walkthrough",
    "section": "Q1: By hand",
    "text": "Q1: By hand\n\np_urban &lt;- mean(diph[diph$group == \"urban\", ]$DP_infection)\np_rural &lt;- mean(diph[diph$group == \"rural\", ]$DP_infection)\nse_urban &lt;- sqrt(p_urban * (1 - p_urban) / nrow(diph[diph$group == \"urban\", ]))\nse_rural &lt;- sqrt(p_rural * (1 - p_rural) / nrow(diph[diph$group == \"rural\", ])) \n\nresult_urban &lt;- paste0(\n    \"Urban: \", round(p_urban, 2), \"; 95% CI: (\",\n    round(p_urban - 1.96 * se_urban, 2), \", \",\n    round(p_urban + 1.96 * se_urban, 2), \")\"\n)\n\nresult_rural &lt;- paste0(\n    \"Rural: \", round(p_rural, 2), \"; 95% CI: (\",\n    round(p_rural - 1.96 * se_rural, 2), \", \",\n    round(p_rural + 1.96 * se_rural, 2), \")\"\n)\n\ncat(result_urban, result_rural, sep = \"\\n\")\n\nUrban: 0.82; 95% CI: (0.76, 0.89)\nRural: 0.78; 95% CI: (0.71, 0.85)",
    "crumbs": [
      "Day 2",
      "Data Analysis Walkthrough"
    ]
  },
  {
    "objectID": "modules/Module095-DataAnalysisWalkthrough.html#q1-by-hand-1",
    "href": "modules/Module095-DataAnalysisWalkthrough.html#q1-by-hand-1",
    "title": "Data Analysis Walkthrough",
    "section": "Q1: By hand",
    "text": "Q1: By hand\n\nWe can see that the 95% CI’s overlap, so the groups are probably not that different. To be sure, we need to do a 2-sample test! But this is not a statistics class.\nSome people will tell you that coding like this is “bad”. But ‘bad’ code that gives you answers is better than broken code! We will learn techniques for writing this with less work and less repetition in upcoming modules.",
    "crumbs": [
      "Day 2",
      "Data Analysis Walkthrough"
    ]
  },
  {
    "objectID": "modules/Module095-DataAnalysisWalkthrough.html#q1-googling-a-package",
    "href": "modules/Module095-DataAnalysisWalkthrough.html#q1-googling-a-package",
    "title": "Data Analysis Walkthrough",
    "section": "Q1: Googling a package",
    "text": "Q1: Googling a package\n\n\n# install.packages(\"DescTools\")\nlibrary(DescTools)\n\naggregate(DP_infection ~ group, data = diph, FUN = DescTools::MeanCI)\n\n  group DP_infection.mean DP_infection.lwr.ci DP_infection.upr.ci\n1 rural         0.7786260           0.7065872           0.8506647\n2 urban         0.8235294           0.7540334           0.8930254",
    "crumbs": [
      "Day 2",
      "Data Analysis Walkthrough"
    ]
  },
  {
    "objectID": "modules/Module095-DataAnalysisWalkthrough.html#you-try-it",
    "href": "modules/Module095-DataAnalysisWalkthrough.html#you-try-it",
    "title": "Data Analysis Walkthrough",
    "section": "You try it!",
    "text": "You try it!\n\nUsing any of the approaches you can think of, answer this question!\nHow many children under 5 were vaccinated? In children under 5, did vaccination lower the prevalence of infection?",
    "crumbs": [
      "Day 2",
      "Data Analysis Walkthrough"
    ]
  },
  {
    "objectID": "modules/Module095-DataAnalysisWalkthrough.html#you-try-it-1",
    "href": "modules/Module095-DataAnalysisWalkthrough.html#you-try-it-1",
    "title": "Data Analysis Walkthrough",
    "section": "You try it!",
    "text": "You try it!\n\n# How many children under 5 were vaccinated\nsum(diph$DP_vacc[diph$age_months &lt; 60])\n\n[1] 91\n\n# Prevalence in both vaccine groups for children under 5\naggregate(\n    DP_infection ~ DP_vacc,\n    data = subset(diph, age_months &lt; 60),\n    FUN = DescTools::MeanCI\n)\n\n  DP_vacc DP_infection.mean DP_infection.lwr.ci DP_infection.upr.ci\n1       0         0.4285714           0.1977457           0.6593972\n2       1         0.6373626           0.5366845           0.7380407\n\n\nIt appears that prevalence was HIGHER in the vaccine group? That is counterintuitive, but the sample size for the unvaccinated group is too small to be sure.",
    "crumbs": [
      "Day 2",
      "Data Analysis Walkthrough"
    ]
  },
  {
    "objectID": "modules/Module095-DataAnalysisWalkthrough.html#congratulations-for-finishing-the-first-case-study",
    "href": "modules/Module095-DataAnalysisWalkthrough.html#congratulations-for-finishing-the-first-case-study",
    "title": "Data Analysis Walkthrough",
    "section": "Congratulations for finishing the first case study!",
    "text": "Congratulations for finishing the first case study!\n\nWhat R functions and skills did you practice?\nWhat other questions could you answer about the same dataset with the skills you know now?",
    "crumbs": [
      "Day 2",
      "Data Analysis Walkthrough"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#welcome-to-sismid-workshop-introduction-to-r",
    "href": "modules/Module00-Welcome.html#welcome-to-sismid-workshop-introduction-to-r",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "Welcome to SISMID Workshop: Introduction to R!",
    "text": "Welcome to SISMID Workshop: Introduction to R!\nAmy Winter (she/her)\nAssistant Professor, Department of Epidemiology and Biostatistics\nEmail: awinter@uga.edu\n\nZane Billings (he/him)\nPhD Candidate, Department of Epidemiology and Biostatistics\nEmail: Wesley.Billings@uga.edu",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#introductions",
    "href": "modules/Module00-Welcome.html#introductions",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "Introductions",
    "text": "Introductions\n\nName?\nCurrent position / institution?\nPast experience with other statistical programs, including R?\nWhy do you want to learn R?\nFavorite useful app\nFavorite guilty pleasure app",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#course-website",
    "href": "modules/Module00-Welcome.html#course-website",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "Course website",
    "text": "Course website\n\nAll of the materials for this course can be found online here: here.\nThis contains the schedule, course resources, and online versions of all of our slide decks.\nThe Course Resources page contains download links for all of the data, exercises, and slides for this class.\nPlease feel free to download these resources and share them – all of the course content is under the Creative Commons BY-NC 4.0 license.",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#what-is-r",
    "href": "modules/Module00-Welcome.html#what-is-r",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "What is R?",
    "text": "What is R?\n\nR is a language and environment for statistical computing and graphics developed in 1991\nR is the open source implementation of the S language, which was developed by Bell laboratories in the 70s.\nThe aim of the S language, as expressed by John Chambers, is “to turn ideas into software, quickly and faithfully”",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#what-is-r-1",
    "href": "modules/Module00-Welcome.html#what-is-r-1",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "What is R?",
    "text": "What is R?\n\nRoss Ihaka and Robert Gentleman at the University of Auckland, New Zealand developed R\nR is both open source and open development",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#what-is-r-2",
    "href": "modules/Module00-Welcome.html#what-is-r-2",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "What is R?",
    "text": "What is R?\n\nR possesses an extensive catalog of statistical and graphical methods\n\nincludes machine learning algorithm, linear regression, time series, statistical inference to name a few.\n\nData analysis with R is done in a series of steps; programming, transforming, discovering, modeling and communicate the results",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#what-is-r-3",
    "href": "modules/Module00-Welcome.html#what-is-r-3",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "What is R?",
    "text": "What is R?\n\nProgram: R is a clear and accessible programming tool\nTransform: R is made up of a collection of packages/libraries designed specifically for statistical computing\nDiscover: Investigate the data, refine your hypothesis and analyze them\nModel: R provides a wide array of tools to capture the right model for your data\nCommunicate: Integrate codes, graphs, and outputs to a report with R Markdown or build Shiny apps to share with the world",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#why-r",
    "href": "modules/Module00-Welcome.html#why-r",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "Why R?",
    "text": "Why R?\n\nFree (open source)\nHigh level language designed for statistical computing\nPowerful and flexible - especially for data wrangling and visualization\nExtensive add-on software (packages)\nStrong community",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#why-not-r",
    "href": "modules/Module00-Welcome.html#why-not-r",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "Why not R?",
    "text": "Why not R?\n\nLittle centralized support, relies on online community and package developers\nAnnoying to update\nSlower, and more memory intensive, than the more traditional programming languages (C, Perl, Python)",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#is-r-difficult",
    "href": "modules/Module00-Welcome.html#is-r-difficult",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "Is R Difficult?",
    "text": "Is R Difficult?\n\nShort answer – It has a steep learning curve, like all programming languages\nYears ago, R was a difficult language to master.\nHadley Wickham developed a collection of packages called tidyverse. Data manipulation became trivial and intuitive. Creating a graph was not so difficult anymore.",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#overall-workshop-objectives",
    "href": "modules/Module00-Welcome.html#overall-workshop-objectives",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "Overall Workshop Objectives",
    "text": "Overall Workshop Objectives\nBy the end of this workshop, you should be able to\n\nstart a new project, read in data, and conduct basic data manipulation, analysis, and visualization\nknow how to use and find packages/functions that we did not specifically learn in class\ntroubleshoot errors",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#this-workshop-differs-from-introduction-to-tidyverse",
    "href": "modules/Module00-Welcome.html#this-workshop-differs-from-introduction-to-tidyverse",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "This workshop differs from “Introduction to Tidyverse”",
    "text": "This workshop differs from “Introduction to Tidyverse”\nWe will focus this class on using Base R functions and packages, i.e., pre-installed into R and the basis for most other functions and packages! If you know Base R then are will be more equipped to use all the other useful/pretty packages that exit.\nThe Tidyverse is one set of useful/pretty sets of packages, designed to can make your code more intuitive as compared to the original older Base R. Tidyverse advantages:\n\nconsistent structure - making it easier to learn how to use different packages\nparticularly good for wrangling (manipulating, cleaning, joining) data\n\nmore flexible for visualizing data",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#workshop-overview",
    "href": "modules/Module00-Welcome.html#workshop-overview",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "Workshop Overview",
    "text": "Workshop Overview\n14 lecture blocks that will each:\n\nStart with learning objectives\nEnd with summary slides\nInclude mini-exercise(s) or a full exercise\n\nThemes that will show up throughout the workshop:\n\nReproducibility\nGood coding techniques\nThinking algorithmically\nBasic terms / R jargon",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#reproducibility",
    "href": "modules/Module00-Welcome.html#reproducibility",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "Reproducibility",
    "text": "Reproducibility\n\nReproducible research: the idea that other people should be able to verify the claims you make – usually by being able to see your data and run your code.\n\n\n\n2023 was the US government’s year of open science – specific aspects of reproducibility will be mandated for federally funded research!\nSharing and documenting your code is a massive step towards making your work reproducible, and the R ecosystem can play a big role in that!",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#useful-free-resources",
    "href": "modules/Module00-Welcome.html#useful-free-resources",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "Useful (+ Free) Resources",
    "text": "Useful (+ Free) Resources\nWant more?\n\nR for Data Science: http://r4ds.had.co.nz/\n(great general information)\nFundamentals of Data Visualization: https://clauswilke.com/dataviz/\nR for Epidemiology: https://www.r4epi.com/\nThe Epidemiologist R Handbook: https://epirhandbook.com/en/\nR basics by Rafael A. Irizarry: https://rafalab.github.io/dsbook/r-basics.html (great general information)\nOpen Case Studies: https://www.opencasestudies.org/\n(resource for specific public health cases with statistical implementation and interpretation)",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#useful-free-resources-1",
    "href": "modules/Module00-Welcome.html#useful-free-resources-1",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "Useful (+Free) Resources",
    "text": "Useful (+Free) Resources\nNeed help?\n\nVarious “Cheat Sheets”: https://github.com/rstudio/cheatsheets/\nR reference card: http://cran.r-project.org/doc/contrib/Short-refcard.pdf\nR jargon: https://link.springer.com/content/pdf/bbm%3A978-1-4419-1318-0%2F1.pdf\nR vs Stata: https://link.springer.com/content/pdf/bbm%3A978-1-4419-1318-0%2F1.pdf\nR terminology: https://cran.r-project.org/doc/manuals/r-release/R-lang.pdf",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "modules/Module00-Welcome.html#installing-r",
    "href": "modules/Module00-Welcome.html#installing-r",
    "title": "Welcome to SISMID Workshop: Introduction to R",
    "section": "Installing R",
    "text": "Installing R\nHopefully everyone has pre-installed R and RStudio. We will take a moment to go around and make sure everyone is ready to go. Please open up your RStudio and leave it open as we check everyone’s laptops.\n\nInstall the latest version from: http://cran.r-project.org/\nInstall RStudio",
    "crumbs": [
      "Day 1",
      "Welcome to SISMID Workshop: Introduction to R"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Course Resources",
    "section": "",
    "text": "Data and Exercise downloads\n\nDownload all datasets here: click to download.\nDownload all exercises and solution files here: click to download\nDownload all slide decks here: click to download\nGet the example R Markdown document for Module 11 here: click to download\n\nAnd the sample bibligraphy “bib” file is here: click to download\nAnd the rendered HTML file is here: click to download\n\nCourse GitHub where all materials can be found (to download the entire course as a zip file click the green “Code” button): https://github.com/UGA-IDD/SISMID-2024.\n\n\n\nUseful (+ Free) Resources\n\nR for Data Science: http://r4ds.had.co.nz/\n(great general information)\nFundamentals of Data Visualization: https://clauswilke.com/dataviz/\nR for Epidemiology: https://www.r4epi.com/\nThe Epidemiologist R Handbook: https://epirhandbook.com/en/\nR basics by Rafael A. Irizarry: https://rafalab.github.io/dsbook/r-basics.html (great general information)\nOpen Case Studies: https://www.opencasestudies.org/\n(resource for specific public health cases with statistical implementation and interpretation)\n\n\n\nNeed help?\n\nVarious “Cheat Sheets”: https://github.com/rstudio/cheatsheets/\nR reference card: http://cran.r-project.org/doc/contrib/Short-refcard.pdf\n\nR jargon: https://link.springer.com/content/pdf/bbm%3A978-1-4419-1318-0%2F1.pdf\nR vs Stata: https://link.springer.com/content/pdf/bbm%3A978-1-4419-1318-0%2F1.pdf\nR terminology: https://cran.r-project.org/doc/manuals/r-release/R-lang.pdf\n\n\n\nOther references\n\n\nBatra, Neale, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, Florence Isaac, Natalie Fischer, et al. 2021. epiR Handbook. Edited by Neale Batra. https://epirhandbook.com/; Applied Epi Incorporated.\n\n\nCarchedi, Nick, and Sean Kross. 2024. “Learn r, in r.” Swirl. https://swirlstats.com/.\n\n\nKeyes, David. 2024. R for the Rest of Us: A Statistics-Free Introduction. San Francisco, CA: No Starch Press.\n\n\nMatloff, Norman. 2011. The Art of R Programming. San Francisco, CA: No Starch Press.\n\n\nR Core team. 2024. An Introduction to R. https://cran.r-project.org/doc/manuals/r-release/R-intro.html.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science. 2nd ed. Sebastopol, CA: https://r4ds.hadley.nz/; O’Reilly Media.\n\n\n\n\n\n\n\n\nReuseCC BY-NC 4.0",
    "crumbs": [
      "Course Resources"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome to “Introduction to R”!\nThis website contains all of the material for the 2024 Summer Institute in Modeling for Infectious Diseases (SISMID) Module “Introduction to R”.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#prerequisities",
    "href": "index.html#prerequisities",
    "title": "Welcome",
    "section": "Prerequisities",
    "text": "Prerequisities\nFamiliary with basic statistical concepts on the level of an introductory statistics class is assumed for our course\nBefore the course begins, you should install R and RStudio on your laptop. If you are using an older version of R, you should update it before the course begins. You will need at least R version 4.3.0 for this course, but using the most recent version (4.4.1 at the time of writing) is always preferable.\n\nYou can install R from the CRAN website by clicking on the correct download link for your OS.\nYou can install RStudio from the Posit website.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#about-the-instructors",
    "href": "index.html#about-the-instructors",
    "title": "Welcome",
    "section": "About the instructors",
    "text": "About the instructors\n\n\n\nCo-Instructor: Dr. Amy Winter\n\n\nDr. Winter is an Assistant Professor of Epidemiology at the University of Georgia. She has been coding in R for 10 years, and uses R day-to-day to conduct her research addressing policy-relevant questions on the transmission and control of infectious diseases in human populations, particularly VPDs. She teaches a semester-long course titled Introduction to Coding in R for Public Health to graduate students at the University of Georgia.\n\n\n\nCo-Instructor: Zane Billings\n\n\nZane Billings is a PhD student in Epidemiology and Biostatistics at the University of Georgia, working with Andreas Handel. He has been using R since 2017, and uses R for nearly all of his statistics and data science practice. Zane’s research focuses on the immune response to influenza vaccination, and uses machine learning and multilevel regression modeling (in R!) to improve our understanding of influenza immunology.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "modules/Module04-RProject.html#learning-objectives",
    "href": "modules/Module04-RProject.html#learning-objectives",
    "title": "Module 4: R Project",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter module 4, you should be able to…\n\nCreate an R Project\nCheck you are in the desired R Project\nReference the Files pane in RStudio\nDescribe “good” R Project organization",
    "crumbs": [
      "Day 1",
      "Module 4: R Project"
    ]
  },
  {
    "objectID": "modules/Module04-RProject.html#rstudio-project",
    "href": "modules/Module04-RProject.html#rstudio-project",
    "title": "Module 4: R Project",
    "section": "RStudio Project",
    "text": "RStudio Project\nRStudio “Project” is one highly recommended strategy to build organized and reproducible code in R.\n\nHelps with working directories by easily incorporating relative paths only.\nHelps you organize your code, data, and output.\nAllows you to open multiple RStudio sessions at once!",
    "crumbs": [
      "Day 1",
      "Module 4: R Project"
    ]
  },
  {
    "objectID": "modules/Module04-RProject.html#rstudio-project-creation",
    "href": "modules/Module04-RProject.html#rstudio-project-creation",
    "title": "Module 4: R Project",
    "section": "RStudio Project Creation",
    "text": "RStudio Project Creation\nLet’s create a new RStudio Project.\nFind the File Menu in the Menu Bar –&gt; New Project –&gt; New Directory –&gt; New Project\nName your Project “IntroToR_RProject”",
    "crumbs": [
      "Day 1",
      "Module 4: R Project"
    ]
  },
  {
    "objectID": "modules/Module04-RProject.html#rstudio-project-organization",
    "href": "modules/Module04-RProject.html#rstudio-project-organization",
    "title": "Module 4: R Project",
    "section": "RStudio Project Organization",
    "text": "RStudio Project Organization\nThis is my personal preference for organizing an R Project. But, for this workshop it will be mandatory as it will help us help you. A critical component of conducting any data analysis is being able to reproduce it! Organizing your code, data, output, and figures is a necessary (although not sufficient) condition for reproducibility.\nCreate 4 sub-directories with the following names within your “SISMID_IntroToR_RProject” folder:\n\ncode\ndata\noutput\nfigures\n\nWe will be working from this directory for the remainder of the Workshop. Take a moment to move any R scripts you have already created to the ‘code’ sub-directory.",
    "crumbs": [
      "Day 1",
      "Module 4: R Project"
    ]
  },
  {
    "objectID": "modules/Module04-RProject.html#some-things-to-notice-in-an-r-project",
    "href": "modules/Module04-RProject.html#some-things-to-notice-in-an-r-project",
    "title": "Module 4: R Project",
    "section": "Some things to notice in an R Project",
    "text": "Some things to notice in an R Project\n\nThe name of the R Project will be shown at the top of the RStudio Window\nIf you check the working directory using getwd() you will find the working directory is set to the location where the R Project was saved.\nThe Files pane in RStudio is also set to the location where the R Project was saved, making it easy to navigate to sub-directories directly from RStudio.",
    "crumbs": [
      "Day 1",
      "Module 4: R Project"
    ]
  },
  {
    "objectID": "modules/Module04-RProject.html#r-project---common-issues",
    "href": "modules/Module04-RProject.html#r-project---common-issues",
    "title": "Module 4: R Project",
    "section": "R Project - Common issues",
    "text": "R Project - Common issues\nIf you simply open RStudio, it will not automatically open your R Project. As a result, when you say run a function to import data using the relative path based on your working directory, it won’t be able to find the data.\nTo open a previously created R Project, you need to open the R Project (i.e., double click on SISMID_IntroToR_RProject.RProj)",
    "crumbs": [
      "Day 1",
      "Module 4: R Project"
    ]
  },
  {
    "objectID": "modules/Module04-RProject.html#summary",
    "href": "modules/Module04-RProject.html#summary",
    "title": "Module 4: R Project",
    "section": "Summary",
    "text": "Summary\n\nR Projects are really helpful for lots of reasons, including to improve the reproducibility of your work\nConsistently set up your R Project’s sub-directories so that you can easily navigate the project\nIf you get an error that a file can’t be found, make sure you correctly opened the R Project by looking for the Project name at the top of the RStudio application window.",
    "crumbs": [
      "Day 1",
      "Module 4: R Project"
    ]
  },
  {
    "objectID": "modules/Module04-RProject.html#mini-exercise",
    "href": "modules/Module04-RProject.html#mini-exercise",
    "title": "Module 4: R Project",
    "section": "Mini Exercise",
    "text": "Mini Exercise\n\nClose R Studio\nReopen your R Project\nCheck that you are actually in the R Project\nCreate a new R script and save it in your ‘code’ subdirectory\nCreate a vector of numbers\nCreate a vector a character values\nAdd comment(s) to your R script to explain your code.",
    "crumbs": [
      "Day 1",
      "Module 4: R Project"
    ]
  },
  {
    "objectID": "modules/Module04-RProject.html#acknowledgements",
    "href": "modules/Module04-RProject.html#acknowledgements",
    "title": "Module 4: R Project",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese are the materials we looked through, modified, or extracted to complete this module’s lecture.",
    "crumbs": [
      "Day 1",
      "Module 4: R Project"
    ]
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Course Schedule",
    "section": "",
    "text": "Meeting times:\nLocation: Randal Rollins Building (RR) 201, Emory University",
    "crumbs": [
      "Course Schedule"
    ]
  },
  {
    "objectID": "schedule.html#day-01-monday",
    "href": "schedule.html#day-01-monday",
    "title": "Course Schedule",
    "section": "Day 01 – Monday",
    "text": "Day 01 – Monday\n\n\n\n\n\n\n\nTime\nSection\n\n\n\n\n08:30 am - 09:00 am\nModule 0 (Amy and Zane)\n\n\n09:00 am - 10:00 am\nModule 1 (Amy)\n\n\n10:00 am - 10:30 am\nCoffee break\n\n\n10:30 am - 11:15 am\nModule 2 (Amy)\n\n\n11:15 am - 11:30 am\nModule 3 (Zane)\n\n\n11:30 am - 12:00 pm\nModule 4 (Zane)\n\n\n12:00 pm - 01:30 pm\nLunch (2nd floor lobby)\n\n\n01:30 pm - 02:15 pm\nModule 5 (Amy)\n\n\n02:15 pm - 02:45 pm\nExercise 1\n\n\n02:45 pm - 03:00 pm\nStart Module 6 (Amy)\n\n\n03:00 pm - 03:30 pm\nCoffee break\n\n\n03:30 pm - 04:00 pm\nFinish Module 6 (Amy or Zane)\n\n\n04:00 pm - 05:00 pm\nModule 7, exercise 2 in remaining time (Zane)\n\n\n05:00 pm - 07:00 pm\nNetworking night and poster session, Randal Rollins P01",
    "crumbs": [
      "Course Schedule"
    ]
  },
  {
    "objectID": "schedule.html#day-02-tuesday",
    "href": "schedule.html#day-02-tuesday",
    "title": "Course Schedule",
    "section": "Day 02 – Tuesday",
    "text": "Day 02 – Tuesday\n\n\n\n\n\n\n\nTime\nSection\n\n\n\n\n08:30 am - 09:00 am\nexercise review and questions / catchup (Zane)\n\n\n09:00 am - 09:15 am\nModule 8 (Amy)\n\n\n09:15 am - 10:00 am\nData analysis walkthrough (Zane and Amy)\n\n\n10:00 am - 10:30 am\nCoffee break\n\n\n10:30 am - 10:45 am\nExercise 3 work time\n\n\n10:45 am - 11:15 am\nExercise review (Zane)\n\n\n11:15 am - 12:00 pm\nModule 9 (Amy)\n\n\n12:00 pm - 01:30 pm\nLunch (2nd floor lobby); Lunch and Learn!\n\n\n01:30 pm - 02:00 pm\nExercise 4\n\n\n02:00 pm - 02:30 pm\nExercise 4 review (Zane)\n\n\n02:30 pm - 03:00 pm\nModule 10 (Amy)\n\n\n03:00 pm - 03:30 pm\nCoffee break\n\n\n03:30 pm - 04:00 pm\nExercise 5\n\n\n04:00 pm - 04:30 pm\nReview exercise 5 (Zane)\n\n\n04:30 pm - 05:00 pm\nModule 11 (Zane)",
    "crumbs": [
      "Course Schedule"
    ]
  },
  {
    "objectID": "schedule.html#day-03-wednesday",
    "href": "schedule.html#day-03-wednesday",
    "title": "Course Schedule",
    "section": "Day 03 – Wednesday",
    "text": "Day 03 – Wednesday\n\n\n\n\n\n\n\nTime\nSection\n\n\n\n\n08:30 am - 10:00 am\ntbd; Modules 12 (Amy) and 13 (Zane)\n\n\n10:00 am - 10:15 am\nCoffee break\n\n\n10:30 am - 12:00 pm\ntbd; Module 14, practice, questions, review",
    "crumbs": [
      "Course Schedule"
    ]
  },
  {
    "objectID": "modules/Module11-RMarkdown.html#learning-goals",
    "href": "modules/Module11-RMarkdown.html#learning-goals",
    "title": "Module 11: Literate Programming",
    "section": "Learning goals",
    "text": "Learning goals\n\nDefine literate programming\nImplement literate programming in R using knitr and either R Markdown or Quarto\nInclude plots, tables, and references along with your code in a written report.\nLocate additional resources for literate programming with R Markdown or Quarto.",
    "crumbs": [
      "Day 2",
      "Module 11: Literate Programming"
    ]
  },
  {
    "objectID": "modules/Module11-RMarkdown.html#what-is-literate-programming",
    "href": "modules/Module11-RMarkdown.html#what-is-literate-programming",
    "title": "Module 11: Literate Programming",
    "section": "What is literate programming?",
    "text": "What is literate programming?\n\nProgramming files contain code along with text, code results, and other supporting information.\nInstead of having separate code and text, that you glue together in Word, we have one document which combines code and text.",
    "crumbs": [
      "Day 2",
      "Module 11: Literate Programming"
    ]
  },
  {
    "objectID": "modules/Module11-RMarkdown.html#what-is-literate-programming-1",
    "href": "modules/Module11-RMarkdown.html#what-is-literate-programming-1",
    "title": "Module 11: Literate Programming",
    "section": "What is literate programming?",
    "text": "What is literate programming?\n\nR markdown example, from https://rmarkdown.rstudio.com/authoring_quick_tour.html",
    "crumbs": [
      "Day 2",
      "Module 11: Literate Programming"
    ]
  },
  {
    "objectID": "modules/Module11-RMarkdown.html#literate-programming-examples",
    "href": "modules/Module11-RMarkdown.html#literate-programming-examples",
    "title": "Module 11: Literate Programming",
    "section": "Literate programming examples",
    "text": "Literate programming examples\n\nWriting a research paper with R Markdown: https://github.com/wzbillings/Patient-vs-Clinician-Symptom-Reports\nWriting a book with R Markdown: https://github.com/moderndive/ModernDive_book\nPersonal websites (like my tutorial!): https://jadeyryan.com/blog/2024-02-19_beginner-quarto-netlify/\nOther examples: https://bookdown.org/yihui/rmarkdown/basics-examples.html",
    "crumbs": [
      "Day 2",
      "Module 11: Literate Programming"
    ]
  },
  {
    "objectID": "modules/Module11-RMarkdown.html#r-markdown-and-quarto",
    "href": "modules/Module11-RMarkdown.html#r-markdown-and-quarto",
    "title": "Module 11: Literate Programming",
    "section": "R Markdown and Quarto",
    "text": "R Markdown and Quarto\n\nR Markdown and Quarto are both implementations of literate programming using R, with the knitr package for the backend. Both are supported by RStudio.\nTo use R Markdown, you need to install.packages(\"rmarkdown\").\nQuarto comes with new versions of RStudio, but you can also install the latest version from the Quarto website.\nR Markdown is older and now very commonly used. Quarto is newer and so has many fancy new features, but more bugs that are constantly being found and fixed.\nIn this class, we will use R Markdown. But if you decide to use quarto, 90% of your knowledge will transfer since they are very similar.\n\nAdvantages of R Markdown: more online resources, most common bugs have been fixed over the years, many people are familiar with it.\nAdvantages of Quarto: supports other programming languages like Python and Julia, uses more modern syntax, less slapped together overall.",
    "crumbs": [
      "Day 2",
      "Module 11: Literate Programming"
    ]
  },
  {
    "objectID": "modules/Module11-RMarkdown.html#a-few-sticking-points",
    "href": "modules/Module11-RMarkdown.html#a-few-sticking-points",
    "title": "Module 11: Literate Programming",
    "section": "A few sticking points",
    "text": "A few sticking points\n\nKnitting to html format is really easy, but most scientist don’t like html format for some reason. If you want to knit to pdf, you should install the package tinytex and read the intro.\nIf you want to knit to word (what many journals in epidemiology require), you need to have Word installed on your computer. Note that with word, you are a bit more restricted in your formatting options, so if weird things happen you’ll have to try some other options.\nYou maybe noticed in the tutorial that I used the here::here() function for all of my file paths. This is because R Markdown and Quarto files use a different working directory from the R Project. Using here::here() translates relative paths into absolute paths based on your R Project, so it makes sure your R Markdown files can always find the right path!",
    "crumbs": [
      "Day 2",
      "Module 11: Literate Programming"
    ]
  },
  {
    "objectID": "modules/Module11-RMarkdown.html#you-try-it",
    "href": "modules/Module11-RMarkdown.html#you-try-it",
    "title": "Module 11: Literate Programming",
    "section": "You try it!",
    "text": "You try it!\n\nCreate an R Markdown document. Write about either the measles or diphtheria example data sets, and include a figure and a table.\nBONUS EXERCISE: read the intro of the bookdown book, and create a bookdown document. Modify your writeup to have a few references with a bibliography, and cross-references with your figures and tables.\nBONUS: Try to structure your document like a report, with a section stating the questions you want to answer (intro), a section with your R code and results, and a section with your interpretations (discussion). This is a very open ended exercise but by now I believe you can do it, and you’ll have a nice document you can put on your portfolio or show employers!",
    "crumbs": [
      "Day 2",
      "Module 11: Literate Programming"
    ]
  },
  {
    "objectID": "modules/Module03-WorkingDirectories.html#learning-objectives",
    "href": "modules/Module03-WorkingDirectories.html#learning-objectives",
    "title": "Module 3: Working Directories",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter module 3, you should be able to…\n\nUnderstand your own systems’ file structure and the purpose of the working directory\nDetermine the working directory\nChange the working directory",
    "crumbs": [
      "Day 1",
      "Module 3: Working Directories"
    ]
  },
  {
    "objectID": "modules/Module03-WorkingDirectories.html#file-structure",
    "href": "modules/Module03-WorkingDirectories.html#file-structure",
    "title": "Module 3: Working Directories",
    "section": "File Structure",
    "text": "File Structure\nThe internal file structure of the computer is completely nested!\n\nknitr::include_graphics(here::here(\"images\", \"presentation4.webp\"))\n\n\nComputer scientists call this the “file tree”.",
    "crumbs": [
      "Day 1",
      "Module 3: Working Directories"
    ]
  },
  {
    "objectID": "modules/Module03-WorkingDirectories.html#working-directory-basic-term",
    "href": "modules/Module03-WorkingDirectories.html#working-directory-basic-term",
    "title": "Module 3: Working Directories",
    "section": "Working Directory – Basic term",
    "text": "Working Directory – Basic term\n\nR “looks” for files on your computer relative to the “working” directory\nFor example, if you want to load data into R or save a figure, you will need to tell R where to look for or store the file\nMany people recommend not setting a directory in the scripts, rather assume you’re in the directory the script is in",
    "crumbs": [
      "Day 1",
      "Module 3: Working Directories"
    ]
  },
  {
    "objectID": "modules/Module03-WorkingDirectories.html#understanding-the-working-directory",
    "href": "modules/Module03-WorkingDirectories.html#understanding-the-working-directory",
    "title": "Module 3: Working Directories",
    "section": "Understanding the working directory",
    "text": "Understanding the working directory",
    "crumbs": [
      "Day 1",
      "Module 3: Working Directories"
    ]
  },
  {
    "objectID": "modules/Module03-WorkingDirectories.html#understanding-the-working-directory-1",
    "href": "modules/Module03-WorkingDirectories.html#understanding-the-working-directory-1",
    "title": "Module 3: Working Directories",
    "section": "Understanding the working directory",
    "text": "Understanding the working directory",
    "crumbs": [
      "Day 1",
      "Module 3: Working Directories"
    ]
  },
  {
    "objectID": "modules/Module03-WorkingDirectories.html#understanding-the-working-directory-2",
    "href": "modules/Module03-WorkingDirectories.html#understanding-the-working-directory-2",
    "title": "Module 3: Working Directories",
    "section": "Understanding the working directory",
    "text": "Understanding the working directory",
    "crumbs": [
      "Day 1",
      "Module 3: Working Directories"
    ]
  },
  {
    "objectID": "modules/Module03-WorkingDirectories.html#understanding-the-working-directory-3",
    "href": "modules/Module03-WorkingDirectories.html#understanding-the-working-directory-3",
    "title": "Module 3: Working Directories",
    "section": "Understanding the working directory",
    "text": "Understanding the working directory",
    "crumbs": [
      "Day 1",
      "Module 3: Working Directories"
    ]
  },
  {
    "objectID": "modules/Module03-WorkingDirectories.html#getting-and-setting-the-working-directory-using-code",
    "href": "modules/Module03-WorkingDirectories.html#getting-and-setting-the-working-directory-using-code",
    "title": "Module 3: Working Directories",
    "section": "Getting and setting the working directory using code",
    "text": "Getting and setting the working directory using code\n\n## get the working directory\ngetwd()\nsetwd(\"~/\")",
    "crumbs": [
      "Day 1",
      "Module 3: Working Directories"
    ]
  },
  {
    "objectID": "modules/Module03-WorkingDirectories.html#setting-a-working-directory",
    "href": "modules/Module03-WorkingDirectories.html#setting-a-working-directory",
    "title": "Module 3: Working Directories",
    "section": "Setting a working directory",
    "text": "Setting a working directory\n\nSetting the directory can sometimes (almost always when new to R) be finicky\n\nWindows: Default directory structure involves single backslashes (“\\”), but R interprets these as”escape” characters. So you must replace the backslash with forward slashes (“/”) or two backslashes (“\\\\”)\nMac/Linux: Default is forward slashes, so you are okay\n\nTypical directory structure syntax applies\n\n“..” - goes up one level\n“./” - is the current directory\n“~” - is your “home” directory",
    "crumbs": [
      "Day 1",
      "Module 3: Working Directories"
    ]
  },
  {
    "objectID": "modules/Module03-WorkingDirectories.html#absolute-vs.-relative-paths",
    "href": "modules/Module03-WorkingDirectories.html#absolute-vs.-relative-paths",
    "title": "Module 3: Working Directories",
    "section": "Absolute vs. relative paths",
    "text": "Absolute vs. relative paths\nFrom Wiki\n\nAn absolute or full path points to the same location in a file system, regardless of the current working directory. To do that, it must include the root directory. Absolute path is specific to your system alone. This means if I try your code, and you use absolute paths, it won’t work unless we have the exact same folder structure where R is looking (bad).\nBy contrast, a relative path starts from some given working directory, avoiding the need to provide the full absolute path.",
    "crumbs": [
      "Day 1",
      "Module 3: Working Directories"
    ]
  },
  {
    "objectID": "modules/Module03-WorkingDirectories.html#relative-path",
    "href": "modules/Module03-WorkingDirectories.html#relative-path",
    "title": "Module 3: Working Directories",
    "section": "Relative path",
    "text": "Relative path\nYou want to set you code up based on relative paths. This allows sharing of code, and also, allows you to modify your own file structure (above the working directory) without breaking your own code.",
    "crumbs": [
      "Day 1",
      "Module 3: Working Directories"
    ]
  },
  {
    "objectID": "modules/Module03-WorkingDirectories.html#setting-the-working-directory-using-your-cursor",
    "href": "modules/Module03-WorkingDirectories.html#setting-the-working-directory-using-your-cursor",
    "title": "Module 3: Working Directories",
    "section": "Setting the working directory using your cursor",
    "text": "Setting the working directory using your cursor\nRemember above “Many people recommend not setting a directory in the scripts, rather assume you’re in the directory the script is in.” To do so, go to Session –&gt; Set Working Directory –&gt; To Source File Location\nRStudio will show the code in the Console for the action you took with your cursor. This is a good way to learn about your file system how to set a correct working directory!\n\nsetwd(\"~/Dropbox/Git/SISMID-2024\")",
    "crumbs": [
      "Day 1",
      "Module 3: Working Directories"
    ]
  },
  {
    "objectID": "modules/Module03-WorkingDirectories.html#setting-the-working-directory",
    "href": "modules/Module03-WorkingDirectories.html#setting-the-working-directory",
    "title": "Module 3: Working Directories",
    "section": "Setting the Working Directory",
    "text": "Setting the Working Directory\nIf you have not yet saved a “source” file, it will set working directory to the default location.Find the Tool Menu in the Menu Bar -&gt; Global Opsions -&gt; General for default location.\nTo change the working directory to another location, find Session Menu in the Menu Bar –&gt; Set Working Directory –&gt; Choose Directory`\nAgain, RStudio will show the code in the Console for the action you took with your cursor.",
    "crumbs": [
      "Day 1",
      "Module 3: Working Directories"
    ]
  },
  {
    "objectID": "modules/Module03-WorkingDirectories.html#summary",
    "href": "modules/Module03-WorkingDirectories.html#summary",
    "title": "Module 3: Working Directories",
    "section": "Summary",
    "text": "Summary\n\nR “looks” for files on your computer relative to the “working” directory\nAbsolute path points to the same location in a file system - it is specific to your system and your system alone\nRelative path points is based on the current working directory\nTwo functions, setwd() and getwd() are useful for identifying and manipulating the working directory.",
    "crumbs": [
      "Day 1",
      "Module 3: Working Directories"
    ]
  },
  {
    "objectID": "modules/Module03-WorkingDirectories.html#acknowledgements",
    "href": "modules/Module03-WorkingDirectories.html#acknowledgements",
    "title": "Module 3: Working Directories",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese are the materials we looked through, modified, or extracted to complete this module’s lecture.\n\n“Introduction to R for Public Health Researchers” Johns Hopkins University",
    "crumbs": [
      "Day 1",
      "Module 3: Working Directories"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#learning-objectives",
    "href": "modules/Module05-DataImportExport.html#learning-objectives",
    "title": "Module 5: Data Import and Export",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter module 5, you should be able to…\n\nUse Base R functions to load data\nInstall and attach external R Packages to extend R’s functionality\nLoad any type of data into R\nFind loaded data in the Environment pane of RStudio\nReading and writing R .Rds and .Rda/.RData files",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#import-read-data",
    "href": "modules/Module05-DataImportExport.html#import-read-data",
    "title": "Module 5: Data Import and Export",
    "section": "Import (read) Data",
    "text": "Import (read) Data\n\nImporting or ‘Reading in’ data are the first step of any real project / data analysis\nR can read almost any file format, especially with external, non-Base R, packages\nWe are going to focus on simple delimited files first.\n\ncomma separated (e.g. ‘.csv’)\ntab delimited (e.g. ‘.txt’)\n\n\nA delimited file is a sequential file with column delimiters. Each delimited file is a stream of records, which consists of fields that are ordered by column. Each record contains fields for one row. Within each row, individual fields are separated by column delimiters (IBM.com definition)",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#mini-exercise",
    "href": "modules/Module05-DataImportExport.html#mini-exercise",
    "title": "Module 5: Data Import and Export",
    "section": "Mini exercise",
    "text": "Mini exercise\n\nDownload Module 5 data from the website and save the data to your data subdirectory – specifically SISMID_IntroToR_RProject/data\nOpen the ‘.csv’ and ‘.txt’ data files in a text editor application and familiarize yourself with the data (i.e., Notepad for Windows and TextEdit for Mac)\nOpen the ‘.xlsx’ data file in excel and familiarize yourself with the data - if you use a Mac do not open in Numbers, it can corrupt the file - if you do not have excel, you can upload it to Google Sheets\nDetermine the delimiter of the two ‘.txt’ files",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#mini-exercise-1",
    "href": "modules/Module05-DataImportExport.html#mini-exercise-1",
    "title": "Module 5: Data Import and Export",
    "section": "Mini exercise",
    "text": "Mini exercise",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#import-delimited-data",
    "href": "modules/Module05-DataImportExport.html#import-delimited-data",
    "title": "Module 5: Data Import and Export",
    "section": "Import delimited data",
    "text": "Import delimited data\nWithin the Base R ‘util’ package we can find a handful of useful functions including read.csv() and read.delim() to importing data.\n\n?read.csv\n\n\n\nRegistered S3 method overwritten by 'printr':\n  method                from     \n  knit_print.data.frame rmarkdown\n\n\nData Input\n\nDescription:\n\n     Reads a file in table format and creates a data frame from it,\n     with cases corresponding to lines and variables to fields in the\n     file.\n\nUsage:\n\n     read.table(file, header = FALSE, sep = \"\", quote = \"\\\"'\",\n                dec = \".\", numerals = c(\"allow.loss\", \"warn.loss\", \"no.loss\"),\n                row.names, col.names, as.is = !stringsAsFactors, tryLogical = TRUE,\n                na.strings = \"NA\", colClasses = NA, nrows = -1,\n                skip = 0, check.names = TRUE, fill = !blank.lines.skip,\n                strip.white = FALSE, blank.lines.skip = TRUE,\n                comment.char = \"#\",\n                allowEscapes = FALSE, flush = FALSE,\n                stringsAsFactors = FALSE,\n                fileEncoding = \"\", encoding = \"unknown\", text, skipNul = FALSE)\n     \n     read.csv(file, header = TRUE, sep = \",\", quote = \"\\\"\",\n              dec = \".\", fill = TRUE, comment.char = \"\", ...)\n     \n     read.csv2(file, header = TRUE, sep = \";\", quote = \"\\\"\",\n               dec = \",\", fill = TRUE, comment.char = \"\", ...)\n     \n     read.delim(file, header = TRUE, sep = \"\\t\", quote = \"\\\"\",\n                dec = \".\", fill = TRUE, comment.char = \"\", ...)\n     \n     read.delim2(file, header = TRUE, sep = \"\\t\", quote = \"\\\"\",\n                 dec = \",\", fill = TRUE, comment.char = \"\", ...)\n     \nArguments:\n\n    file: the name of the file which the data are to be read from.\n          Each row of the table appears as one line of the file.  If it\n          does not contain an _absolute_ path, the file name is\n          _relative_ to the current working directory, 'getwd()'.\n          Tilde-expansion is performed where supported.  This can be a\n          compressed file (see 'file').\n\n          Alternatively, 'file' can be a readable text-mode connection\n          (which will be opened for reading if necessary, and if so\n          'close'd (and hence destroyed) at the end of the function\n          call).  (If 'stdin()' is used, the prompts for lines may be\n          somewhat confusing.  Terminate input with a blank line or an\n          EOF signal, 'Ctrl-D' on Unix and 'Ctrl-Z' on Windows.  Any\n          pushback on 'stdin()' will be cleared before return.)\n\n          'file' can also be a complete URL.  (For the supported URL\n          schemes, see the 'URLs' section of the help for 'url'.)\n\n  header: a logical value indicating whether the file contains the\n          names of the variables as its first line.  If missing, the\n          value is determined from the file format: 'header' is set to\n          'TRUE' if and only if the first row contains one fewer field\n          than the number of columns.\n\n     sep: the field separator character.  Values on each line of the\n          file are separated by this character.  If 'sep = \"\"' (the\n          default for 'read.table') the separator is 'white space',\n          that is one or more spaces, tabs, newlines or carriage\n          returns.\n\n   quote: the set of quoting characters. To disable quoting altogether,\n          use 'quote = \"\"'.  See 'scan' for the behaviour on quotes\n          embedded in quotes.  Quoting is only considered for columns\n          read as character, which is all of them unless 'colClasses'\n          is specified.\n\n     dec: the character used in the file for decimal points.\n\nnumerals: string indicating how to convert numbers whose conversion to\n          double precision would lose accuracy, see 'type.convert'.\n          Can be abbreviated.  (Applies also to complex-number inputs.)\n\nrow.names: a vector of row names.  This can be a vector giving the\n          actual row names, or a single number giving the column of the\n          table which contains the row names, or character string\n          giving the name of the table column containing the row names.\n\n          If there is a header and the first row contains one fewer\n          field than the number of columns, the first column in the\n          input is used for the row names.  Otherwise if 'row.names' is\n          missing, the rows are numbered.\n\n          Using 'row.names = NULL' forces row numbering. Missing or\n          'NULL' 'row.names' generate row names that are considered to\n          be 'automatic' (and not preserved by 'as.matrix').\n\ncol.names: a vector of optional names for the variables.  The default\n          is to use '\"V\"' followed by the column number.\n\n   as.is: controls conversion of character variables (insofar as they\n          are not converted to logical, numeric or complex) to factors,\n          if not otherwise specified by 'colClasses'.  Its value is\n          either a vector of logicals (values are recycled if\n          necessary), or a vector of numeric or character indices which\n          specify which columns should not be converted to factors.\n\n          Note: to suppress all conversions including those of numeric\n          columns, set 'colClasses = \"character\"'.\n\n          Note that 'as.is' is specified per column (not per variable)\n          and so includes the column of row names (if any) and any\n          columns to be skipped.\n\ntryLogical: a 'logical' determining if columns consisting entirely of\n          '\"F\"', '\"T\"', '\"FALSE\"', and '\"TRUE\"' should be converted to\n          'logical'; passed to 'type.convert', true by default.\n\nna.strings: a character vector of strings which are to be interpreted\n          as 'NA' values.  Blank fields are also considered to be\n          missing values in logical, integer, numeric and complex\n          fields.  Note that the test happens _after_ white space is\n          stripped from the input, so 'na.strings' values may need\n          their own white space stripped in advance.\n\ncolClasses: character.  A vector of classes to be assumed for the\n          columns.  If unnamed, recycled as necessary.  If named, names\n          are matched with unspecified values being taken to be 'NA'.\n\n          Possible values are 'NA' (the default, when 'type.convert' is\n          used), '\"NULL\"' (when the column is skipped), one of the\n          atomic vector classes (logical, integer, numeric, complex,\n          character, raw), or '\"factor\"', '\"Date\"' or '\"POSIXct\"'.\n          Otherwise there needs to be an 'as' method (from package\n          'methods') for conversion from '\"character\"' to the specified\n          formal class.\n\n          Note that 'colClasses' is specified per column (not per\n          variable) and so includes the column of row names (if any).\n\n   nrows: integer: the maximum number of rows to read in.  Negative and\n          other invalid values are ignored.\n\n    skip: integer: the number of lines of the data file to skip before\n          beginning to read data.\n\ncheck.names: logical.  If 'TRUE' then the names of the variables in the\n          data frame are checked to ensure that they are syntactically\n          valid variable names.  If necessary they are adjusted (by\n          'make.names') so that they are, and also to ensure that there\n          are no duplicates.\n\n    fill: logical. If 'TRUE' then in case the rows have unequal length,\n          blank fields are implicitly added.  See 'Details'.\n\nstrip.white: logical. Used only when 'sep' has been specified, and\n          allows the stripping of leading and trailing white space from\n          unquoted 'character' fields ('numeric' fields are always\n          stripped).  See 'scan' for further details (including the\n          exact meaning of 'white space'), remembering that the columns\n          may include the row names.\n\nblank.lines.skip: logical: if 'TRUE' blank lines in the input are\n          ignored.\n\ncomment.char: character: a character vector of length one containing a\n          single character or an empty string.  Use '\"\"' to turn off\n          the interpretation of comments altogether.\n\nallowEscapes: logical.  Should C-style escapes such as '\\n' be\n          processed or read verbatim (the default)?  Note that if not\n          within quotes these could be interpreted as a delimiter (but\n          not as a comment character).  For more details see 'scan'.\n\n   flush: logical: if 'TRUE', 'scan' will flush to the end of the line\n          after reading the last of the fields requested.  This allows\n          putting comments after the last field.\n\nstringsAsFactors: logical: should character vectors be converted to\n          factors?  Note that this is overridden by 'as.is' and\n          'colClasses', both of which allow finer control.\n\nfileEncoding: character string: if non-empty declares the encoding used\n          on a file (not a connection) so the character data can be\n          re-encoded.  See the 'Encoding' section of the help for\n          'file', the 'R Data Import/Export' manual and 'Note'.\n\nencoding: encoding to be assumed for input strings.  It is used to mark\n          character strings as known to be in Latin-1 or UTF-8 (see\n          'Encoding'): it is not used to re-encode the input, but\n          allows R to handle encoded strings in their native encoding\n          (if one of those two).  See 'Value' and 'Note'.\n\n    text: character string: if 'file' is not supplied and this is, then\n          data are read from the value of 'text' via a text connection.\n          Notice that a literal string can be used to include (small)\n          data sets within R code.\n\n skipNul: logical: should nuls be skipped?\n\n     ...: Further arguments to be passed to 'read.table'.\n\nDetails:\n\n     This function is the principal means of reading tabular data into\n     R.\n\n     Unless 'colClasses' is specified, all columns are read as\n     character columns and then converted using 'type.convert' to\n     logical, integer, numeric, complex or (depending on 'as.is')\n     factor as appropriate.  Quotes are (by default) interpreted in all\n     fields, so a column of values like '\"42\"' will result in an\n     integer column.\n\n     A field or line is 'blank' if it contains nothing (except\n     whitespace if no separator is specified) before a comment\n     character or the end of the field or line.\n\n     If 'row.names' is not specified and the header line has one less\n     entry than the number of columns, the first column is taken to be\n     the row names.  This allows data frames to be read in from the\n     format in which they are printed.  If 'row.names' is specified and\n     does not refer to the first column, that column is discarded from\n     such files.\n\n     The number of data columns is determined by looking at the first\n     five lines of input (or the whole input if it has less than five\n     lines), or from the length of 'col.names' if it is specified and\n     is longer.  This could conceivably be wrong if 'fill' or\n     'blank.lines.skip' are true, so specify 'col.names' if necessary\n     (as in the 'Examples').\n\n     'read.csv' and 'read.csv2' are identical to 'read.table' except\n     for the defaults.  They are intended for reading 'comma separated\n     value' files ('.csv') or ('read.csv2') the variant used in\n     countries that use a comma as decimal point and a semicolon as\n     field separator.  Similarly, 'read.delim' and 'read.delim2' are\n     for reading delimited files, defaulting to the TAB character for\n     the delimiter.  Notice that 'header = TRUE' and 'fill = TRUE' in\n     these variants, and that the comment character is disabled.\n\n     The rest of the line after a comment character is skipped; quotes\n     are not processed in comments.  Complete comment lines are allowed\n     provided 'blank.lines.skip = TRUE'; however, comment lines prior\n     to the header must have the comment character in the first\n     non-blank column.\n\n     Quoted fields with embedded newlines are supported except after a\n     comment character.  Embedded nuls are unsupported: skipping them\n     (with 'skipNul = TRUE') may work.\n\nValue:\n\n     A data frame ('data.frame') containing a representation of the\n     data in the file.\n\n     Empty input is an error unless 'col.names' is specified, when a\n     0-row data frame is returned: similarly giving just a header line\n     if 'header = TRUE' results in a 0-row data frame.  Note that in\n     either case the columns will be logical unless 'colClasses' was\n     supplied.\n\n     Character strings in the result (including factor levels) will\n     have a declared encoding if 'encoding' is '\"latin1\"' or '\"UTF-8\"'.\n\nCSV files:\n\n     See the help on 'write.csv' for the various conventions for '.csv'\n     files.  The commonest form of CSV file with row names needs to be\n     read with 'read.csv(..., row.names = 1)' to use the names in the\n     first column of the file as row names.\n\nMemory usage:\n\n     These functions can use a surprising amount of memory when reading\n     large files.  There is extensive discussion in the 'R Data\n     Import/Export' manual, supplementing the notes here.\n\n     Less memory will be used if 'colClasses' is specified as one of\n     the six atomic vector classes.  This can be particularly so when\n     reading a column that takes many distinct numeric values, as\n     storing each distinct value as a character string can take up to\n     14 times as much memory as storing it as an integer.\n\n     Using 'nrows', even as a mild over-estimate, will help memory\n     usage.\n\n     Using 'comment.char = \"\"' will be appreciably faster than the\n     'read.table' default.\n\n     'read.table' is not the right tool for reading large matrices,\n     especially those with many columns: it is designed to read _data\n     frames_ which may have columns of very different classes.  Use\n     'scan' instead for matrices.\n\nNote:\n\n     The columns referred to in 'as.is' and 'colClasses' include the\n     column of row names (if any).\n\n     There are two approaches for reading input that is not in the\n     local encoding.  If the input is known to be UTF-8 or Latin1, use\n     the 'encoding' argument to declare that.  If the input is in some\n     other encoding, then it may be translated on input.  The\n     'fileEncoding' argument achieves this by setting up a connection\n     to do the re-encoding into the current locale.  Note that on\n     Windows or other systems not running in a UTF-8 locale, this may\n     not be possible.\n\nReferences:\n\n     Chambers, J. M. (1992) _Data for models._ Chapter 3 of\n     _Statistical Models in S_ eds J. M. Chambers and T. J. Hastie,\n     Wadsworth & Brooks/Cole.\n\nSee Also:\n\n     The 'R Data Import/Export' manual.\n\n     'scan', 'type.convert', 'read.fwf' for reading _f_ixed _w_idth\n     _f_ormatted input; 'write.table'; 'data.frame'.\n\n     'count.fields' can be useful to determine problems with reading\n     files which result in reports of incorrect record lengths (see the\n     'Examples' below).\n\n     &lt;https://www.rfc-editor.org/rfc/rfc4180&gt; for the IANA definition\n     of CSV files (which requires comma as separator and CRLF line\n     endings).\n\nExamples:\n\n     ## using count.fields to handle unknown maximum number of fields\n     ## when fill = TRUE\n     test1 &lt;- c(1:5, \"6,7\", \"8,9,10\")\n     tf &lt;- tempfile()\n     writeLines(test1, tf)\n     \n     read.csv(tf, fill = TRUE) # 1 column\n     ncol &lt;- max(count.fields(tf, sep = \",\"))\n     read.csv(tf, fill = TRUE, header = FALSE,\n              col.names = paste0(\"V\", seq_len(ncol)))\n     unlink(tf)\n     \n     ## \"Inline\" data set, using text=\n     ## Notice that leading and trailing empty lines are auto-trimmed\n     \n     read.table(header = TRUE, text = \"\n     a b\n     1 2\n     3 4\n     \")",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#import-.csv-files",
    "href": "modules/Module05-DataImportExport.html#import-.csv-files",
    "title": "Module 5: Data Import and Export",
    "section": "Import .csv files",
    "text": "Import .csv files\nFunction signature reminder\nread.csv(file, header = TRUE, sep = \",\", quote = \"\\\"\",\n         dec = \".\", fill = TRUE, comment.char = \"\", ...)\n\n## Examples\ndf &lt;- read.csv(file = \"data/serodata.csv\") #relative path\n\nNote #1, I assigned the data frame to an object called df. I could have called the data anything, but in order to use the data (i.e., as an object we can find in the Environment), I need to assign it as an object.\nNote #2, If the data is imported correct, you can expect to see the df object ready to be used.",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#import-.txt-files",
    "href": "modules/Module05-DataImportExport.html#import-.txt-files",
    "title": "Module 5: Data Import and Export",
    "section": "Import .txt files",
    "text": "Import .txt files\nread.csv() is a special case of read.delim() – a general function to read a delimited file into a data frame\nReminder function signature\nread.delim(file, header = TRUE, sep = \"\\t\", quote = \"\\\"\",\n           dec = \".\", fill = TRUE, comment.char = \"\", ...)\n    - `file` is the path to your file, in quotes \n    - `delim` is what separates the fields within a record. The default for csv is comma\nWe can import the ‘.txt’ files given that we know that ‘serodata1.txt’ uses a tab delimiter and ‘serodata2.txt’ uses a semicolon delimiter.\n\n## Examples\ndf &lt;- read.delim(file = \"data/serodata.txt\", sep = \"\\t\")\ndf &lt;- read.delim(file = \"data/serodata.txt\", sep = \";\")\n\nThe dataset is now successfully read into your R workspace, many times actually. Notice, that each time we imported the data we assigned the data to the df object, meaning we replaced it each time we reassigned the df object.",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#what-if-we-have-a-.xlsx-file---what-do-we-do",
    "href": "modules/Module05-DataImportExport.html#what-if-we-have-a-.xlsx-file---what-do-we-do",
    "title": "Module 5: Data Import and Export",
    "section": "What if we have a .xlsx file - what do we do?",
    "text": "What if we have a .xlsx file - what do we do?\n\nAsk Google / ChatGPT\nFind and vet function and package you want\nInstall package\nAttach package\nUse function",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#internet-search",
    "href": "modules/Module05-DataImportExport.html#internet-search",
    "title": "Module 5: Data Import and Export",
    "section": "1. Internet Search",
    "text": "1. Internet Search",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#find-and-vet-function-and-package-you-want",
    "href": "modules/Module05-DataImportExport.html#find-and-vet-function-and-package-you-want",
    "title": "Module 5: Data Import and Export",
    "section": "2. Find and vet function and package you want",
    "text": "2. Find and vet function and package you want\nI am getting consistent message to use the the read_excel() function found in the readxl package. This package was developed by Hadley Wickham, who we know is reputable. Also, you can check that data was read in correctly, b/c this is a straightforward task.",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#install-package",
    "href": "modules/Module05-DataImportExport.html#install-package",
    "title": "Module 5: Data Import and Export",
    "section": "3. Install Package",
    "text": "3. Install Package\nTo use the bundle or “package” of code (and or possibly data) from a package, you need to install and also attach the package.\nTo install a package you can\n\ngo to Tools —&gt; Install Packages in the RStudio header\n\nOR\n\nuse the following code:\n\n\ninstall.packages(\"package_name\")\n\nTherefore,\n\ninstall.packages(\"readxl\")",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#attach-package",
    "href": "modules/Module05-DataImportExport.html#attach-package",
    "title": "Module 5: Data Import and Export",
    "section": "4. Attach Package",
    "text": "4. Attach Package\nReminder - To attach (i.e., be able to use the package) you can use the following code:\n\nrequire(package_name)\n\nTherefore,\n\nrequire(readxl)",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#use-function",
    "href": "modules/Module05-DataImportExport.html#use-function",
    "title": "Module 5: Data Import and Export",
    "section": "5. Use Function",
    "text": "5. Use Function\n\n?read_excel\n\nRead xls and xlsx files\nDescription:\n Read xls and xlsx files\n\n 'read_excel()' calls 'excel_format()' to determine if 'path' is\n xls or xlsx, based on the file extension and the file itself, in\n that order. Use 'read_xls()' and 'read_xlsx()' directly if you\n know better and want to prevent such guessing.\nUsage:\n read_excel(\n   path,\n   sheet = NULL,\n   range = NULL,\n   col_names = TRUE,\n   col_types = NULL,\n   na = \"\",\n   trim_ws = TRUE,\n   skip = 0,\n   n_max = Inf,\n   guess_max = min(1000, n_max),\n   progress = readxl_progress(),\n   .name_repair = \"unique\"\n )\n \n read_xls(\n   path,\n   sheet = NULL,\n   range = NULL,\n   col_names = TRUE,\n   col_types = NULL,\n   na = \"\",\n   trim_ws = TRUE,\n   skip = 0,\n   n_max = Inf,\n   guess_max = min(1000, n_max),\n   progress = readxl_progress(),\n   .name_repair = \"unique\"\n )\n \n read_xlsx(\n   path,\n   sheet = NULL,\n   range = NULL,\n   col_names = TRUE,\n   col_types = NULL,\n   na = \"\",\n   trim_ws = TRUE,\n   skip = 0,\n   n_max = Inf,\n   guess_max = min(1000, n_max),\n   progress = readxl_progress(),\n   .name_repair = \"unique\"\n )\n \nArguments:\npath: Path to the xls/xlsx file.\nsheet: Sheet to read. Either a string (the name of a sheet), or an integer (the position of the sheet). Ignored if the sheet is specified via ‘range’. If neither argument specifies the sheet, defaults to the first sheet.\nrange: A cell range to read from, as described in cell-specification. Includes typical Excel ranges like “B3:D87”, possibly including the sheet name like “Budget!B2:G14”, and more. Interpreted strictly, even if the range forces the inclusion of leading or trailing empty rows or columns. Takes precedence over ‘skip’, ‘n_max’ and ‘sheet’.\ncol_names: ‘TRUE’ to use the first row as column names, ‘FALSE’ to get default names, or a character vector giving a name for each column. If user provides ‘col_types’ as a vector, ‘col_names’ can have one entry per column, i.e. have the same length as ‘col_types’, or one entry per unskipped column.\ncol_types: Either ‘NULL’ to guess all from the spreadsheet or a character vector containing one entry per column from these options: “skip”, “guess”, “logical”, “numeric”, “date”, “text” or “list”. If exactly one ‘col_type’ is specified, it will be recycled. The content of a cell in a skipped column is never read and that column will not appear in the data frame output. A list cell loads a column as a list of length 1 vectors, which are typed using the type guessing logic from ‘col_types = NULL’, but on a cell-by-cell basis.\n  na: Character vector of strings to interpret as missing values.\n      By default, readxl treats blank cells as missing data.\ntrim_ws: Should leading and trailing whitespace be trimmed?\nskip: Minimum number of rows to skip before reading anything, be it\n      column names or data. Leading empty rows are automatically\n      skipped, so this is a lower bound. Ignored if 'range' is\n      given.\nn_max: Maximum number of data rows to read. Trailing empty rows are automatically skipped, so this is an upper bound on the number of rows in the returned tibble. Ignored if ‘range’ is given.\nguess_max: Maximum number of data rows to use for guessing column types.\nprogress: Display a progress spinner? By default, the spinner appears only in an interactive session, outside the context of knitting a document, and when the call is likely to run for several seconds or more. See ‘readxl_progress()’ for more details.\n.name_repair: Handling of column names. Passed along to ‘tibble::as_tibble()’. readxl’s default is `.name_repair = “unique”, which ensures column names are not empty and are unique.\nValue:\n A tibble\nSee Also:\n cell-specification for more details on targetting cells with the\n 'range' argument\nExamples:\n datasets &lt;- readxl_example(\"datasets.xlsx\")\n read_excel(datasets)\n \n # Specify sheet either by position or by name\n read_excel(datasets, 2)\n read_excel(datasets, \"mtcars\")\n \n # Skip rows and use default column names\n read_excel(datasets, skip = 148, col_names = FALSE)\n \n # Recycle a single column type\n read_excel(datasets, col_types = \"text\")\n \n # Specify some col_types and guess others\n read_excel(datasets, col_types = c(\"text\", \"guess\", \"numeric\", \"guess\", \"guess\"))\n \n # Accomodate a column with disparate types via col_type = \"list\"\n df &lt;- read_excel(readxl_example(\"clippy.xlsx\"), col_types = c(\"text\", \"list\"))\n df\n df$value\n sapply(df$value, class)\n \n # Limit the number of data rows read\n read_excel(datasets, n_max = 3)\n \n # Read from an Excel range using A1 or R1C1 notation\n read_excel(datasets, range = \"C1:E7\")\n read_excel(datasets, range = \"R1C2:R2C5\")\n \n # Specify the sheet as part of the range\n read_excel(datasets, range = \"mtcars!B1:D5\")\n \n # Read only specific rows or columns\n read_excel(datasets, range = cell_rows(102:151), col_names = FALSE)\n read_excel(datasets, range = cell_cols(\"B:D\"))\n \n # Get a preview of column names\n names(read_excel(readxl_example(\"datasets.xlsx\"), n_max = 0))\n \n # exploit full .name_repair flexibility from tibble\n \n # \"universal\" names are unique and syntactic\n read_excel(\n   readxl_example(\"deaths.xlsx\"),\n   range = \"arts!A5:F15\",\n   .name_repair = \"universal\"\n )\n \n # specify name repair as a built-in function\n read_excel(readxl_example(\"clippy.xlsx\"), .name_repair = toupper)\n \n # specify name repair as a custom function\n my_custom_name_repair &lt;- function(nms) tolower(gsub(\"[.]\", \"_\", nms))\n read_excel(\n   readxl_example(\"datasets.xlsx\"),\n   .name_repair = my_custom_name_repair\n )\n \n # specify name repair as an anonymous function\n read_excel(\n   readxl_example(\"datasets.xlsx\"),\n   sheet = \"chickwts\",\n   .name_repair = ~ substr(.x, start = 1, stop = 3)\n )",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#use-function-1",
    "href": "modules/Module05-DataImportExport.html#use-function-1",
    "title": "Module 5: Data Import and Export",
    "section": "5. Use Function",
    "text": "5. Use Function\nReminder of function signature\nread_excel(\n  path,\n  sheet = NULL,\n  range = NULL,\n  col_names = TRUE,\n  col_types = NULL,\n  na = \"\",\n  trim_ws = TRUE,\n  skip = 0,\n  n_max = Inf,\n  guess_max = min(1000, n_max),\n  progress = readxl_progress(),\n  .name_repair = \"unique\"\n)\nLet’s practice\n\ndf &lt;- read_excel(path = \"data/serodata.xlsx\", sheet = \"Data\")",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#what-would-happen-if-we-made-these-mistakes",
    "href": "modules/Module05-DataImportExport.html#what-would-happen-if-we-made-these-mistakes",
    "title": "Module 5: Data Import and Export",
    "section": "What would happen if we made these mistakes (*)",
    "text": "What would happen if we made these mistakes (*)\n\nWhat do you think would happen if I had imported the data without assigning it to an object\n\n\nread_excel(path = \"data/serodata.xlsx\", sheet = \"Data\")\n\n\nWhat do you think would happen if I forgot to specify the sheet argument?\n\n\ndd &lt;- read_excel(path = \"data/serodata.xlsx\")",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#installing-and-attaching-packages---common-confusion",
    "href": "modules/Module05-DataImportExport.html#installing-and-attaching-packages---common-confusion",
    "title": "Module 5: Data Import and Export",
    "section": "Installing and attaching packages - Common confusion",
    "text": "Installing and attaching packages - Common confusion\n\nYou only need to install a package once (unless you update R or want to update the package), but you will need to attach a package each time you want to use it.\n\nThe exception to this rule are the “base” set of packages (i.e., Base R) that are installed automatically when you install R and that automatically attached whenever you open R or RStudio.",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#common-error",
    "href": "modules/Module05-DataImportExport.html#common-error",
    "title": "Module 5: Data Import and Export",
    "section": "Common Error",
    "text": "Common Error\nBe prepared to see this error\n\nError: could not find function \"some_function_name\"\n\nThis usually means that either\n\nyou called the function by the wrong name\nyou have not installed a package that contains the function\nyou have installed a package but you forgot to attach it (i.e., require(package_name)) – most likely",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#export-write-data",
    "href": "modules/Module05-DataImportExport.html#export-write-data",
    "title": "Module 5: Data Import and Export",
    "section": "Export (write) Data",
    "text": "Export (write) Data\n\nExporting or ‘Writing out’ data allows you to save modified files for future use or sharing\nR can write almost any file format, especially with external, non-Base R, packages\nWe are going to focus again on writing delimited files",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#export-delimited-data",
    "href": "modules/Module05-DataImportExport.html#export-delimited-data",
    "title": "Module 5: Data Import and Export",
    "section": "Export delimited data",
    "text": "Export delimited data\nWithin the Base R ‘util’ package we can find a handful of useful functions including write.csv() and write.table() to exporting data.\n\n\nData Output\n\nDescription:\n\n     'write.table' prints its required argument 'x' (after converting\n     it to a data frame if it is not one nor a matrix) to a file or\n     connection.\n\nUsage:\n\n     write.table(x, file = \"\", append = FALSE, quote = TRUE, sep = \" \",\n                 eol = \"\\n\", na = \"NA\", dec = \".\", row.names = TRUE,\n                 col.names = TRUE, qmethod = c(\"escape\", \"double\"),\n                 fileEncoding = \"\")\n     \n     write.csv(...)\n     write.csv2(...)\n     \nArguments:\n\n       x: the object to be written, preferably a matrix or data frame.\n          If not, it is attempted to coerce 'x' to a data frame.\n\n    file: either a character string naming a file or a connection open\n          for writing.  '\"\"' indicates output to the console.\n\n  append: logical. Only relevant if 'file' is a character string.  If\n          'TRUE', the output is appended to the file.  If 'FALSE', any\n          existing file of the name is destroyed.\n\n   quote: a logical value ('TRUE' or 'FALSE') or a numeric vector.  If\n          'TRUE', any character or factor columns will be surrounded by\n          double quotes.  If a numeric vector, its elements are taken\n          as the indices of columns to quote.  In both cases, row and\n          column names are quoted if they are written.  If 'FALSE',\n          nothing is quoted.\n\n     sep: the field separator string.  Values within each row of 'x'\n          are separated by this string.\n\n     eol: the character(s) to print at the end of each line (row).  For\n          example, 'eol = \"\\r\\n\"' will produce Windows' line endings on\n          a Unix-alike OS, and 'eol = \"\\r\"' will produce files as\n          expected by Excel:mac 2004.\n\n      na: the string to use for missing values in the data.\n\n     dec: the string to use for decimal points in numeric or complex\n          columns: must be a single character.\n\nrow.names: either a logical value indicating whether the row names of\n          'x' are to be written along with 'x', or a character vector\n          of row names to be written.\n\ncol.names: either a logical value indicating whether the column names\n          of 'x' are to be written along with 'x', or a character\n          vector of column names to be written.  See the section on\n          'CSV files' for the meaning of 'col.names = NA'.\n\n qmethod: a character string specifying how to deal with embedded\n          double quote characters when quoting strings.  Must be one of\n          '\"escape\"' (default for 'write.table'), in which case the\n          quote character is escaped in C style by a backslash, or\n          '\"double\"' (default for 'write.csv' and 'write.csv2'), in\n          which case it is doubled.  You can specify just the initial\n          letter.\n\nfileEncoding: character string: if non-empty declares the encoding to\n          be used on a file (not a connection) so the character data\n          can be re-encoded as they are written.  See 'file'.\n\n     ...: arguments to 'write.table': 'append', 'col.names', 'sep',\n          'dec' and 'qmethod' cannot be altered.\n\nDetails:\n\n     If the table has no columns the rownames will be written only if\n     'row.names = TRUE', and _vice versa_.\n\n     Real and complex numbers are written to the maximal possible\n     precision.\n\n     If a data frame has matrix-like columns these will be converted to\n     multiple columns in the result (_via_ 'as.matrix') and so a\n     character 'col.names' or a numeric 'quote' should refer to the\n     columns in the result, not the input.  Such matrix-like columns\n     are unquoted by default.\n\n     Any columns in a data frame which are lists or have a class (e.g.,\n     dates) will be converted by the appropriate 'as.character' method:\n     such columns are unquoted by default.  On the other hand, any\n     class information for a matrix is discarded and non-atomic (e.g.,\n     list) matrices are coerced to character.\n\n     Only columns which have been converted to character will be quoted\n     if specified by 'quote'.\n\n     The 'dec' argument only applies to columns that are not subject to\n     conversion to character because they have a class or are part of a\n     matrix-like column (or matrix), in particular to columns protected\n     by 'I()'.  Use 'options(\"OutDec\")' to control such conversions.\n\n     In almost all cases the conversion of numeric quantities is\n     governed by the option '\"scipen\"' (see 'options'), but with the\n     internal equivalent of 'digits = 15'.  For finer control, use\n     'format' to make a character matrix/data frame, and call\n     'write.table' on that.\n\n     These functions check for a user interrupt every 1000 lines of\n     output.\n\n     If 'file' is a non-open connection, an attempt is made to open it\n     and then close it after use.\n\n     To write a Unix-style file on Windows, use a binary connection\n     e.g. 'file = file(\"filename\", \"wb\")'.\n\nCSV files:\n\n     By default there is no column name for a column of row names.  If\n     'col.names = NA' and 'row.names = TRUE' a blank column name is\n     added, which is the convention used for CSV files to be read by\n     spreadsheets.  Note that such CSV files can be read in R by\n\n       read.csv(file = \"&lt;filename&gt;\", row.names = 1)\n     \n     'write.csv' and 'write.csv2' provide convenience wrappers for\n     writing CSV files.  They set 'sep' and 'dec' (see below), 'qmethod\n     = \"double\"', and 'col.names' to 'NA' if 'row.names = TRUE' (the\n     default) and to 'TRUE' otherwise.\n\n     'write.csv' uses '\".\"' for the decimal point and a comma for the\n     separator.\n\n     'write.csv2' uses a comma for the decimal point and a semicolon\n     for the separator, the Excel convention for CSV files in some\n     Western European locales.\n\n     These wrappers are deliberately inflexible: they are designed to\n     ensure that the correct conventions are used to write a valid\n     file.  Attempts to change 'append', 'col.names', 'sep', 'dec' or\n     'qmethod' are ignored, with a warning.\n\n     CSV files do not record an encoding, and this causes problems if\n     they are not ASCII for many other applications.  Windows Excel\n     2007/10 will open files (e.g., by the file association mechanism)\n     correctly if they are ASCII or UTF-16 (use 'fileEncoding =\n     \"UTF-16LE\"') or perhaps in the current Windows codepage (e.g.,\n     '\"CP1252\"'), but the 'Text Import Wizard' (from the 'Data' tab)\n     allows far more choice of encodings.  Excel:mac 2004/8 can\n     _import_ only 'Macintosh' (which seems to mean Mac Roman),\n     'Windows' (perhaps Latin-1) and 'PC-8' files.  OpenOffice 3.x asks\n     for the character set when opening the file.\n\n     There is an IETF RFC4180\n     (&lt;https://www.rfc-editor.org/rfc/rfc4180&gt;) for CSV files, which\n     mandates comma as the separator and CRLF line endings.\n     'write.csv' writes compliant files on Windows: use 'eol = \"\\r\\n\"'\n     on other platforms.\n\nNote:\n\n     'write.table' can be slow for data frames with large numbers\n     (hundreds or more) of columns: this is inevitable as each column\n     could be of a different class and so must be handled separately.\n     If they are all of the same class, consider using a matrix\n     instead.\n\nSee Also:\n\n     The 'R Data Import/Export' manual.\n\n     'read.table', 'write'.\n\n     'write.matrix' in package 'MASS'.\n\nExamples:\n\n     x &lt;- data.frame(a = I(\"a \\\" quote\"), b = pi)\n     tf &lt;- tempfile(fileext = \".csv\")\n     \n     ## To write a CSV file for input to Excel one might use\n     write.table(x, file = tf, sep = \",\", col.names = NA,\n                 qmethod = \"double\")\n     file.show(tf)\n     ## and to read this file back into R one needs\n     read.table(tf, header = TRUE, sep = \",\", row.names = 1)\n     ## NB: you do need to specify a separator if qmethod = \"double\".\n     \n     ### Alternatively\n     write.csv(x, file = tf)\n     read.csv(tf, row.names = 1)\n     ## or without row names\n     write.csv(x, file = tf, row.names = FALSE)\n     read.csv(tf)\n     \n     ## Not run:\n     \n     ## To write a file in Mac Roman for simple use in Mac Excel 2004/8\n     write.csv(x, file = \"foo.csv\", fileEncoding = \"macroman\")\n     ## or for Windows Excel 2007/10\n     write.csv(x, file = \"foo.csv\", fileEncoding = \"UTF-16LE\")\n     ## End(Not run)",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#export-delimited-data-1",
    "href": "modules/Module05-DataImportExport.html#export-delimited-data-1",
    "title": "Module 5: Data Import and Export",
    "section": "Export delimited data",
    "text": "Export delimited data\nLet’s practice exporting the data as three files with three different delimiters (comma, tab, semicolon)\n\nwrite.csv(df, file=\"data/serodata_new.csv\", row.names = FALSE) #comma delimited\nwrite.table(df, file=\"data/serodata1_new.txt\", sep=\"\\t\", row.names = FALSE) #tab delimited\nwrite.table(df, file=\"data/serodata2_new.txt\", sep=\";\", row.names = FALSE) #semicolon delimited\n\nNote, I wrote the data to new file names. Even though we didn’t change the data at all in this module, it is good practice to keep raw data raw, and not to write over it.",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#r-.rds-and-.rdardata-files",
    "href": "modules/Module05-DataImportExport.html#r-.rds-and-.rdardata-files",
    "title": "Module 5: Data Import and Export",
    "section": "R .rds and .rda/RData files",
    "text": "R .rds and .rda/RData files\nThere are two file extensions worth discussing.\nR has two native data formats—‘Rdata’ (sometimes shortened to ‘Rda’) and ‘Rds’. These formats are used when R objects are saved for later use. ‘Rdata’ is used to save multiple R objects, while ‘Rds’ is used to save a single R object. ‘Rds’ is fast to write/read and is very small.",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#rds-binary-file",
    "href": "modules/Module05-DataImportExport.html#rds-binary-file",
    "title": "Module 5: Data Import and Export",
    "section": ".rds binary file",
    "text": ".rds binary file\nSaving datasets in .rds format can save time if you have to read it back in later.\nwrite_rds() and read_rds() from readr package can be used to write/read a single R object to/from file.\nrequire(readr)\nwrite_rds(object1, file = \"filename.rds\")\nobject1 &lt;- read_rds(file = \"filename.rds\")",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#rdardata-files",
    "href": "modules/Module05-DataImportExport.html#rdardata-files",
    "title": "Module 5: Data Import and Export",
    "section": ".rda/RData files",
    "text": ".rda/RData files\nThe Base R functions save() and load() can be used to save and load multiple R objects.\nsave() writes an external representation of R objects to the specified file, and can by loaded back into the environment using load(). A nice feature about using save and load is that the R object(s) is directly imported into the environment and you don’t have to specify the name. The files can be saved as .RData or .Rda files.\nFunction signature\nsave(object1, object2, file = \"filename.RData\")\nload(\"filename.RData\")\nNote, that you separate the objects you want to save with commas.",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#summary",
    "href": "modules/Module05-DataImportExport.html#summary",
    "title": "Module 5: Data Import and Export",
    "section": "Summary",
    "text": "Summary\n\nImporting or ‘Reading in’ data are the first step of any real project / data analysis\nThe Base R ‘util’ package has useful functions including read.csv() and read.delim() to importing/reading data or write.csv() and write.table() for exporting/writing data\nWhen importing data (exception is object from .RData), you must assign it to an object, otherwise it cannot be used\nIf data are imported correctly, they can be found in the Environment pane of RStudio\nYou only need to install a package once (unless you update R or the package), but you will need to attach a package each time you want to use it.\nTo complete a task you don’t know how to do (e.g., reading in an excel data file) use the following steps: 1. Asl Google / ChatGPT, 2. Find and vet function and package you want, 3. Install package, 4. Attach package, 5. Use function",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module05-DataImportExport.html#acknowledgements",
    "href": "modules/Module05-DataImportExport.html#acknowledgements",
    "title": "Module 5: Data Import and Export",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese are the materials we looked through, modified, or extracted to complete this module’s lecture.\n\n“Introduction to R for Public Health Researchers” Johns Hopkins University",
    "crumbs": [
      "Day 1",
      "Module 5: Data Import and Export"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#learning-objectives",
    "href": "modules/Module08-DataMergeReshape.html#learning-objectives",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter module 8, you should be able to…\n\nMerge/join data together\nReshape data from wide to long\nReshape data from long to wide",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#joining-types",
    "href": "modules/Module08-DataMergeReshape.html#joining-types",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "Joining types",
    "text": "Joining types\nPay close attention to the number of rows in your data set before and after a join. This will help flag when an issue has arisen. This will depend on the type of merge:\n\n1:1 merge (one-to-one merge) – Simplest merge (sometimes things go wrong)\n1:m merge (one-to-many merge) – More complex (things often go wrong)\n\nThe “one” suggests that one dataset has the merging variable (e.g., id) each represented once and the “many” implies that one dataset has the merging variable represented multiple times\n\nm:m merge (many-to-many merge) – Danger zone (can be unpredictable)",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#one-to-one-merge",
    "href": "modules/Module08-DataMergeReshape.html#one-to-one-merge",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "one-to-one merge",
    "text": "one-to-one merge\n\nThis means that each row of data represents a unique unit of analysis that exists in another dataset (e.g,. id variable)\nWill likely have variables that don’t exist in the current dataset (that’s why you are trying to merge it in)\nThe merging variable (e.g., id) each represented a single time\nYou should try to structure your data so that a 1:1 merge or 1:m merge is possible so that fewer things can go wrong.",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#merge-function",
    "href": "modules/Module08-DataMergeReshape.html#merge-function",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "merge() function",
    "text": "merge() function\nWe will use the merge() function to conduct one-to-one merge\n\n?merge\n\nRegistered S3 method overwritten by 'printr':\n  method                from     \n  knit_print.data.frame rmarkdown\nMerge Two Data Frames\nDescription:\n Merge two data frames by common columns or row names, or do other\n versions of database _join_ operations.\nUsage:\n merge(x, y, ...)\n \n ## Default S3 method:\n merge(x, y, ...)\n \n ## S3 method for class 'data.frame'\n merge(x, y, by = intersect(names(x), names(y)),\n       by.x = by, by.y = by, all = FALSE, all.x = all, all.y = all,\n       sort = TRUE, suffixes = c(\".x\",\".y\"), no.dups = TRUE,\n       incomparables = NULL, ...)\n \nArguments:\nx, y: data frames, or objects to be coerced to one.\nby, by.x, by.y: specifications of the columns used for merging. See ‘Details’.\n all: logical; 'all = L' is shorthand for 'all.x = L' and 'all.y =\n      L', where 'L' is either 'TRUE' or 'FALSE'.\nall.x: logical; if ‘TRUE’, then extra rows will be added to the output, one for each row in ‘x’ that has no matching row in ‘y’. These rows will have ‘NA’s in those columns that are usually filled with values from ’y’. The default is ‘FALSE’, so that only rows with data from both ‘x’ and ‘y’ are included in the output.\nall.y: logical; analogous to ‘all.x’.\nsort: logical.  Should the result be sorted on the 'by' columns?\nsuffixes: a character vector of length 2 specifying the suffixes to be used for making unique the names of columns in the result which are not used for merging (appearing in ‘by’ etc).\nno.dups: logical indicating that ‘suffixes’ are appended in more cases to avoid duplicated column names in the result. This was implicitly false before R version 3.5.0.\nincomparables: values which cannot be matched. See ‘match’. This is intended to be used for merging on one column, so these are incomparable values of that column.\n ...: arguments to be passed to or from methods.\nDetails:\n 'merge' is a generic function whose principal method is for data\n frames: the default method coerces its arguments to data frames\n and calls the '\"data.frame\"' method.\n\n By default the data frames are merged on the columns with names\n they both have, but separate specifications of the columns can be\n given by 'by.x' and 'by.y'.  The rows in the two data frames that\n match on the specified columns are extracted, and joined together.\n If there is more than one match, all possible matches contribute\n one row each.  For the precise meaning of 'match', see 'match'.\n\n Columns to merge on can be specified by name, number or by a\n logical vector: the name '\"row.names\"' or the number '0' specifies\n the row names.  If specified by name it must correspond uniquely\n to a named column in the input.\n\n If 'by' or both 'by.x' and 'by.y' are of length 0 (a length zero\n vector or 'NULL'), the result, 'r', is the _Cartesian product_ of\n 'x' and 'y', i.e., 'dim(r) = c(nrow(x)*nrow(y), ncol(x) +\n ncol(y))'.\n\n If 'all.x' is true, all the non matching cases of 'x' are appended\n to the result as well, with 'NA' filled in the corresponding\n columns of 'y'; analogously for 'all.y'.\n\n If the columns in the data frames not used in merging have any\n common names, these have 'suffixes' ('\".x\"' and '\".y\"' by default)\n appended to try to make the names of the result unique.  If this\n is not possible, an error is thrown.\n\n If a 'by.x' column name matches one of 'y', and if 'no.dups' is\n true (as by default), the y version gets suffixed as well,\n avoiding duplicate column names in the result.\n\n The complexity of the algorithm used is proportional to the length\n of the answer.\n\n In SQL database terminology, the default value of 'all = FALSE'\n gives a _natural join_, a special case of an _inner join_.\n Specifying 'all.x = TRUE' gives a _left (outer) join_, 'all.y =\n TRUE' a _right (outer) join_, and both ('all = TRUE') a _(full)\n outer join_.  DBMSes do not match 'NULL' records, equivalent to\n 'incomparables = NA' in R.\nValue:\n A data frame.  The rows are by default lexicographically sorted on\n the common columns, but for 'sort = FALSE' are in an unspecified\n order.  The columns are the common columns followed by the\n remaining columns in 'x' and then those in 'y'.  If the matching\n involved row names, an extra character column called 'Row.names'\n is added at the left, and in all cases the result has 'automatic'\n row names.\nNote:\n This is intended to work with data frames with vector-like\n columns: some aspects work with data frames containing matrices,\n but not all.\n\n Currently long vectors are not accepted for inputs, which are thus\n restricted to less than 2^31 rows. That restriction also applies\n to the result for 32-bit platforms.\nSee Also:\n 'data.frame', 'by', 'cbind'.\n\n 'dendrogram' for a class which has a 'merge' method.\nExamples:\n authors &lt;- data.frame(\n     ## I(*) : use character columns of names to get sensible sort order\n     surname = I(c(\"Tukey\", \"Venables\", \"Tierney\", \"Ripley\", \"McNeil\")),\n     nationality = c(\"US\", \"Australia\", \"US\", \"UK\", \"Australia\"),\n     deceased = c(\"yes\", rep(\"no\", 4)))\n authorN &lt;- within(authors, { name &lt;- surname; rm(surname) })\n books &lt;- data.frame(\n     name = I(c(\"Tukey\", \"Venables\", \"Tierney\",\n              \"Ripley\", \"Ripley\", \"McNeil\", \"R Core\")),\n     title = c(\"Exploratory Data Analysis\",\n               \"Modern Applied Statistics ...\",\n               \"LISP-STAT\",\n               \"Spatial Statistics\", \"Stochastic Simulation\",\n               \"Interactive Data Analysis\",\n               \"An Introduction to R\"),\n     other.author = c(NA, \"Ripley\", NA, NA, NA, NA,\n                      \"Venables & Smith\"))\n \n (m0 &lt;- merge(authorN, books))\n (m1 &lt;- merge(authors, books, by.x = \"surname\", by.y = \"name\"))\n  m2 &lt;- merge(books, authors, by.x = \"name\", by.y = \"surname\")\n stopifnot(exprs = {\n    identical(m0, m2[, names(m0)])\n    as.character(m1[, 1]) == as.character(m2[, 1])\n    all.equal(m1[, -1], m2[, -1][ names(m1)[-1] ])\n    identical(dim(merge(m1, m2, by = NULL)),\n              c(nrow(m1)*nrow(m2), ncol(m1)+ncol(m2)))\n })\n \n ## \"R core\" is missing from authors and appears only here :\n merge(authors, books, by.x = \"surname\", by.y = \"name\", all = TRUE)\n \n \n ## example of using 'incomparables'\n x &lt;- data.frame(k1 = c(NA,NA,3,4,5), k2 = c(1,NA,NA,4,5), data = 1:5)\n y &lt;- data.frame(k1 = c(NA,2,NA,4,5), k2 = c(NA,NA,3,4,5), data = 1:5)\n merge(x, y, by = c(\"k1\",\"k2\")) # NA's match\n merge(x, y, by = \"k1\") # NA's match, so 6 rows\n merge(x, y, by = \"k2\", incomparables = NA) # 2 rows",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#lets-import-the-new-data-we-want-to-merge-and-take-a-look",
    "href": "modules/Module08-DataMergeReshape.html#lets-import-the-new-data-we-want-to-merge-and-take-a-look",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "Lets import the new data we want to merge and take a look",
    "text": "Lets import the new data we want to merge and take a look\nThe new data serodata_new.csv represents a follow-up serological survey four years later. At this follow-up individuals were retested for IgG antibody concentrations and their ages were collected.\n\ndf_new &lt;- read.csv(\"data/serodata_new.csv\")\nstr(df_new)\n\n'data.frame':   636 obs. of  3 variables:\n $ observation_id   : int  5772 8095 9784 9338 6369 6885 6252 8913 7332 6941 ...\n $ IgG_concentration: num  0.261 2.981 0.282 136.638 0.381 ...\n $ age              : int  6 8 8 8 5 8 8 NA 8 6 ...\n\nsummary(df_new)\n\n\n\n\n\nobservation_id\nIgG_concentration\nage\n\n\n\n\n\nMin. :5006\nMin. : 0.0051\nMin. : 5.00\n\n\n\n1st Qu.:6328\n1st Qu.: 0.2751\n1st Qu.: 7.00\n\n\n\nMedian :7494\nMedian : 1.5477\nMedian :10.00\n\n\n\nMean :7490\nMean : 82.7684\nMean :10.63\n\n\n\n3rd Qu.:8736\n3rd Qu.:129.6389\n3rd Qu.:14.00\n\n\n\nMax. :9982\nMax. :950.6590\nMax. :19.00\n\n\n\nNA\nNA\nNA’s :9",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#merge-the-new-data-with-the-original-data",
    "href": "modules/Module08-DataMergeReshape.html#merge-the-new-data-with-the-original-data",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "Merge the new data with the original data",
    "text": "Merge the new data with the original data\nLets load the old data as well and look for a variable, or variables, to merge by.\n\ndf &lt;- read.csv(\"data/serodata.csv\")\ncolnames(df)\n\n[1] \"observation_id\"    \"IgG_concentration\" \"age\"              \n[4] \"gender\"            \"slum\"             \n\n\nWe notice that observation_id seems to be the obvious variable by which to merge. However, we also realize that IgG_concentration and age are the exact same names. If we merge now we see that R has forced the IgG_concentration and age to have a .x or .y to make sure that these variables are different.\n\nhead(merge(df, df_new, all.x=T, all.y=T, by=c('observation_id')))\n\n\n\n\n\n\n\n\n\n\n\n\n\nobservation_id\nIgG_concentration.x\nage.x\ngender\nslum\nIgG_concentration.y\nage.y\n\n\n\n\n5006\n164.2979452\n7\nMale\nNon slum\n155.5811325\n11\n\n\n5024\n0.3000000\n5\nFemale\nNon slum\n0.2918605\n9\n\n\n5026\n0.3000000\n10\nFemale\nNon slum\n0.2542945\n14\n\n\n5030\n0.0555556\n7\nFemale\nNon slum\n0.0533262\n11\n\n\n5035\n26.2112514\n11\nFemale\nNon slum\n22.0159300\n15\n\n\n5054\n0.3000000\n3\nMale\nNon slum\n0.2709671\n7",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#merge-the-new-data-with-the-original-data-1",
    "href": "modules/Module08-DataMergeReshape.html#merge-the-new-data-with-the-original-data-1",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "Merge the new data with the original data",
    "text": "Merge the new data with the original data\nWhat do we do?\nThe first option is to rename the IgG_concentration and age variables before the merge, so that it is clear which is time point 1 and time point 2.\n\ndf$IgG_concentration_time1 &lt;- df$IgG_concentration\ndf$age_time1 &lt;- df$age\ndf$IgG_concentration &lt;- df$age &lt;- NULL #remove the original variables\n\ndf_new$IgG_concentration_time2 &lt;- df_new$IgG_concentration\ndf_new$age_time2 &lt;- df_new$age\ndf_new$IgG_concentration &lt;- df_new$age &lt;- NULL #remove the original variables\n\nNow, lets merge.\n\ndf_all_wide &lt;- merge(df, df_new, all.x=T, all.y=T, by=c('observation_id'))\nstr(df_all_wide)\n\n'data.frame':   651 obs. of  7 variables:\n $ observation_id         : int  5006 5024 5026 5030 5035 5054 5057 5063 5064 5080 ...\n $ gender                 : chr  \"Male\" \"Female\" \"Female\" \"Female\" ...\n $ slum                   : chr  \"Non slum\" \"Non slum\" \"Non slum\" \"Non slum\" ...\n $ IgG_concentration_time1: num  164.2979 0.3 0.3 0.0556 26.2113 ...\n $ age_time1              : int  7 5 10 7 11 3 3 12 14 6 ...\n $ IgG_concentration_time2: num  155.5811 0.2919 0.2543 0.0533 22.0159 ...\n $ age_time2              : int  11 9 14 11 15 7 7 16 18 10 ...",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#merge-the-new-data-with-the-original-data-2",
    "href": "modules/Module08-DataMergeReshape.html#merge-the-new-data-with-the-original-data-2",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "Merge the new data with the original data",
    "text": "Merge the new data with the original data\nThe second option is to add a time variable to the two data sets and then merge by observation_id, time, age, and IgG_concentration. Note, I need to read in the data again b/c I removed the IgG_concentration and age variables.\n\ndf &lt;- read.csv(\"data/serodata.csv\")\ndf_new &lt;- read.csv(\"data/serodata_new.csv\")\n\n\ndf$time &lt;- 1 #you can put in one number and it will repeat it\ndf_new$time &lt;- 2\nhead(df)\n\n\n\n\nobservation_id\nIgG_concentration\nage\ngender\nslum\ntime\n\n\n\n\n5772\n0.3176895\n2\nFemale\nNon slum\n1\n\n\n8095\n3.4368231\n4\nFemale\nNon slum\n1\n\n\n9784\n0.3000000\n4\nMale\nNon slum\n1\n\n\n9338\n143.2363014\n4\nMale\nNon slum\n1\n\n\n6369\n0.4476534\n1\nMale\nNon slum\n1\n\n\n6885\n0.0252708\n4\nMale\nNon slum\n1\n\n\n\n\nhead(df_new)\n\n\n\n\nobservation_id\nIgG_concentration\nage\ntime\n\n\n\n\n5772\n0.2612388\n6\n2\n\n\n8095\n2.9809049\n8\n2\n\n\n9784\n0.2819489\n8\n2\n\n\n9338\n136.6382260\n8\n2\n\n\n6369\n0.3810119\n5\n2\n\n\n6885\n0.0245951\n8\n2\n\n\n\n\n\nNow, lets merge. Note, “By default the data frames are merged on the columns with names they both have” therefore if I don’t specify the by argument it will merge on all matching variables.\n\ndf_all_long &lt;- merge(df, df_new, all.x=T, all.y=T)\nhead(df_all_long)\n\n\n\n\nobservation_id\nIgG_concentration\nage\ntime\ngender\nslum\n\n\n\n\n5006\n155.5811325\n11\n2\nNA\nNA\n\n\n5006\n164.2979452\n7\n1\nMale\nNon slum\n\n\n5024\n0.2918605\n9\n2\nNA\nNA\n\n\n5024\n0.3000000\n5\n1\nFemale\nNon slum\n\n\n5026\n0.2542945\n14\n2\nNA\nNA\n\n\n5026\n0.3000000\n10\n1\nFemale\nNon slum\n\n\n\n\n\nNote, there are 1287 rows, which is the sum of the number of rows of df (651 rows) and df_new (636 rows)\nNotice that there are some missing values though, because df_new doesn’t have the gender or slum variables. If we assume that those are constant and don’t change between the two study points, we can fill in the data points before merging for an easy solution. One easy way to make a new dataframe from df_new with extra columns is to use the transform() function, which lets us make multiple column changes to a data frame at one time. We just need to make sure to match the correct observation_id values together, using the match() function.\n\ndf_new_filled &lt;- transform(\n  df_new,\n  gender = df[match(df_new$observation_id, df$observation_id), \"gender\"],\n  slum = df[match(df_new$observation_id, df$observation_id), \"slum\"]\n)\n\nNow we can redo the merge.\n\ndf_all_long &lt;- merge(df, df_new_filled, all.x=T, all.y=T)\nhead(df_all_long)\n\n\n\n\nobservation_id\nIgG_concentration\nage\ngender\nslum\ntime\n\n\n\n\n5006\n155.5811325\n11\nMale\nNon slum\n2\n\n\n5006\n164.2979452\n7\nMale\nNon slum\n1\n\n\n5024\n0.2918605\n9\nFemale\nNon slum\n2\n\n\n5024\n0.3000000\n5\nFemale\nNon slum\n1\n\n\n5026\n0.2542945\n14\nFemale\nNon slum\n2\n\n\n5026\n0.3000000\n10\nFemale\nNon slum\n1\n\n\n\n\n\nLooks good now! Another solution would be to edit the data file, or use a function that can actually fill in missing values for the same individual, like zoo::na.locf().",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#what-is-widelong-data",
    "href": "modules/Module08-DataMergeReshape.html#what-is-widelong-data",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "What is wide/long data?",
    "text": "What is wide/long data?\nAbove, we actually created a wide and long version of the data.\nWide: has many columns\n\nmultiple columns per individual, values spread across multiple columns\neasier for humans to read\n\nLong: has many rows\n\ncolumn names become data\nmultiple rows per observation, a single column contains the values\neasier for R to make plots & do analysis",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#reshape-function",
    "href": "modules/Module08-DataMergeReshape.html#reshape-function",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "reshape() function",
    "text": "reshape() function\nThe reshape() function allows you to toggle between wide and long data\n\n?reshape\n\nReshape Grouped Data\nDescription:\n This function reshapes a data frame between 'wide' format (with\n repeated measurements in separate columns of the same row) and\n 'long' format (with the repeated measurements in separate rows).\nUsage:\n reshape(data, varying = NULL, v.names = NULL, timevar = \"time\",\n         idvar = \"id\", ids = 1:NROW(data),\n         times = seq_along(varying[[1]]),\n         drop = NULL, direction, new.row.names = NULL,\n         sep = \".\",\n         split = if (sep == \"\") {\n             list(regexp = \"[A-Za-z][0-9]\", include = TRUE)\n         } else {\n             list(regexp = sep, include = FALSE, fixed = TRUE)}\n         )\n \n ### Typical usage for converting from long to wide format:\n \n # reshape(data, direction = \"wide\",\n #         idvar = \"___\", timevar = \"___\", # mandatory\n #         v.names = c(___),    # time-varying variables\n #         varying = list(___)) # auto-generated if missing\n \n ### Typical usage for converting from wide to long format:\n \n ### If names of wide-format variables are in a 'nice' format\n \n # reshape(data, direction = \"long\",\n #         varying = c(___), # vector \n #         sep)              # to help guess 'v.names' and 'times'\n \n ### To specify long-format variable names explicitly\n \n # reshape(data, direction = \"long\",\n #         varying = ___,  # list / matrix / vector (use with care)\n #         v.names = ___,  # vector of variable names in long format\n #         timevar, times, # name / values of constructed time variable\n #         idvar, ids)     # name / values of constructed id variable\n \nArguments:\ndata: a data frame\nvarying: names of sets of variables in the wide format that correspond to single variables in long format (‘time-varying’). This is canonically a list of vectors of variable names, but it can optionally be a matrix of names, or a single vector of names. In each case, when ‘direction = “long”’, the names can be replaced by indices which are interpreted as referring to ‘names(data)’. See ‘Details’ for more details and options.\nv.names: names of variables in the long format that correspond to multiple variables in the wide format. See ‘Details’.\ntimevar: the variable in long format that differentiates multiple records from the same group or individual. If more than one record matches, the first will be taken (with a warning).\nidvar: Names of one or more variables in long format that identify multiple records from the same group/individual. These variables may also be present in wide format.\n ids: the values to use for a newly created 'idvar' variable in\n      long format.\ntimes: the values to use for a newly created ‘timevar’ variable in long format. See ‘Details’.\ndrop: a vector of names of variables to drop before reshaping.\ndirection: character string, partially matched to either ‘“wide”’ to reshape to wide format, or ‘“long”’ to reshape to long format.\nnew.row.names: character or ‘NULL’: a non-null value will be used for the row names of the result.\n sep: A character vector of length 1, indicating a separating\n      character in the variable names in the wide format.  This is\n      used for guessing 'v.names' and 'times' arguments based on\n      the names in 'varying'.  If 'sep == \"\"', the split is just\n      before the first numeral that follows an alphabetic\n      character.  This is also used to create variable names when\n      reshaping to wide format.\nsplit: A list with three components, ‘regexp’, ‘include’, and (optionally) ‘fixed’. This allows an extended interface to variable name splitting. See ‘Details’.\nDetails:\n Although 'reshape()' can be used in a variety of contexts, the\n motivating application is data from longitudinal studies, and the\n arguments of this function are named and described in those terms.\n A longitudinal study is characterized by repeated measurements of\n the same variable(s), e.g., height and weight, on each unit being\n studied (e.g., individual persons) at different time points (which\n are assumed to be the same for all units). These variables are\n called time-varying variables. The study may include other\n variables that are measured only once for each unit and do not\n vary with time (e.g., gender and race); these are called\n time-constant variables.\n\n A 'wide' format representation of a longitudinal dataset will have\n one record (row) for each unit, typically with some time-constant\n variables that occupy single columns, and some time-varying\n variables that occupy multiple columns (one column for each time\n point).  A 'long' format representation of the same dataset will\n have multiple records (rows) for each individual, with the\n time-constant variables being constant across these records and\n the time-varying variables varying across the records.  The 'long'\n format dataset will have two additional variables: a 'time'\n variable identifying which time point each record comes from, and\n an 'id' variable showing which records refer to the same unit.\n\n The type of conversion (long to wide or wide to long) is\n determined by the 'direction' argument, which is mandatory unless\n the 'data' argument is the result of a previous call to 'reshape'.\n In that case, the operation can be reversed simply using\n 'reshape(data)' (the other arguments are stored as attributes on\n the data frame).\n\n Conversion from long to wide format with 'direction = \"wide\"' is\n the simpler operation, and is mainly useful in the context of\n multivariate analysis where data is often expected as a\n wide-format matrix. In this case, the time variable 'timevar' and\n id variable 'idvar' must be specified. All other variables are\n assumed to be time-varying, unless the time-varying variables are\n explicitly specified via the 'v.names' argument.  A warning is\n issued if time-constant variables are not actually constant.\n\n Each time-varying variable is expanded into multiple variables in\n the wide format.  The names of these expanded variables are\n generated automatically, unless they are specified as the\n 'varying' argument in the form of a list (or matrix) with one\n component (or row) for each time-varying variable. If 'varying' is\n a vector of names, it is implicitly converted into a matrix, with\n one row for each time-varying variable. Use this option with care\n if there are multiple time-varying variables, as the ordering (by\n column, the default in the 'matrix' constructor) may be\n unintuitive, whereas the explicit list or matrix form is\n unambiguous.\n\n Conversion from wide to long with 'direction = \"long\"' is the more\n common operation as most (univariate) statistical modeling\n functions expect data in the long format. In the simpler case\n where there is only one time-varying variable, the corresponding\n columns in the wide format input can be specified as the 'varying'\n argument, which can be either a vector of column names or the\n corresponding column indices. The name of the corresponding\n variable in the long format output combining these columns can be\n optionally specified as the 'v.names' argument, and the name of\n the time variables as the 'timevar' argument. The values to use as\n the time values corresponding to the different columns in the wide\n format can be specified as the 'times' argument.  If 'v.names' is\n unspecified, the function will attempt to guess 'v.names' and\n 'times' from 'varying' (an explicitly specified 'times' argument\n is unused in that case).  The default expects variable names like\n 'x.1', 'x.2', where 'sep = \".\"' specifies to split at the dot and\n drop it from the name.  To have alphabetic followed by numeric\n times use 'sep = \"\"'.\n\n Multiple time-varying variables can be specified in two ways,\n either with 'varying' as an atomic vector as above, or as a list\n (or a matrix). The first form is useful (and mandatory) if the\n automatic variable name splitting as described above is used; this\n requires the names of all time-varying variables to be suitably\n formatted in the same manner, and 'v.names' to be unspecified. If\n 'varying' is a list (with one component for each time-varying\n variable) or a matrix (one row for each time-varying variable),\n variable name splitting is not attempted, and 'v.names' and\n 'times' will generally need to be specified, although they will\n default to, respectively, the first variable name in each set, and\n sequential times.\n\n Also, guessing is not attempted if 'v.names' is given explicitly,\n even if 'varying' is an atomic vector. In that case, the number of\n time-varying variables is taken to be the length of 'v.names', and\n 'varying' is implicitly converted into a matrix, with one row for\n each time-varying variable. As in the case of long to wide\n conversion, the matrix is filled up by column, so careful\n attention needs to be paid to the order of variable names (or\n indices) in 'varying', which is taken to be like 'x.1', 'y.1',\n 'x.2', 'y.2' (i.e., variables corresponding to the same time point\n need to be grouped together).\n\n The 'split' argument should not usually be necessary.  The\n 'split$regexp' component is passed to either 'strsplit' or\n 'regexpr', where the latter is used if 'split$include' is 'TRUE',\n in which case the splitting occurs after the first character of\n the matched string.  In the 'strsplit' case, the separator is not\n included in the result, and it is possible to specify fixed-string\n matching using 'split$fixed'.\nValue:\n The reshaped data frame with added attributes to simplify\n reshaping back to the original form.\nSee Also:\n 'stack', 'aperm'; 'relist' for reshaping the result of 'unlist'.\n 'xtabs' and 'as.data.frame.table' for creating contingency tables\n and converting them back to data frames.\nExamples:\n summary(Indometh) # data in long format\n \n ## long to wide (direction = \"wide\") requires idvar and timevar at a minimum\n reshape(Indometh, direction = \"wide\", idvar = \"Subject\", timevar = \"time\")\n \n ## can also explicitly specify name of combined variable\n wide &lt;- reshape(Indometh, direction = \"wide\", idvar = \"Subject\",\n                 timevar = \"time\", v.names = \"conc\", sep= \"_\")\n wide\n \n ## reverse transformation\n reshape(wide, direction = \"long\")\n reshape(wide, idvar = \"Subject\", varying = list(2:12),\n         v.names = \"conc\", direction = \"long\")\n \n ## times need not be numeric\n df &lt;- data.frame(id = rep(1:4, rep(2,4)),\n                  visit = I(rep(c(\"Before\",\"After\"), 4)),\n                  x = rnorm(4), y = runif(4))\n df\n reshape(df, timevar = \"visit\", idvar = \"id\", direction = \"wide\")\n ## warns that y is really varying\n reshape(df, timevar = \"visit\", idvar = \"id\", direction = \"wide\", v.names = \"x\")\n \n \n ##  unbalanced 'long' data leads to NA fill in 'wide' form\n df2 &lt;- df[1:7, ]\n df2\n reshape(df2, timevar = \"visit\", idvar = \"id\", direction = \"wide\")\n \n ## Alternative regular expressions for guessing names\n df3 &lt;- data.frame(id = 1:4, age = c(40,50,60,50), dose1 = c(1,2,1,2),\n                   dose2 = c(2,1,2,1), dose4 = c(3,3,3,3))\n reshape(df3, direction = \"long\", varying = 3:5, sep = \"\")\n \n \n ## an example that isn't longitudinal data\n state.x77 &lt;- as.data.frame(state.x77)\n long &lt;- reshape(state.x77, idvar = \"state\", ids = row.names(state.x77),\n                 times = names(state.x77), timevar = \"Characteristic\",\n                 varying = list(names(state.x77)), direction = \"long\")\n \n reshape(long, direction = \"wide\")\n \n reshape(long, direction = \"wide\", new.row.names = unique(long$state))\n \n ## multiple id variables\n df3 &lt;- data.frame(school = rep(1:3, each = 4), class = rep(9:10, 6),\n                   time = rep(c(1,1,2,2), 3), score = rnorm(12))\n wide &lt;- reshape(df3, idvar = c(\"school\", \"class\"), direction = \"wide\")\n wide\n ## transform back\n reshape(wide)",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#wide-to-long-data",
    "href": "modules/Module08-DataMergeReshape.html#wide-to-long-data",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "wide to long data",
    "text": "wide to long data\nReminder: “typical usage for converting from long to wide format”\n\n### If names of wide-format variables are in a 'nice' format\n\nreshape(data, direction = \"long\",\n       varying = c(___), # vector \n       sep)              # to help guess 'v.names' and 'times'\n\n### To specify long-format variable names explicitly\n\nreshape(data, direction = \"long\",\n       varying = ___,  # list / matrix / vector (use with care)\n       v.names = ___,  # vector of variable names in long format\n       timevar, times, # name / values of constructed time variable\n       idvar, ids)     # name / values of constructed id variable\n\nWe can try to apply that to our data.\n\ndf_wide_to_long &lt;-\n  reshape(\n    # First argument is the wide-format data frame to be reshaped\n    df_all_wide,\n    # We are inputting wide data and expect long format as output\n    direction = \"long\",\n    # \"varying\" argument is a list of vectors. Each vector in the list is a\n    # group of time-varying (or grouping-factor-varying) variables which\n    # should become one variable after reformat. We want two variables after\n    # reformating, so we need two vectors in a list.\n    varying = list(\n      c(\"IgG_concentration_time1\", \"IgG_concentration_time2\"),\n      c(\"age_time1\", \"age_time2\")\n    ),\n    # \"v.names\" is a vector of names for the new long-format variables, it\n    # should have the same length as the list for varying and the names will\n    # be assigned in order.\n    v.names = c(\"IgG_concentration\", \"age\"),\n    # Name of the variable for the time index that will be created\n    timevar = \"time\",\n    # Values of the time variable that should be created. Note that if you\n    # have any missing observations over time, they NEED to be in the dataset\n    # as NAs or your times will get messed up.\n    times = 1:2,\n    # 'idvar' is a variable that marks which records belong to each\n    # observational unit, for us that is the ID marking individuals.\n    idvar = \"observation_id\"\n  )\n\nNotice that this has exactly twice as many rows as our wide data format, and doesn’t appear to have any systematic missingness, so it seems correct.\n\nstr(df_wide_to_long)\n\n'data.frame':   1302 obs. of  6 variables:\n $ observation_id   : int  5006 5024 5026 5030 5035 5054 5057 5063 5064 5080 ...\n $ gender           : chr  \"Male\" \"Female\" \"Female\" \"Female\" ...\n $ slum             : chr  \"Non slum\" \"Non slum\" \"Non slum\" \"Non slum\" ...\n $ time             : int  1 1 1 1 1 1 1 1 1 1 ...\n $ IgG_concentration: num  164.2979 0.3 0.3 0.0556 26.2113 ...\n $ age              : int  7 5 10 7 11 3 3 12 14 6 ...\n - attr(*, \"reshapeLong\")=List of 4\n  ..$ varying:List of 2\n  .. ..$ : chr [1:2] \"IgG_concentration_time1\" \"IgG_concentration_time2\"\n  .. ..$ : chr [1:2] \"age_time1\" \"age_time2\"\n  ..$ v.names: chr [1:2] \"IgG_concentration\" \"age\"\n  ..$ idvar  : chr \"observation_id\"\n  ..$ timevar: chr \"time\"\n\nnrow(df_wide_to_long)\n\n[1] 1302\n\nnrow(df_all_wide)\n\n[1] 651",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#long-to-wide-data",
    "href": "modules/Module08-DataMergeReshape.html#long-to-wide-data",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "long to wide data",
    "text": "long to wide data\nReminder: “typical usage for converting from long to wide format”\n\nreshape(data, direction = \"wide\",\n       idvar = \"___\", timevar = \"___\", # mandatory\n       v.names = c(___),    # time-varying variables\n       varying = list(___)) # auto-generated if missing\n\nWe can try to apply that to our data. Note that the arguments are the same as in the wide to long case, but we don’t need to specify the times argument because they are in the data already. The varying argument is optional also, and R will auto-generate names for the wide variables if it is left empty.\n\ndf_long_to_wide &lt;-\n  reshape(\n    df_all_long,\n    direction = \"wide\",\n    idvar = \"observation_id\",\n    timevar = \"time\",\n    v.names = c(\"IgG_concentration\", \"age\"),\n    varying = list(\n      c(\"IgG_concentration_time1\", \"IgG_concentration_time2\"),\n      c(\"age_time1\", \"age_time2\")\n    )\n  )\n\nWe can do the same checks to make sure we pivoted correctly.\n\nstr(df_long_to_wide)\n\n'data.frame':   651 obs. of  7 variables:\n $ observation_id         : int  5006 5024 5026 5030 5035 5054 5057 5063 5064 5080 ...\n $ gender                 : chr  \"Male\" \"Female\" \"Female\" \"Female\" ...\n $ slum                   : chr  \"Non slum\" \"Non slum\" \"Non slum\" \"Non slum\" ...\n $ IgG_concentration_time1: num  155.5811 0.2919 0.2543 0.0533 22.0159 ...\n $ age_time1              : int  11 9 14 11 15 7 7 16 18 10 ...\n $ IgG_concentration_time2: num  164.2979 0.3 0.3 0.0556 26.2113 ...\n $ age_time2              : int  7 5 10 7 11 3 3 12 14 6 ...\n - attr(*, \"reshapeWide\")=List of 5\n  ..$ v.names: chr [1:2] \"IgG_concentration\" \"age\"\n  ..$ timevar: chr \"time\"\n  ..$ idvar  : chr \"observation_id\"\n  ..$ times  : num [1:2] 2 1\n  ..$ varying: chr [1:2, 1:2] \"IgG_concentration_time1\" \"age_time1\" \"IgG_concentration_time2\" \"age_time2\"\n\nnrow(df_long_to_wide)\n\n[1] 651\n\nnrow(df_all_long)\n\n[1] 1287\n\n\nNote that this time we don’t have exactly twice as many records because of some quirks in how reshape() works. When we go from wide to long, R will create new records with NA values at the second time point for the individuals who were not in the second study – it won’t do that when we go from long to wide data. This is why it can be important to make sure all of your missing data are explicit rather than implicit.\n\n# For the original long dataset, we can see that not all individuals have 2\n# time points\nall(table(df_all_long$observation_id) == 2)\n\n[1] FALSE\n\n# But for the reshaped version they do all have 2 time points\nall(table(df_wide_to_long$observation_id) == 2)\n\n[1] TRUE",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#reshape-metadata",
    "href": "modules/Module08-DataMergeReshape.html#reshape-metadata",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "reshape metadata",
    "text": "reshape metadata\nWhenever you use reshape() to change the data format, it leaves behind some metadata on our new data frame, as an attr.\n\nstr(df_wide_to_long)\n\n'data.frame':   1302 obs. of  6 variables:\n $ observation_id   : int  5006 5024 5026 5030 5035 5054 5057 5063 5064 5080 ...\n $ gender           : chr  \"Male\" \"Female\" \"Female\" \"Female\" ...\n $ slum             : chr  \"Non slum\" \"Non slum\" \"Non slum\" \"Non slum\" ...\n $ time             : int  1 1 1 1 1 1 1 1 1 1 ...\n $ IgG_concentration: num  164.2979 0.3 0.3 0.0556 26.2113 ...\n $ age              : int  7 5 10 7 11 3 3 12 14 6 ...\n - attr(*, \"reshapeLong\")=List of 4\n  ..$ varying:List of 2\n  .. ..$ : chr [1:2] \"IgG_concentration_time1\" \"IgG_concentration_time2\"\n  .. ..$ : chr [1:2] \"age_time1\" \"age_time2\"\n  ..$ v.names: chr [1:2] \"IgG_concentration\" \"age\"\n  ..$ idvar  : chr \"observation_id\"\n  ..$ timevar: chr \"time\"\n\n\nThis stores information so we can reshape() back to the other format and we don’t have to specify arguments again.\n\ndf_back_to_wide &lt;- reshape(df_wide_to_long)",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#lets-get-real",
    "href": "modules/Module08-DataMergeReshape.html#lets-get-real",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "Let’s get real",
    "text": "Let’s get real\nUse the pivot_wider() and pivot_longer() from the tidyr package!",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#summary",
    "href": "modules/Module08-DataMergeReshape.html#summary",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "Summary",
    "text": "Summary\n\nthe merge() function can be used to marge datasets.\npay close attention to the number of rows in your data set before and after a merge\nwide data has many columns and has many columns per observation\nlong data has many rows and can have multiple rows per observation\nthe reshape() function allows you to toggle between wide and long data. although we highly recommend using pivot_wider() and pivot_longer() from the tidyr package instead",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module08-DataMergeReshape.html#acknowledgements",
    "href": "modules/Module08-DataMergeReshape.html#acknowledgements",
    "title": "Module 8: Data Merging and Reshaping",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese are the materials we looked through, modified, or extracted to complete this module’s lecture.\n\n“Introduction to R for Public Health Researchers” Johns Hopkins University",
    "crumbs": [
      "Day 2",
      "Module 8: Data Merging and Reshaping"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#learning-objectives",
    "href": "modules/Module10-DataVisualization.html#learning-objectives",
    "title": "Module 10: Data Visualization",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter module 10, you should be able to:\n\nCreate Base R plots",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#import-data-for-this-module",
    "href": "modules/Module10-DataVisualization.html#import-data-for-this-module",
    "title": "Module 10: Data Visualization",
    "section": "Import data for this module",
    "text": "Import data for this module\nLet’s read in our data (again) and take a quick look.\n\ndf &lt;- read.csv(file = \"data/serodata.csv\") #relative path\nhead(x=df, n=3)\n\n  observation_id IgG_concentration age gender     slum\n1           5772         0.3176895   2 Female Non slum\n2           8095         3.4368231   4 Female Non slum\n3           9784         0.3000000   4   Male Non slum",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#prep-data",
    "href": "modules/Module10-DataVisualization.html#prep-data",
    "title": "Module 10: Data Visualization",
    "section": "Prep data",
    "text": "Prep data\nCreate age_group three level factor variable\n\ndf$age_group &lt;- ifelse(df$age &lt;= 5, \"young\", \n                       ifelse(df$age&lt;=10 & df$age&gt;5, \"middle\", \"old\")) \ndf$age_group &lt;- factor(df$age_group, levels=c(\"young\", \"middle\", \"old\"))\n\nCreate seropos binary variable representing seropositivity if antibody concentrations are &gt;10 IU/mL.\n\ndf$seropos &lt;- ifelse(df$IgG_concentration&lt;10, 0, 1)",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#base-r-data-visualizattion-functions",
    "href": "modules/Module10-DataVisualization.html#base-r-data-visualizattion-functions",
    "title": "Module 10: Data Visualization",
    "section": "Base R data visualizattion functions",
    "text": "Base R data visualizattion functions\nThe Base R ‘graphics’ package has a ton of graphics options.\n\nhelp(package = \"graphics\")\n\n\n\nRegistered S3 method overwritten by 'printr':\n  method                from     \n  knit_print.data.frame rmarkdown\n\n\n        Information on package 'graphics'\n\nDescription:\n\nPackage:            graphics\nVersion:            4.4.1\nPriority:           base\nTitle:              The R Graphics Package\nAuthor:             R Core Team and contributors worldwide\nMaintainer:         R Core Team &lt;do-use-Contact-address@r-project.org&gt;\nContact:            R-help mailing list &lt;r-help@r-project.org&gt;\nDescription:        R functions for base graphics.\nImports:            grDevices\nLicense:            Part of R 4.4.1\nNeedsCompilation:   yes\nEnhances:           vcd\nBuilt:              R 4.4.1; x86_64-w64-mingw32; 2024-06-14 08:20:40\n                    UTC; windows\n\nIndex:\n\nAxis                    Generic Function to Add an Axis to a Plot\nabline                  Add Straight Lines to a Plot\narrows                  Add Arrows to a Plot\nassocplot               Association Plots\naxTicks                 Compute Axis Tickmark Locations\naxis                    Add an Axis to a Plot\naxis.POSIXct            Date and Date-time Plotting Functions\nbarplot                 Bar Plots\nbox                     Draw a Box around a Plot\nboxplot                 Box Plots\nboxplot.matrix          Draw a Boxplot for each Column (Row) of a\n                        Matrix\nbxp                     Draw Box Plots from Summaries\ncdplot                  Conditional Density Plots\nclip                    Set Clipping Region\ncontour                 Display Contours\ncoplot                  Conditioning Plots\ncurve                   Draw Function Plots\ndotchart                Cleveland's Dot Plots\nfilled.contour          Level (Contour) Plots\nfourfoldplot            Fourfold Plots\nframe                   Create / Start a New Plot Frame\ngraphics-package        The R Graphics Package\ngrconvertX              Convert between Graphics Coordinate Systems\ngrid                    Add Grid to a Plot\nhist                    Histograms\nhist.POSIXt             Histogram of a Date or Date-Time Object\nidentify                Identify Points in a Scatter Plot\nimage                   Display a Color Image\nlayout                  Specifying Complex Plot Arrangements\nlegend                  Add Legends to Plots\nlines                   Add Connected Line Segments to a Plot\nlocator                 Graphical Input\nmatplot                 Plot Columns of Matrices\nmosaicplot              Mosaic Plots\nmtext                   Write Text into the Margins of a Plot\npairs                   Scatterplot Matrices\npanel.smooth            Simple Panel Plot\npar                     Set or Query Graphical Parameters\npersp                   Perspective Plots\npie                     Pie Charts\nplot.data.frame         Plot Method for Data Frames\nplot.default            The Default Scatterplot Function\nplot.design             Plot Univariate Effects of a Design or Model\nplot.factor             Plotting Factor Variables\nplot.formula            Formula Notation for Scatterplots\nplot.histogram          Plot Histograms\nplot.raster             Plotting Raster Images\nplot.table              Plot Methods for 'table' Objects\nplot.window             Set up World Coordinates for Graphics Window\nplot.xy                 Basic Internal Plot Function\npoints                  Add Points to a Plot\npolygon                 Polygon Drawing\npolypath                Path Drawing\nrasterImage             Draw One or More Raster Images\nrect                    Draw One or More Rectangles\nrug                     Add a Rug to a Plot\nscreen                  Creating and Controlling Multiple Screens on a\n                        Single Device\nsegments                Add Line Segments to a Plot\nsmoothScatter           Scatterplots with Smoothed Densities Color\n                        Representation\nspineplot               Spine Plots and Spinograms\nstars                   Star (Spider/Radar) Plots and Segment Diagrams\nstem                    Stem-and-Leaf Plots\nstripchart              1-D Scatter Plots\nstrwidth                Plotting Dimensions of Character Strings and\n                        Math Expressions\nsunflowerplot           Produce a Sunflower Scatter Plot\nsymbols                 Draw Symbols (Circles, Squares, Stars,\n                        Thermometers, Boxplots)\ntext                    Add Text to a Plot\ntitle                   Plot Annotation\nxinch                   Graphical Units\nxspline                 Draw an X-spline",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#base-r-plotting",
    "href": "modules/Module10-DataVisualization.html#base-r-plotting",
    "title": "Module 10: Data Visualization",
    "section": "Base R Plotting",
    "text": "Base R Plotting\nTo make a plot you often need to specify the following features:\n\nParameters\nPlot attributes\nThe legend",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#parameters",
    "href": "modules/Module10-DataVisualization.html#parameters",
    "title": "Module 10: Data Visualization",
    "section": "1. Parameters",
    "text": "1. Parameters\nThe parameter section fixes the settings for all your plots, basically the plot options. Adding attributes via par() before you call the plot creates ‘global’ settings for your plot.\nIn the example below, we have set two commonly used optional attributes in the global plot settings.\n\nThe mfrow specifies that we have one row and two columns of plots — that is, two plots side by side.\nThe mar attribute is a vector of our margin widths, with the first value indicating the margin below the plot (5), the second indicating the margin to the left of the plot (5), the third, the top of the plot(4), and the fourth to the left (1).\n\npar(mfrow = c(1,2), mar = c(5,5,4,1))",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#parameters-1",
    "href": "modules/Module10-DataVisualization.html#parameters-1",
    "title": "Module 10: Data Visualization",
    "section": "1. Parameters",
    "text": "1. Parameters",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#lots-of-parameters-options",
    "href": "modules/Module10-DataVisualization.html#lots-of-parameters-options",
    "title": "Module 10: Data Visualization",
    "section": "Lots of parameters options",
    "text": "Lots of parameters options\nHowever, there are many more parameter options that can be specified in the ‘global’ settings or specific to a certain plot option.\n\n?par\n\nSet or Query Graphical Parameters\nDescription:\n 'par' can be used to set or query graphical parameters.\n Parameters can be set by specifying them as arguments to 'par' in\n 'tag = value' form, or by passing them as a list of tagged values.\nUsage:\n par(..., no.readonly = FALSE)\n \n &lt;highlevel plot&gt; (...., &lt;tag&gt; = &lt;value&gt;)\n \nArguments:\n ...: arguments in 'tag = value' form, a single list of tagged\n      values, or character vectors of parameter names. Supported\n      parameters are described in the 'Graphical Parameters'\n      section.\nno.readonly: logical; if ‘TRUE’ and there are no other arguments, only parameters are returned which can be set by a subsequent ‘par()’ call on the same device.\nDetails:\n Each device has its own set of graphical parameters.  If the\n current device is the null device, 'par' will open a new device\n before querying/setting parameters.  (What device is controlled by\n 'options(\"device\")'.)\n\n Parameters are queried by giving one or more character vectors of\n parameter names to 'par'.\n\n 'par()' (no arguments) or 'par(no.readonly = TRUE)' is used to get\n _all_ the graphical parameters (as a named list).  Their names are\n currently taken from the unexported variable 'graphics:::.Pars'.\n\n _*R.O.*_ indicates _*read-only arguments*_: These may only be used\n in queries and cannot be set.  ('\"cin\"', '\"cra\"', '\"csi\"',\n '\"cxy\"', '\"din\"' and '\"page\"' are always read-only.)\n\n Several parameters can only be set by a call to 'par()':\n\n    * '\"ask\"',\n\n    * '\"fig\"', '\"fin\"',\n\n    * '\"lheight\"',\n\n    * '\"mai\"', '\"mar\"', '\"mex\"', '\"mfcol\"', '\"mfrow\"', '\"mfg\"',\n\n    * '\"new\"',\n\n    * '\"oma\"', '\"omd\"', '\"omi\"',\n\n    * '\"pin\"', '\"plt\"', '\"ps\"', '\"pty\"',\n\n    * '\"usr\"',\n\n    * '\"xlog\"', '\"ylog\"',\n\n    * '\"ylbias\"'\n\n The remaining parameters can also be set as arguments (often via\n '...') to high-level plot functions such as 'plot.default',\n 'plot.window', 'points', 'lines', 'abline', 'axis', 'title',\n 'text', 'mtext', 'segments', 'symbols', 'arrows', 'polygon',\n 'rect', 'box', 'contour', 'filled.contour' and 'image'.  Such\n settings will be active during the execution of the function,\n only.  However, see the comments on 'bg', 'cex', 'col', 'lty',\n 'lwd' and 'pch' which may be taken as _arguments_ to certain plot\n functions rather than as graphical parameters.\n\n The meaning of 'character size' is not well-defined: this is set\n up for the device taking 'pointsize' into account but often not\n the actual font family in use.  Internally the corresponding pars\n ('cra', 'cin', 'cxy' and 'csi') are used only to set the\n inter-line spacing used to convert 'mar' and 'oma' to physical\n margins.  (The same inter-line spacing multiplied by 'lheight' is\n used for multi-line strings in 'text' and 'strheight'.)\n\n Note that graphical parameters are suggestions: plotting functions\n and devices need not make use of them (and this is particularly\n true of non-default methods for e.g. 'plot').\nValue:\n When parameters are set, their previous values are returned in an\n invisible named list.  Such a list can be passed as an argument to\n 'par' to restore the parameter values.  Use 'par(no.readonly =\n TRUE)' for the full list of parameters that can be restored.\n However, restoring all of these is not wise: see the 'Note'\n section.\n\n When just one parameter is queried, the value of that parameter is\n returned as (atomic) vector.  When two or more parameters are\n queried, their values are returned in a list, with the list names\n giving the parameters.\n\n Note the inconsistency: setting one parameter returns a list, but\n querying one parameter returns a vector.\nGraphical Parameters:\n 'adj' The value of 'adj' determines the way in which text strings\n      are justified in 'text', 'mtext' and 'title'.  A value of '0'\n      produces left-justified text, '0.5' (the default) centered\n      text and '1' right-justified text.  (Any value in [0, 1] is\n      allowed, and on most devices values outside that interval\n      will also work.)\n\n      Note that the 'adj' _argument_ of 'text' also allows 'adj =\n      c(x, y)' for different adjustment in x- and y- directions.\n      Note that whereas for 'text' it refers to positioning of text\n      about a point, for 'mtext' and 'title' it controls placement\n      within the plot or device region.\n\n 'ann' If set to 'FALSE', high-level plotting functions calling\n      'plot.default' do not annotate the plots they produce with\n      axis titles and overall titles.  The default is to do\n      annotation.\n\n 'ask' logical.  If 'TRUE' (and the R session is interactive) the\n      user is asked for input, before a new figure is drawn.  As\n      this applies to the device, it also affects output by\n      packages 'grid' and 'lattice'.  It can be set even on\n      non-screen devices but may have no effect there.\n\n      This not really a graphics parameter, and its use is\n      deprecated in favour of 'devAskNewPage'.\n\n 'bg' The color to be used for the background of the device region.\n      When called from 'par()' it also sets 'new = FALSE'. See\n      section 'Color Specification' for suitable values.  For many\n      devices the initial value is set from the 'bg' argument of\n      the device, and for the rest it is normally '\"white\"'.\n\n      Note that some graphics functions such as 'plot.default' and\n      'points' have an _argument_ of this name with a different\n      meaning.\n\n 'bty' A character string which determined the type of 'box' which\n      is drawn about plots.  If 'bty' is one of '\"o\"' (the\n      default), '\"l\"', '\"7\"', '\"c\"', '\"u\"', or '\"]\"' the resulting\n      box resembles the corresponding upper case letter.  A value\n      of '\"n\"' suppresses the box.\n\n 'cex' A numerical value giving the amount by which plotting text\n      and symbols should be magnified relative to the default.\n      This starts as '1' when a device is opened, and is reset when\n      the layout is changed, e.g. by setting 'mfrow'.\n\n      Note that some graphics functions such as 'plot.default' have\n      an _argument_ of this name which _multiplies_ this graphical\n      parameter, and some functions such as 'points' and 'text'\n      accept a vector of values which are recycled.\n\n 'cex.axis' The magnification to be used for axis annotation\n      relative to the current setting of 'cex'.\n\n 'cex.lab' The magnification to be used for x and y labels relative\n      to the current setting of 'cex'.\n\n 'cex.main' The magnification to be used for main titles relative\n      to the current setting of 'cex'.\n\n 'cex.sub' The magnification to be used for sub-titles relative to\n      the current setting of 'cex'.\n\n 'cin' _*R.O.*_; character size '(width, height)' in inches.  These\n      are the same measurements as 'cra', expressed in different\n      units.\n\n 'col' A specification for the default plotting color.  See section\n      'Color Specification'.\n\n      Some functions such as 'lines' and 'text' accept a vector of\n      values which are recycled and may be interpreted slightly\n      differently.\n\n 'col.axis' The color to be used for axis annotation.  Defaults to\n      '\"black\"'.\n\n 'col.lab' The color to be used for x and y labels.  Defaults to\n      '\"black\"'.\n\n 'col.main' The color to be used for plot main titles.  Defaults to\n      '\"black\"'.\n\n 'col.sub' The color to be used for plot sub-titles.  Defaults to\n      '\"black\"'.\n\n 'cra' _*R.O.*_; size of default character '(width, height)' in\n      'rasters' (pixels).  Some devices have no concept of pixels\n      and so assume an arbitrary pixel size, usually 1/72 inch.\n      These are the same measurements as 'cin', expressed in\n      different units.\n\n 'crt' A numerical value specifying (in degrees) how single\n      characters should be rotated.  It is unwise to expect values\n      other than multiples of 90 to work.  Compare with 'srt' which\n      does string rotation.\n\n 'csi' _*R.O.*_; height of (default-sized) characters in inches.\n      The same as 'par(\"cin\")[2]'.\n\n 'cxy' _*R.O.*_; size of default character '(width, height)' in\n      user coordinate units.  'par(\"cxy\")' is\n      'par(\"cin\")/par(\"pin\")' scaled to user coordinates.  Note\n      that 'c(strwidth(ch), strheight(ch))' for a given string 'ch'\n      is usually much more precise.\n\n 'din' _*R.O.*_; the device dimensions, '(width, height)', in\n      inches.  See also 'dev.size', which is updated immediately\n      when an on-screen device windows is re-sized.\n\n 'err' (_Unimplemented_; R is silent when points outside the plot\n      region are _not_ plotted.)  The degree of error reporting\n      desired.\n\n 'family' The name of a font family for drawing text.  The maximum\n      allowed length is 200 bytes.  This name gets mapped by each\n      graphics device to a device-specific font description.  The\n      default value is '\"\"' which means that the default device\n      fonts will be used (and what those are should be listed on\n      the help page for the device).  Standard values are\n      '\"serif\"', '\"sans\"' and '\"mono\"', and the Hershey font\n      families are also available.  (Devices may define others, and\n      some devices will ignore this setting completely.  Names\n      starting with '\"Hershey\"' are treated specially and should\n      only be used for the built-in Hershey font families.)  This\n      can be specified inline for 'text'.\n\n 'fg' The color to be used for the foreground of plots.  This is\n      the default color used for things like axes and boxes around\n      plots.  When called from 'par()' this also sets parameter\n      'col' to the same value.  See section 'Color Specification'.\n      A few devices have an argument to set the initial value,\n      which is otherwise '\"black\"'.\n\n 'fig' A numerical vector of the form 'c(x1, x2, y1, y2)' which\n      gives the (NDC) coordinates of the figure region in the\n      display region of the device. If you set this, unlike S, you\n      start a new plot, so to add to an existing plot use 'new =\n      TRUE' as well.\n\n 'fin' The figure region dimensions, '(width, height)', in inches.\n      If you set this, unlike S, you start a new plot.\n\n 'font' An integer which specifies which font to use for text.  If\n      possible, device drivers arrange so that 1 corresponds to\n      plain text (the default), 2 to bold face, 3 to italic and 4\n      to bold italic.  Also, font 5 is expected to be the symbol\n      font, in Adobe symbol encoding.  On some devices font\n      families can be selected by 'family' to choose different sets\n      of 5 fonts.\n\n 'font.axis' The font to be used for axis annotation.\n\n 'font.lab' The font to be used for x and y labels.\n\n 'font.main' The font to be used for plot main titles.\n\n 'font.sub' The font to be used for plot sub-titles.\n\n 'lab' A numerical vector of the form 'c(x, y, len)' which modifies\n      the default way that axes are annotated.  The values of 'x'\n      and 'y' give the (approximate) number of tickmarks on the x\n      and y axes and 'len' specifies the label length.  The default\n      is 'c(5, 5, 7)'.  'len' _is unimplemented_ in R.\n\n 'las' numeric in {0,1,2,3}; the style of axis labels.\n\n      0: always parallel to the axis [_default_],\n\n      1: always horizontal,\n\n      2: always perpendicular to the axis,\n\n      3: always vertical.\n\n      Also supported by 'mtext'.  Note that string/character\n      rotation _via_ argument 'srt' to 'par' does _not_ affect the\n      axis labels.\n\n 'lend' The line end style.  This can be specified as an integer or\n      string:\n\n      '0' and '\"round\"' mean rounded line caps [_default_];\n\n      '1' and '\"butt\"' mean butt line caps;\n\n      '2' and '\"square\"' mean square line caps.\n\n 'lheight' The line height multiplier.  The height of a line of\n      text (used to vertically space multi-line text) is found by\n      multiplying the character height both by the current\n      character expansion and by the line height multiplier.\n      Default value is 1.  Used in 'text' and 'strheight'.\n\n 'ljoin' The line join style.  This can be specified as an integer\n      or string:\n\n      '0' and '\"round\"' mean rounded line joins [_default_];\n\n      '1' and '\"mitre\"' mean mitred line joins;\n\n      '2' and '\"bevel\"' mean bevelled line joins.\n\n 'lmitre' The line mitre limit.  This controls when mitred line\n      joins are automatically converted into bevelled line joins.\n      The value must be larger than 1 and the default is 10.  Not\n      all devices will honour this setting.\n\n 'lty' The line type.  Line types can either be specified as an\n      integer (0=blank, 1=solid (default), 2=dashed, 3=dotted,\n      4=dotdash, 5=longdash, 6=twodash) or as one of the character\n      strings '\"blank\"', '\"solid\"', '\"dashed\"', '\"dotted\"',\n      '\"dotdash\"', '\"longdash\"', or '\"twodash\"', where '\"blank\"'\n      uses 'invisible lines' (i.e., does not draw them).\n\n      Alternatively, a string of up to 8 characters (from 'c(1:9,\n      \"A\":\"F\")') may be given, giving the length of line segments\n      which are alternatively drawn and skipped.  See section 'Line\n      Type Specification'.\n\n      Functions such as 'lines' and 'segments' accept a vector of\n      values which are recycled.\n\n 'lwd' The line width, a _positive_ number, defaulting to '1'.  The\n      interpretation is device-specific, and some devices do not\n      implement line widths less than one.  (See the help on the\n      device for details of the interpretation.)\n\n      Functions such as 'lines' and 'segments' accept a vector of\n      values which are recycled: in such uses lines corresponding\n      to values 'NA' or 'NaN' are omitted.  The interpretation of\n      '0' is device-specific.\n\n 'mai' A numerical vector of the form 'c(bottom, left, top, right)'\n      which gives the margin size specified in inches.\n\n 'mar' A numerical vector of the form 'c(bottom, left, top, right)'\n      which gives the number of lines of margin to be specified on\n      the four sides of the plot.  The default is 'c(5, 4, 4, 2) +\n      0.1'.\n\n 'mex' 'mex' is a character size expansion factor which is used to\n      describe coordinates in the margins of plots. Note that this\n      does not change the font size, rather specifies the size of\n      font (as a multiple of 'csi') used to convert between 'mar'\n      and 'mai', and between 'oma' and 'omi'.\n\n      This starts as '1' when the device is opened, and is reset\n      when the layout is changed (alongside resetting 'cex').\n\n 'mfcol, mfrow' A vector of the form 'c(nr, nc)'.  Subsequent\n      figures will be drawn in an 'nr'-by-'nc' array on the device\n      by _columns_ ('mfcol'), or _rows_ ('mfrow'), respectively.\n\n      In a layout with exactly two rows and columns the base value\n      of '\"cex\"' is reduced by a factor of 0.83: if there are three\n      or more of either rows or columns, the reduction factor is\n      0.66.\n\n      Setting a layout resets the base value of 'cex' and that of\n      'mex' to '1'.\n\n      If either of these is queried it will give the current\n      layout, so querying cannot tell you the order in which the\n      array will be filled.\n\n      Consider the alternatives, 'layout' and 'split.screen'.\n\n 'mfg' A numerical vector of the form 'c(i, j)' where 'i' and 'j'\n      indicate which figure in an array of figures is to be drawn\n      next (if setting) or is being drawn (if enquiring).  The\n      array must already have been set by 'mfcol' or 'mfrow'.\n\n      For compatibility with S, the form 'c(i, j, nr, nc)' is also\n      accepted, when 'nr' and 'nc' should be the current number of\n      rows and number of columns.  Mismatches will be ignored, with\n      a warning.\n\n 'mgp' The margin line (in 'mex' units) for the axis title, axis\n      labels and axis line.  Note that 'mgp[1]' affects 'title'\n      whereas 'mgp[2:3]' affect 'axis'.  The default is 'c(3, 1,\n      0)'.\n\n 'mkh' The height in inches of symbols to be drawn when the value\n      of 'pch' is an integer. _Completely ignored in R_.\n\n 'new' logical, defaulting to 'FALSE'.  If set to 'TRUE', the next\n      high-level plotting command (actually 'plot.new') should _not\n      clean_ the frame before drawing _as if it were on a *_new_*\n      device_.  It is an error (ignored with a warning) to try to\n      use 'new = TRUE' on a device that does not currently contain\n      a high-level plot.\n\n 'oma' A vector of the form 'c(bottom, left, top, right)' giving\n      the size of the outer margins in lines of text.\n\n 'omd' A vector of the form 'c(x1, x2, y1, y2)' giving the region\n      _inside_ outer margins in NDC (= normalized device\n      coordinates), i.e., as a fraction (in [0, 1]) of the device\n      region.\n\n 'omi' A vector of the form 'c(bottom, left, top, right)' giving\n      the size of the outer margins in inches.\n\n 'page' _*R.O.*_; A boolean value indicating whether the next call\n      to 'plot.new' is going to start a new page.  This value may\n      be 'FALSE' if there are multiple figures on the page.\n\n 'pch' Either an integer specifying a symbol or a single character\n      to be used as the default in plotting points.  See 'points'\n      for possible values and their interpretation.  Note that only\n      integers and single-character strings can be set as a\n      graphics parameter (and not 'NA' nor 'NULL').\n\n      Some functions such as 'points' accept a vector of values\n      which are recycled.\n\n 'pin' The current plot dimensions, '(width, height)', in inches.\n\n 'plt' A vector of the form 'c(x1, x2, y1, y2)' giving the\n      coordinates of the plot region as fractions of the current\n      figure region.\n\n 'ps' integer; the point size of text (but not symbols).  Unlike\n      the 'pointsize' argument of most devices, this does not\n      change the relationship between 'mar' and 'mai' (nor 'oma'\n      and 'omi').\n\n      What is meant by 'point size' is device-specific, but most\n      devices mean a multiple of 1bp, that is 1/72 of an inch.\n\n 'pty' A character specifying the type of plot region to be used;\n      '\"s\"' generates a square plotting region and '\"m\"' generates\n      the maximal plotting region.\n\n 'smo' (_Unimplemented_) a value which indicates how smooth circles\n      and circular arcs should be.\n\n 'srt' The string rotation in degrees.  See the comment about\n      'crt'.  Only supported by 'text'.\n\n 'tck' The length of tick marks as a fraction of the smaller of the\n      width or height of the plotting region.  If 'tck &gt;= 0.5' it\n      is interpreted as a fraction of the relevant side, so if 'tck\n      = 1' grid lines are drawn.  The default setting ('tck = NA')\n      is to use 'tcl = -0.5'.\n\n 'tcl' The length of tick marks as a fraction of the height of a\n      line of text.  The default value is '-0.5'; setting 'tcl =\n      NA' sets 'tck = -0.01' which is S' default.\n\n 'usr' A vector of the form 'c(x1, x2, y1, y2)' giving the extremes\n      of the user coordinates of the plotting region.  When a\n      logarithmic scale is in use (i.e., 'par(\"xlog\")' is true, see\n      below), then the x-limits will be '10 ^ par(\"usr\")[1:2]'.\n      Similarly for the y-axis.\n\n 'xaxp' A vector of the form 'c(x1, x2, n)' giving the coordinates\n      of the extreme tick marks and the number of intervals between\n      tick-marks when 'par(\"xlog\")' is false.  Otherwise, when\n      _log_ coordinates are active, the three values have a\n      different meaning: For a small range, 'n' is _negative_, and\n      the ticks are as in the linear case, otherwise, 'n' is in\n      '1:3', specifying a case number, and 'x1' and 'x2' are the\n      lowest and highest power of 10 inside the user coordinates,\n      '10 ^ par(\"usr\")[1:2]'. (The '\"usr\"' coordinates are\n      log10-transformed here!)\n\n      n = 1 will produce tick marks at 10^j for integer j,\n\n      n = 2 gives marks k 10^j with k in {1,5},\n\n      n = 3 gives marks k 10^j with k in {1,2,5}.\n\n      See 'axTicks()' for a pure R implementation of this.\n\n      This parameter is reset when a user coordinate system is set\n      up, for example by starting a new page or by calling\n      'plot.window' or setting 'par(\"usr\")': 'n' is taken from\n      'par(\"lab\")'.  It affects the default behaviour of subsequent\n      calls to 'axis' for sides 1 or 3.\n\n      It is only relevant to default numeric axis systems, and not\n      for example to dates.\n\n 'xaxs' The style of axis interval calculation to be used for the\n      x-axis.  Possible values are '\"r\"', '\"i\"', '\"e\"', '\"s\"',\n      '\"d\"'.  The styles are generally controlled by the range of\n      data or 'xlim', if given.\n      Style '\"r\"' (regular) first extends the data range by 4\n      percent at each end and then finds an axis with pretty labels\n      that fits within the extended range.\n      Style '\"i\"' (internal) just finds an axis with pretty labels\n      that fits within the original data range.\n      Style '\"s\"' (standard) finds an axis with pretty labels\n      within which the original data range fits.\n      Style '\"e\"' (extended) is like style '\"s\"', except that it is\n      also ensures that there is room for plotting symbols within\n      the bounding box.\n      Style '\"d\"' (direct) specifies that the current axis should\n      be used on subsequent plots.\n      (_Only '\"r\"' and '\"i\"' styles have been implemented in R._)\n\n 'xaxt' A character which specifies the x axis type.  Specifying\n      '\"n\"' suppresses plotting of the axis.  The standard value is\n      '\"s\"': for compatibility with S values '\"l\"' and '\"t\"' are\n      accepted but are equivalent to '\"s\"': any value other than\n      '\"n\"' implies plotting.\n\n 'xlog' A logical value (see 'log' in 'plot.default').  If 'TRUE',\n      a logarithmic scale is in use (e.g., after 'plot(*, log =\n      \"x\")').  For a new device, it defaults to 'FALSE', i.e.,\n      linear scale.\n\n 'xpd' A logical value or 'NA'.  If 'FALSE', all plotting is\n      clipped to the plot region, if 'TRUE', all plotting is\n      clipped to the figure region, and if 'NA', all plotting is\n      clipped to the device region.  See also 'clip'.\n\n 'yaxp' A vector of the form 'c(y1, y2, n)' giving the coordinates\n      of the extreme tick marks and the number of intervals between\n      tick-marks unless for log coordinates, see 'xaxp' above.\n\n 'yaxs' The style of axis interval calculation to be used for the\n      y-axis.  See 'xaxs' above.\n\n 'yaxt' A character which specifies the y axis type.  Specifying\n      '\"n\"' suppresses plotting.\n\n 'ylbias' A positive real value used in the positioning of text in\n      the margins by 'axis' and 'mtext'.  The default is in\n      principle device-specific, but currently '0.2' for all of R's\n      own devices.  Set this to '0.2' for compatibility with R &lt;\n      2.14.0 on 'x11' and 'windows()' devices.\n\n 'ylog' A logical value; see 'xlog' above.\nColor Specification:\n Colors can be specified in several different ways. The simplest\n way is with a character string giving the color name (e.g.,\n '\"red\"').  A list of the possible colors can be obtained with the\n function 'colors'.  Alternatively, colors can be specified\n directly in terms of their RGB components with a string of the\n form '\"#RRGGBB\"' where each of the pairs 'RR', 'GG', 'BB' consist\n of two hexadecimal digits giving a value in the range '00' to\n 'FF'.  Hexadecimal colors can be in the long hexadecimal form\n (e.g., '\"#rrggbb\"' or '\"#rrggbbaa\"') or the short form (e.g,\n '\"#rgb\"' or '\"#rgba\"'). The short form is expanded to the long\n form by replicating digits (not by adding zeroes), e.g., '\"#rgb\"'\n becomes '\"#rrggbb\"'. Colors can also be specified by giving an\n index into a small table of colors, the 'palette': indices wrap\n round so with the default palette of size 8, '10' is the same as\n '2'.  This provides compatibility with S.  Index '0' corresponds\n to the background color.  Note that the palette (apart from '0'\n which is per-device) is a per-session setting.\n\n Negative integer colours are errors.\n\n Additionally, '\"transparent\"' is _transparent_, useful for filled\n areas (such as the background!), and just invisible for things\n like lines or text.  In most circumstances (integer) 'NA' is\n equivalent to '\"transparent\"' (but not for 'text' and 'mtext').\n\n Semi-transparent colors are available for use on devices that\n support them.\n\n The functions 'rgb', 'hsv', 'hcl', 'gray' and 'rainbow' provide\n additional ways of generating colors.\nLine Type Specification:\n Line types can either be specified by giving an index into a small\n built-in table of line types (1 = solid, 2 = dashed, etc, see\n 'lty' above) or directly as the lengths of on/off stretches of\n line.  This is done with a string of an even number (up to eight)\n of characters, namely _non-zero_ (hexadecimal) digits which give\n the lengths in consecutive positions in the string.  For example,\n the string '\"33\"' specifies three units on followed by three off\n and '\"3313\"' specifies three units on followed by three off\n followed by one on and finally three off.  The 'units' here are\n (on most devices) proportional to 'lwd', and with 'lwd = 1' are in\n pixels or points or 1/96 inch.\n\n The five standard dash-dot line types ('lty = 2:6') correspond to\n 'c(\"44\", \"13\", \"1343\", \"73\", \"2262\")'.\n\n Note that 'NA' is not a valid value for 'lty'.\nNote:\n The effect of restoring all the (settable) graphics parameters as\n in the examples is hard to predict if the device has been resized.\n Several of them are attempting to set the same things in different\n ways, and those last in the alphabet will win.  In particular, the\n settings of 'mai', 'mar', 'pin', 'plt' and 'pty' interact, as do\n the outer margin settings, the figure layout and figure region\n size.\nReferences:\n Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S\n Language_.  Wadsworth & Brooks/Cole.\n\n Murrell, P. (2005) _R Graphics_. Chapman & Hall/CRC Press.\nSee Also:\n 'plot.default' for some high-level plotting parameters; 'colors';\n 'clip'; 'options' for other setup parameters; graphic devices\n 'x11', 'pdf', 'postscript' and setting up device regions by\n 'layout' and 'split.screen'.\nExamples:\n op &lt;- par(mfrow = c(2, 2), # 2 x 2 pictures on one plot\n           pty = \"s\")       # square plotting region,\n                            # independent of device size\n \n ## At end of plotting, reset to previous settings:\n par(op)\n \n ## Alternatively,\n op &lt;- par(no.readonly = TRUE) # the whole list of settable par's.\n ## do lots of plotting and par(.) calls, then reset:\n par(op)\n ## Note this is not in general good practice\n \n par(\"ylog\") # FALSE\n plot(1 : 12, log = \"y\")\n par(\"ylog\") # TRUE\n \n plot(1:2, xaxs = \"i\") # 'inner axis' w/o extra space\n par(c(\"usr\", \"xaxp\"))\n \n ( nr.prof &lt;-\n c(prof.pilots = 16, lawyers = 11, farmers = 10, salesmen = 9, physicians = 9,\n   mechanics = 6, policemen = 6, managers = 6, engineers = 5, teachers = 4,\n   housewives = 3, students = 3, armed.forces = 1))\n par(las = 3)\n barplot(rbind(nr.prof)) # R 0.63.2: shows alignment problem\n par(las = 0)  # reset to default\n \n require(grDevices) # for gray\n ## 'fg' use:\n plot(1:12, type = \"b\", main = \"'fg' : axes, ticks and box in gray\",\n      fg = gray(0.7), bty = \"7\" , sub = R.version.string)\n \n ex &lt;- function() {\n    old.par &lt;- par(no.readonly = TRUE) # all par settings which\n                                       # could be changed.\n    on.exit(par(old.par))\n    ## ...\n    ## ... do lots of par() settings and plots\n    ## ...\n    invisible() #-- now,  par(old.par)  will be executed\n }\n ex()\n \n ## Line types\n showLty &lt;- function(ltys, xoff = 0, ...) {\n    stopifnot((n &lt;- length(ltys)) &gt;= 1)\n    op &lt;- par(mar = rep(.5,4)); on.exit(par(op))\n    plot(0:1, 0:1, type = \"n\", axes = FALSE, ann = FALSE)\n    y &lt;- (n:1)/(n+1)\n    clty &lt;- as.character(ltys)\n    mytext &lt;- function(x, y, txt)\n       text(x, y, txt, adj = c(0, -.3), cex = 0.8, ...)\n    abline(h = y, lty = ltys, ...); mytext(xoff, y, clty)\n    y &lt;- y - 1/(3*(n+1))\n    abline(h = y, lty = ltys, lwd = 2, ...)\n    mytext(1/8+xoff, y, paste(clty,\" lwd = 2\"))\n }\n showLty(c(\"solid\", \"dashed\", \"dotted\", \"dotdash\", \"longdash\", \"twodash\"))\n par(new = TRUE)  # the same:\n showLty(c(\"solid\", \"44\", \"13\", \"1343\", \"73\", \"2262\"), xoff = .2, col = 2)\n showLty(c(\"11\", \"22\", \"33\", \"44\",   \"12\", \"13\", \"14\",   \"21\", \"31\"))",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#common-parameter-options",
    "href": "modules/Module10-DataVisualization.html#common-parameter-options",
    "title": "Module 10: Data Visualization",
    "section": "Common parameter options",
    "text": "Common parameter options\nEight useful parameter arguments help improve the readability of the plot:\n\nxlab: specifies the x-axis label of the plot\nylab: specifies the y-axis label\nmain: titles your graph\npch: specifies the symbology of your graph\nlty: specifies the line type of your graph\nlwd: specifies line thickness\ncex : specifies size\ncol: specifies the colors for your graph.\n\nWe will explore use of these arguments below.",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#common-parameter-options-1",
    "href": "modules/Module10-DataVisualization.html#common-parameter-options-1",
    "title": "Module 10: Data Visualization",
    "section": "Common parameter options",
    "text": "Common parameter options",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#plot-attributes",
    "href": "modules/Module10-DataVisualization.html#plot-attributes",
    "title": "Module 10: Data Visualization",
    "section": "2. Plot Attributes",
    "text": "2. Plot Attributes\nPlot attributes are those that map your data to the plot. This mean this is where you specify what variables in the data frame you want to plot.\nWe will only look at four types of plots today:\n\nhist() displays histogram of one variable\nplot() displays x-y plot of two variables\nboxplot() displays boxplot\nbarplot() displays barplot",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#hist-help-file",
    "href": "modules/Module10-DataVisualization.html#hist-help-file",
    "title": "Module 10: Data Visualization",
    "section": "hist() Help File",
    "text": "hist() Help File\n\n?hist\n\nHistograms\nDescription:\n The generic function 'hist' computes a histogram of the given data\n values.  If 'plot = TRUE', the resulting object of class\n '\"histogram\"' is plotted by 'plot.histogram', before it is\n returned.\nUsage:\n hist(x, ...)\n \n ## Default S3 method:\n hist(x, breaks = \"Sturges\",\n      freq = NULL, probability = !freq,\n      include.lowest = TRUE, right = TRUE, fuzz = 1e-7,\n      density = NULL, angle = 45, col = \"lightgray\", border = NULL,\n      main = paste(\"Histogram of\" , xname),\n      xlim = range(breaks), ylim = NULL,\n      xlab = xname, ylab,\n      axes = TRUE, plot = TRUE, labels = FALSE,\n      nclass = NULL, warn.unused = TRUE, ...)\n \nArguments:\n   x: a vector of values for which the histogram is desired.\nbreaks: one of:\n        * a vector giving the breakpoints between histogram cells,\n\n        * a function to compute the vector of breakpoints,\n\n        * a single number giving the number of cells for the\n          histogram,\n\n        * a character string naming an algorithm to compute the\n          number of cells (see 'Details'),\n\n        * a function to compute the number of cells.\n\n      In the last three cases the number is a suggestion only; as\n      the breakpoints will be set to 'pretty' values, the number is\n      limited to '1e6' (with a warning if it was larger).  If\n      'breaks' is a function, the 'x' vector is supplied to it as\n      the only argument (and the number of breaks is only limited\n      by the amount of available memory).\n\nfreq: logical; if 'TRUE', the histogram graphic is a representation\n      of frequencies, the 'counts' component of the result; if\n      'FALSE', probability densities, component 'density', are\n      plotted (so that the histogram has a total area of one).\n      Defaults to 'TRUE' _if and only if_ 'breaks' are equidistant\n      (and 'probability' is not specified).\nprobability: an alias for ‘!freq’, for S compatibility.\ninclude.lowest: logical; if ‘TRUE’, an ‘x[i]’ equal to the ‘breaks’ value will be included in the first (or last, for ‘right = FALSE’) bar. This will be ignored (with a warning) unless ‘breaks’ is a vector.\nright: logical; if ‘TRUE’, the histogram cells are right-closed (left open) intervals.\nfuzz: non-negative number, for the case when the data is \"pretty\"\n      and some observations 'x[.]' are close but not exactly on a\n      'break'.  For counting fuzzy breaks proportional to 'fuzz'\n      are used.  The default is occasionally suboptimal.\ndensity: the density of shading lines, in lines per inch. The default value of ‘NULL’ means that no shading lines are drawn. Non-positive values of ‘density’ also inhibit the drawing of shading lines.\nangle: the slope of shading lines, given as an angle in degrees (counter-clockwise).\n col: a colour to be used to fill the bars.\nborder: the color of the border around the bars. The default is to use the standard foreground color.\nmain, xlab, ylab: main title and axis labels: these arguments to ‘title()’ get “smart” defaults here, e.g., the default ‘ylab’ is ‘“Frequency”’ iff ‘freq’ is true.\nxlim, ylim: the range of x and y values with sensible defaults. Note that ‘xlim’ is not used to define the histogram (breaks), but only for plotting (when ‘plot = TRUE’).\naxes: logical.  If 'TRUE' (default), axes are draw if the plot is\n      drawn.\n\nplot: logical.  If 'TRUE' (default), a histogram is plotted,\n      otherwise a list of breaks and counts is returned.  In the\n      latter case, a warning is used if (typically graphical)\n      arguments are specified that only apply to the 'plot = TRUE'\n      case.\nlabels: logical or character string. Additionally draw labels on top of bars, if not ‘FALSE’; see ‘plot.histogram’.\nnclass: numeric (integer). For S(-PLUS) compatibility only, ‘nclass’ is equivalent to ‘breaks’ for a scalar or character argument.\nwarn.unused: logical. If ‘plot = FALSE’ and ‘warn.unused = TRUE’, a warning will be issued when graphical parameters are passed to ‘hist.default()’.\n ...: further arguments and graphical parameters passed to\n      'plot.histogram' and thence to 'title' and 'axis' (if 'plot =\n      TRUE').\nDetails:\n The definition of _histogram_ differs by source (with\n country-specific biases).  R's default with equispaced breaks\n (also the default) is to plot the counts in the cells defined by\n 'breaks'.  Thus the height of a rectangle is proportional to the\n number of points falling into the cell, as is the area _provided_\n the breaks are equally-spaced.\n\n The default with non-equispaced breaks is to give a plot of area\n one, in which the _area_ of the rectangles is the fraction of the\n data points falling in the cells.\n\n If 'right = TRUE' (default), the histogram cells are intervals of\n the form (a, b], i.e., they include their right-hand endpoint, but\n not their left one, with the exception of the first cell when\n 'include.lowest' is 'TRUE'.\n\n For 'right = FALSE', the intervals are of the form [a, b), and\n 'include.lowest' means '_include highest_'.\n\n A numerical tolerance of 1e-7 times the median bin size (for more\n than four bins, otherwise the median is substituted) is applied\n when counting entries on the edges of bins.  This is not included\n in the reported 'breaks' nor in the calculation of 'density'.\n\n The default for 'breaks' is '\"Sturges\"': see 'nclass.Sturges'.\n Other names for which algorithms are supplied are '\"Scott\"' and\n '\"FD\"' / '\"Freedman-Diaconis\"' (with corresponding functions\n 'nclass.scott' and 'nclass.FD').  Case is ignored and partial\n matching is used.  Alternatively, a function can be supplied which\n will compute the intended number of breaks or the actual\n breakpoints as a function of 'x'.\nValue:\n an object of class '\"histogram\"' which is a list with components:\nbreaks: the n+1 cell boundaries (= ‘breaks’ if that was a vector). These are the nominal breaks, not with the boundary fuzz.\ncounts: n integers; for each cell, the number of ‘x[]’ inside.\ndensity: values f^(x[i]), as estimated density values. If ‘all(diff(breaks) == 1)’, they are the relative frequencies ‘counts/n’ and in general satisfy sum[i; f^(x[i]) (b[i+1]-b[i])] = 1, where b[i] = ‘breaks[i]’.\nmids: the n cell midpoints.\nxname: a character string with the actual ‘x’ argument name.\nequidist: logical, indicating if the distances between ‘breaks’ are all the same.\nReferences:\n Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S\n Language_.  Wadsworth & Brooks/Cole.\n\n Venables, W. N. and Ripley. B. D. (2002) _Modern Applied\n Statistics with S_.  Springer.\nSee Also:\n 'nclass.Sturges', 'stem', 'density', 'truehist' in package 'MASS'.\n\n Typical plots with vertical bars are _not_ histograms.  Consider\n 'barplot' or 'plot(*, type = \"h\")' for such bar plots.\nExamples:\n op &lt;- par(mfrow = c(2, 2))\n hist(islands)\n utils::str(hist(islands, col = \"gray\", labels = TRUE))\n \n hist(sqrt(islands), breaks = 12, col = \"lightblue\", border = \"pink\")\n ##-- For non-equidistant breaks, counts should NOT be graphed unscaled:\n r &lt;- hist(sqrt(islands), breaks = c(4*0:5, 10*3:5, 70, 100, 140),\n           col = \"blue1\")\n text(r$mids, r$density, r$counts, adj = c(.5, -.5), col = \"blue3\")\n sapply(r[2:3], sum)\n sum(r$density * diff(r$breaks)) # == 1\n lines(r, lty = 3, border = \"purple\") # -&gt; lines.histogram(*)\n par(op)\n \n require(utils) # for str\n str(hist(islands, breaks = 12, plot =  FALSE)) #-&gt; 10 (~= 12) breaks\n str(hist(islands, breaks = c(12,20,36,80,200,1000,17000), plot = FALSE))\n \n hist(islands, breaks = c(12,20,36,80,200,1000,17000), freq = TRUE,\n      main = \"WRONG histogram\") # and warning\n \n ## Extreme outliers; the \"FD\" rule would take very large number of 'breaks':\n XXL &lt;- c(1:9, c(-1,1)*1e300)\n hh &lt;- hist(XXL, \"FD\") # did not work in R &lt;= 3.4.1; now gives warning\n ## pretty() determines how many counts are used (platform dependently!):\n length(hh$breaks) ## typically 1 million -- though 1e6 was \"a suggestion only\"\n \n ## R &gt;= 4.2.0: no \"*.5\" labels on y-axis:\n hist(c(2,3,3,5,5,6,6,6,7))\n \n require(stats)\n set.seed(14)\n x &lt;- rchisq(100, df = 4)\n \n ## Histogram with custom x-axis:\n hist(x, xaxt = \"n\")\n axis(1, at = 0:17)\n \n \n ## Comparing data with a model distribution should be done with qqplot()!\n qqplot(x, qchisq(ppoints(x), df = 4)); abline(0, 1, col = 2, lty = 2)\n \n ## if you really insist on using hist() ... :\n hist(x, freq = FALSE, ylim = c(0, 0.2))\n curve(dchisq(x, df = 4), col = 2, lty = 2, lwd = 2, add = TRUE)",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#hist-example",
    "href": "modules/Module10-DataVisualization.html#hist-example",
    "title": "Module 10: Data Visualization",
    "section": "hist() example",
    "text": "hist() example\nReminder function signature\nhist(x, breaks = \"Sturges\",\n     freq = NULL, probability = !freq,\n     include.lowest = TRUE, right = TRUE, fuzz = 1e-7,\n     density = NULL, angle = 45, col = \"lightgray\", border = NULL,\n     main = paste(\"Histogram of\" , xname),\n     xlim = range(breaks), ylim = NULL,\n     xlab = xname, ylab,\n     axes = TRUE, plot = TRUE, labels = FALSE,\n     nclass = NULL, warn.unused = TRUE, ...)\nLet’s practice\n\nhist(df$age)\n\n\n\n\n\n\n\nhist(\n    df$age, \n    freq=FALSE, \n    main=\"Histogram\", \n    xlab=\"Age (years)\"\n    )",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#plot-help-file",
    "href": "modules/Module10-DataVisualization.html#plot-help-file",
    "title": "Module 10: Data Visualization",
    "section": "plot() Help File",
    "text": "plot() Help File\n\n?plot\n\nGeneric X-Y Plotting\nDescription:\n Generic function for plotting of R objects.\n\n For simple scatter plots, 'plot.default' will be used.  However,\n there are 'plot' methods for many R objects, including\n 'function's, 'data.frame's, 'density' objects, etc.  Use\n 'methods(plot)' and the documentation for these. Most of these\n methods are implemented using traditional graphics (the 'graphics'\n package), but this is not mandatory.\n\n For more details about graphical parameter arguments used by\n traditional graphics, see 'par'.\nUsage:\n plot(x, y, ...)\n \nArguments:\n   x: the coordinates of points in the plot. Alternatively, a\n      single plotting structure, function or _any R object with a\n      'plot' method_ can be provided.\n\n   y: the y coordinates of points in the plot, _optional_ if 'x' is\n      an appropriate structure.\n\n ...: arguments to be passed to methods, such as graphical\n      parameters (see 'par').  Many methods will accept the\n      following arguments:\n\n      'type' what type of plot should be drawn.  Possible types are\n\n            * '\"p\"' for *p*oints,\n\n            * '\"l\"' for *l*ines,\n\n            * '\"b\"' for *b*oth,\n\n            * '\"c\"' for the lines part alone of '\"b\"',\n\n            * '\"o\"' for both '*o*verplotted',\n\n            * '\"h\"' for '*h*istogram' like (or 'high-density')\n              vertical lines,\n\n            * '\"s\"' for stair *s*teps,\n\n            * '\"S\"' for other *s*teps, see 'Details' below,\n\n            * '\"n\"' for no plotting.\n\n          All other 'type's give a warning or an error; using,\n          e.g., 'type = \"punkte\"' being equivalent to 'type = \"p\"'\n          for S compatibility.  Note that some methods, e.g.\n          'plot.factor', do not accept this.\n\n      'main' an overall title for the plot: see 'title'.\n\n      'sub' a subtitle for the plot: see 'title'.\n\n      'xlab' a title for the x axis: see 'title'.\n\n      'ylab' a title for the y axis: see 'title'.\n\n      'asp' the y/x aspect ratio, see 'plot.window'.\nDetails:\n The two step types differ in their x-y preference: Going from\n (x1,y1) to (x2,y2) with x1 &lt; x2, 'type = \"s\"' moves first\n horizontal, then vertical, whereas 'type = \"S\"' moves the other\n way around.\nNote:\n The 'plot' generic was moved from the 'graphics' package to the\n 'base' package in R 4.0.0. It is currently re-exported from the\n 'graphics' namespace to allow packages importing it from there to\n continue working, but this may change in future versions of R.\nSee Also:\n 'plot.default', 'plot.formula' and other methods; 'points',\n 'lines', 'par'.  For thousands of points, consider using\n 'smoothScatter()' instead of 'plot()'.\n\n For X-Y-Z plotting see 'contour', 'persp' and 'image'.\nExamples:\n require(stats) # for lowess, rpois, rnorm\n require(graphics) # for plot methods\n plot(cars)\n lines(lowess(cars))\n \n plot(sin, -pi, 2*pi) # see ?plot.function\n \n ## Discrete Distribution Plot:\n plot(table(rpois(100, 5)), type = \"h\", col = \"red\", lwd = 10,\n      main = \"rpois(100, lambda = 5)\")\n \n ## Simple quantiles/ECDF, see ecdf() {library(stats)} for a better one:\n plot(x &lt;- sort(rnorm(47)), type = \"s\", main = \"plot(x, type = \\\"s\\\")\")\n points(x, cex = .5, col = \"dark red\")",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#plot-example",
    "href": "modules/Module10-DataVisualization.html#plot-example",
    "title": "Module 10: Data Visualization",
    "section": "plot() example",
    "text": "plot() example\n\nplot(df$age, df$IgG_concentration)\n\n\n\n\n\n\n\nplot(\n    df$age, \n    df$IgG_concentration, \n    type=\"p\", \n    main=\"Age by IgG Concentrations\", \n    xlab=\"Age (years)\", \n    ylab=\"IgG Concentration (IU/mL)\", \n    pch=16, \n    cex=0.9,\n    col=\"lightblue\")",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#adding-more-stuff-to-the-same-plot",
    "href": "modules/Module10-DataVisualization.html#adding-more-stuff-to-the-same-plot",
    "title": "Module 10: Data Visualization",
    "section": "Adding more stuff to the same plot",
    "text": "Adding more stuff to the same plot\n\nWe can use the functions points() or lines() to add additional points or additional lines to an existing plot.\n\n\nplot(\n    df$age[df$slum == \"Non slum\"],\n    df$IgG_concentration[df$slum == \"Non slum\"],\n    type = \"p\",\n    main = \"IgG Concentration vs Age\",\n    xlab = \"Age (years)\",\n    ylab = \"IgG Concentration (IU/mL)\",\n    pch = 16,\n    cex = 0.9,\n    col = \"lightblue\",\n    xlim = range(df$age, na.rm = TRUE),\n    ylim = range(df$IgG_concentration, na.rm = TRUE)\n)\npoints(\n    df$age[df$slum == \"Mixed\"],\n    df$IgG_concentration[df$slum == \"Mixed\"],\n    pch = 16,\n    cex = 0.9,\n    col = \"blue\"\n)\npoints(\n    df$age[df$slum == \"Slum\"],\n    df$IgG_concentration[df$slum == \"Slum\"],\n    pch = 16,\n    cex = 0.9,\n    col = \"darkblue\"\n)\n\n\n\nThe lines() function works similarly for connected lines.\nNote that the points() or lines() functions must be called with a plot()-style function\nWe will show how we could draw a legend() in a future section.",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#boxplot-help-file",
    "href": "modules/Module10-DataVisualization.html#boxplot-help-file",
    "title": "Module 10: Data Visualization",
    "section": "boxplot() Help File",
    "text": "boxplot() Help File\n\n?boxplot\n\nBox Plots\nDescription:\n Produce box-and-whisker plot(s) of the given (grouped) values.\nUsage:\n boxplot(x, ...)\n \n ## S3 method for class 'formula'\n boxplot(formula, data = NULL, ..., subset, na.action = NULL,\n         xlab = mklab(y_var = horizontal),\n         ylab = mklab(y_var =!horizontal),\n         add = FALSE, ann = !add, horizontal = FALSE,\n         drop = FALSE, sep = \".\", lex.order = FALSE)\n \n ## Default S3 method:\n boxplot(x, ..., range = 1.5, width = NULL, varwidth = FALSE,\n         notch = FALSE, outline = TRUE, names, plot = TRUE,\n         border = par(\"fg\"), col = \"lightgray\", log = \"\",\n         pars = list(boxwex = 0.8, staplewex = 0.5, outwex = 0.5),\n          ann = !add, horizontal = FALSE, add = FALSE, at = NULL)\n \nArguments:\nformula: a formula, such as ‘y ~ grp’, where ‘y’ is a numeric vector of data values to be split into groups according to the grouping variable ‘grp’ (usually a factor). Note that ‘~ g1 + g2’ is equivalent to ‘g1:g2’.\ndata: a data.frame (or list) from which the variables in 'formula'\n      should be taken.\nsubset: an optional vector specifying a subset of observations to be used for plotting.\nna.action: a function which indicates what should happen when the data contain ’NA’s. The default is to ignore missing values in either the response or the group.\nxlab, ylab: x- and y-axis annotation, since R 3.6.0 with a non-empty default. Can be suppressed by ‘ann=FALSE’.\n ann: 'logical' indicating if axes should be annotated (by 'xlab'\n      and 'ylab').\ndrop, sep, lex.order: passed to ‘split.default’, see there.\n   x: for specifying data from which the boxplots are to be\n      produced. Either a numeric vector, or a single list\n      containing such vectors. Additional unnamed arguments specify\n      further data as separate vectors (each corresponding to a\n      component boxplot).  'NA's are allowed in the data.\n\n ...: For the 'formula' method, named arguments to be passed to the\n      default method.\n\n      For the default method, unnamed arguments are additional data\n      vectors (unless 'x' is a list when they are ignored), and\n      named arguments are arguments and graphical parameters to be\n      passed to 'bxp' in addition to the ones given by argument\n      'pars' (and override those in 'pars'). Note that 'bxp' may or\n      may not make use of graphical parameters it is passed: see\n      its documentation.\nrange: this determines how far the plot whiskers extend out from the box. If ‘range’ is positive, the whiskers extend to the most extreme data point which is no more than ‘range’ times the interquartile range from the box. A value of zero causes the whiskers to extend to the data extremes.\nwidth: a vector giving the relative widths of the boxes making up the plot.\nvarwidth: if ‘varwidth’ is ‘TRUE’, the boxes are drawn with widths proportional to the square-roots of the number of observations in the groups.\nnotch: if ‘notch’ is ‘TRUE’, a notch is drawn in each side of the boxes. If the notches of two plots do not overlap this is ‘strong evidence’ that the two medians differ (Chambers et al., 1983, p. 62). See ‘boxplot.stats’ for the calculations used.\noutline: if ‘outline’ is not true, the outliers are not drawn (as points whereas S+ uses lines).\nnames: group labels which will be printed under each boxplot. Can be a character vector or an expression (see plotmath).\nboxwex: a scale factor to be applied to all boxes. When there are only a few groups, the appearance of the plot can be improved by making the boxes narrower.\nstaplewex: staple line width expansion, proportional to box width.\noutwex: outlier line width expansion, proportional to box width.\nplot: if 'TRUE' (the default) then a boxplot is produced.  If not,\n      the summaries which the boxplots are based on are returned.\nborder: an optional vector of colors for the outlines of the boxplots. The values in ‘border’ are recycled if the length of ‘border’ is less than the number of plots.\n col: if 'col' is non-null it is assumed to contain colors to be\n      used to colour the bodies of the box plots. By default they\n      are in the background colour.\n\n log: character indicating if x or y or both coordinates should be\n      plotted in log scale.\n\npars: a list of (potentially many) more graphical parameters, e.g.,\n      'boxwex' or 'outpch'; these are passed to 'bxp' (if 'plot' is\n      true); for details, see there.\nhorizontal: logical indicating if the boxplots should be horizontal; default ‘FALSE’ means vertical boxes.\n add: logical, if true _add_ boxplot to current plot.\n\n  at: numeric vector giving the locations where the boxplots should\n      be drawn, particularly when 'add = TRUE'; defaults to '1:n'\n      where 'n' is the number of boxes.\nDetails:\n The generic function 'boxplot' currently has a default method\n ('boxplot.default') and a formula interface ('boxplot.formula').\n\n If multiple groups are supplied either as multiple arguments or\n via a formula, parallel boxplots will be plotted, in the order of\n the arguments or the order of the levels of the factor (see\n 'factor').\n\n Missing values are ignored when forming boxplots.\nValue:\n List with the following components:\nstats: a matrix, each column contains the extreme of the lower whisker, the lower hinge, the median, the upper hinge and the extreme of the upper whisker for one group/plot. If all the inputs have the same class attribute, so will this component.\n   n: a vector with the number of (non-'NA') observations in each\n      group.\n\nconf: a matrix where each column contains the lower and upper\n      extremes of the notch.\n\n out: the values of any data points which lie beyond the extremes\n      of the whiskers.\ngroup: a vector of the same length as ‘out’ whose elements indicate to which group the outlier belongs.\nnames: a vector of names for the groups.\nReferences:\n Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988).  _The New\n S Language_.  Wadsworth & Brooks/Cole.\n\n Chambers, J. M., Cleveland, W. S., Kleiner, B. and Tukey, P. A.\n (1983).  _Graphical Methods for Data Analysis_.  Wadsworth &\n Brooks/Cole.\n\n Murrell, P. (2005).  _R Graphics_.  Chapman & Hall/CRC Press.\n\n See also 'boxplot.stats'.\nSee Also:\n 'boxplot.stats' which does the computation, 'bxp' for the plotting\n and more examples; and 'stripchart' for an alternative (with small\n data sets).\nExamples:\n ## boxplot on a formula:\n boxplot(count ~ spray, data = InsectSprays, col = \"lightgray\")\n # *add* notches (somewhat funny here &lt;--&gt; warning \"notches .. outside hinges\"):\n boxplot(count ~ spray, data = InsectSprays,\n         notch = TRUE, add = TRUE, col = \"blue\")\n \n boxplot(decrease ~ treatment, data = OrchardSprays, col = \"bisque\",\n         log = \"y\")\n ## horizontal=TRUE, switching  y &lt;--&gt; x :\n boxplot(decrease ~ treatment, data = OrchardSprays, col = \"bisque\",\n         log = \"x\", horizontal=TRUE)\n \n rb &lt;- boxplot(decrease ~ treatment, data = OrchardSprays, col = \"bisque\")\n title(\"Comparing boxplot()s and non-robust mean +/- SD\")\n mn.t &lt;- tapply(OrchardSprays$decrease, OrchardSprays$treatment, mean)\n sd.t &lt;- tapply(OrchardSprays$decrease, OrchardSprays$treatment, sd)\n xi &lt;- 0.3 + seq(rb$n)\n points(xi, mn.t, col = \"orange\", pch = 18)\n arrows(xi, mn.t - sd.t, xi, mn.t + sd.t,\n        code = 3, col = \"pink\", angle = 75, length = .1)\n \n ## boxplot on a matrix:\n mat &lt;- cbind(Uni05 = (1:100)/21, Norm = rnorm(100),\n              `5T` = rt(100, df = 5), Gam2 = rgamma(100, shape = 2))\n boxplot(mat) # directly, calling boxplot.matrix()\n \n ## boxplot on a data frame:\n df. &lt;- as.data.frame(mat)\n par(las = 1) # all axis labels horizontal\n boxplot(df., main = \"boxplot(*, horizontal = TRUE)\", horizontal = TRUE)\n \n ## Using 'at = ' and adding boxplots -- example idea by Roger Bivand :\n boxplot(len ~ dose, data = ToothGrowth,\n         boxwex = 0.25, at = 1:3 - 0.2,\n         subset = supp == \"VC\", col = \"yellow\",\n         main = \"Guinea Pigs' Tooth Growth\",\n         xlab = \"Vitamin C dose mg\",\n         ylab = \"tooth length\",\n         xlim = c(0.5, 3.5), ylim = c(0, 35), yaxs = \"i\")\n boxplot(len ~ dose, data = ToothGrowth, add = TRUE,\n         boxwex = 0.25, at = 1:3 + 0.2,\n         subset = supp == \"OJ\", col = \"orange\")\n legend(2, 9, c(\"Ascorbic acid\", \"Orange juice\"),\n        fill = c(\"yellow\", \"orange\"))\n \n ## With less effort (slightly different) using factor *interaction*:\n boxplot(len ~ dose:supp, data = ToothGrowth,\n         boxwex = 0.5, col = c(\"orange\", \"yellow\"),\n         main = \"Guinea Pigs' Tooth Growth\",\n         xlab = \"Vitamin C dose mg\", ylab = \"tooth length\",\n         sep = \":\", lex.order = TRUE, ylim = c(0, 35), yaxs = \"i\")\n \n ## more examples in  help(bxp)",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#boxplot-example",
    "href": "modules/Module10-DataVisualization.html#boxplot-example",
    "title": "Module 10: Data Visualization",
    "section": "boxplot() example",
    "text": "boxplot() example\nReminder function signature\nboxplot(formula, data = NULL, ..., subset, na.action = NULL,\n        xlab = mklab(y_var = horizontal),\n        ylab = mklab(y_var =!horizontal),\n        add = FALSE, ann = !add, horizontal = FALSE,\n        drop = FALSE, sep = \".\", lex.order = FALSE)\nLet’s practice\n\nboxplot(IgG_concentration~age_group, data=df)\n\n\n\n\n\n\n\nboxplot(\n    log(df$IgG_concentration)~df$age_group, \n    main=\"Age by IgG Concentrations\", \n    xlab=\"Age Group (years)\", \n    ylab=\"log IgG Concentration (mIU/mL)\", \n    names=c(\"1-5\",\"6-10\", \"11-15\"), \n    varwidth=T\n    )",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#barplot-help-file",
    "href": "modules/Module10-DataVisualization.html#barplot-help-file",
    "title": "Module 10: Data Visualization",
    "section": "barplot() Help File",
    "text": "barplot() Help File\n\n?barplot\n\nBar Plots\nDescription:\n Creates a bar plot with vertical or horizontal bars.\nUsage:\n barplot(height, ...)\n \n ## Default S3 method:\n barplot(height, width = 1, space = NULL,\n         names.arg = NULL, legend.text = NULL, beside = FALSE,\n         horiz = FALSE, density = NULL, angle = 45,\n         col = NULL, border = par(\"fg\"),\n         main = NULL, sub = NULL, xlab = NULL, ylab = NULL,\n         xlim = NULL, ylim = NULL, xpd = TRUE, log = \"\",\n         axes = TRUE, axisnames = TRUE,\n         cex.axis = par(\"cex.axis\"), cex.names = par(\"cex.axis\"),\n         inside = TRUE, plot = TRUE, axis.lty = 0, offset = 0,\n         add = FALSE, ann = !add && par(\"ann\"), args.legend = NULL, ...)\n \n ## S3 method for class 'formula'\n barplot(formula, data, subset, na.action,\n         horiz = FALSE, xlab = NULL, ylab = NULL, ...)\n \nArguments:\nheight: either a vector or matrix of values describing the bars which make up the plot. If ‘height’ is a vector, the plot consists of a sequence of rectangular bars with heights given by the values in the vector. If ‘height’ is a matrix and ‘beside’ is ‘FALSE’ then each bar of the plot corresponds to a column of ‘height’, with the values in the column giving the heights of stacked sub-bars making up the bar. If ‘height’ is a matrix and ‘beside’ is ‘TRUE’, then the values in each column are juxtaposed rather than stacked.\nwidth: optional vector of bar widths. Re-cycled to length the number of bars drawn. Specifying a single value will have no visible effect unless ‘xlim’ is specified.\nspace: the amount of space (as a fraction of the average bar width) left before each bar. May be given as a single number or one number per bar. If ‘height’ is a matrix and ‘beside’ is ‘TRUE’, ‘space’ may be specified by two numbers, where the first is the space between bars in the same group, and the second the space between the groups. If not given explicitly, it defaults to ‘c(0,1)’ if ‘height’ is a matrix and ‘beside’ is ‘TRUE’, and to 0.2 otherwise.\nnames.arg: a vector of names to be plotted below each bar or group of bars. If this argument is omitted, then the names are taken from the ‘names’ attribute of ‘height’ if this is a vector, or the column names if it is a matrix.\nlegend.text: a vector of text used to construct a legend for the plot, or a logical indicating whether a legend should be included. This is only useful when ‘height’ is a matrix. In that case given legend labels should correspond to the rows of ‘height’; if ‘legend.text’ is true, the row names of ‘height’ will be used as labels if they are non-null.\nbeside: a logical value. If ‘FALSE’, the columns of ‘height’ are portrayed as stacked bars, and if ‘TRUE’ the columns are portrayed as juxtaposed bars.\nhoriz: a logical value. If ‘FALSE’, the bars are drawn vertically with the first bar to the left. If ‘TRUE’, the bars are drawn horizontally with the first at the bottom.\ndensity: a vector giving the density of shading lines, in lines per inch, for the bars or bar components. The default value of ‘NULL’ means that no shading lines are drawn. Non-positive values of ‘density’ also inhibit the drawing of shading lines.\nangle: the slope of shading lines, given as an angle in degrees (counter-clockwise), for the bars or bar components.\n col: a vector of colors for the bars or bar components.  By\n      default, '\"grey\"' is used if 'height' is a vector, and a\n      gamma-corrected grey palette if 'height' is a matrix; see\n      'grey.colors'.\nborder: the color to be used for the border of the bars. Use ‘border = NA’ to omit borders. If there are shading lines, ‘border = TRUE’ means use the same colour for the border as for the shading lines.\nmain, sub: main title and subtitle for the plot.\nxlab: a label for the x axis.\n\nylab: a label for the y axis.\n\nxlim: limits for the x axis.\n\nylim: limits for the y axis.\n\n xpd: logical. Should bars be allowed to go outside region?\n\n log: string specifying if axis scales should be logarithmic; see\n      'plot.default'.\n\naxes: logical.  If 'TRUE', a vertical (or horizontal, if 'horiz' is\n      true) axis is drawn.\naxisnames: logical. If ‘TRUE’, and if there are ‘names.arg’ (see above), the other axis is drawn (with ‘lty = 0’) and labeled.\ncex.axis: expansion factor for numeric axis labels (see ‘par(’cex’)’).\ncex.names: expansion factor for axis names (bar labels).\ninside: logical. If ‘TRUE’, the lines which divide adjacent (non-stacked!) bars will be drawn. Only applies when ‘space = 0’ (which it partly is when ‘beside = TRUE’).\nplot: logical.  If 'FALSE', nothing is plotted.\naxis.lty: the graphics parameter ‘lty’ (see ‘par(’lty’)’) applied to the axis and tick marks of the categorical (default horizontal) axis. Note that by default the axis is suppressed.\noffset: a vector indicating how much the bars should be shifted relative to the x axis.\n add: logical specifying if bars should be added to an already\n      existing plot; defaults to 'FALSE'.\n\n ann: logical specifying if the default annotation ('main', 'sub',\n      'xlab', 'ylab') should appear on the plot, see 'title'.\nargs.legend: list of additional arguments to pass to ‘legend()’; names of the list are used as argument names. Only used if ‘legend.text’ is supplied.\nformula: a formula where the ‘y’ variables are numeric data to plot against the categorical ‘x’ variables. The formula can have one of three forms:\n            y ~ x\n            y ~ x1 + x2\n            cbind(y1, y2) ~ x\n      \n      (see the examples).\n\ndata: a data frame (or list) from which the variables in formula\n      should be taken.\nsubset: an optional vector specifying a subset of observations to be used.\nna.action: a function which indicates what should happen when the data contain ‘NA’ values. The default is to ignore missing values in the given variables.\n ...: arguments to be passed to/from other methods.  For the\n      default method these can include further arguments (such as\n      'axes', 'asp' and 'main') and graphical parameters (see\n      'par') which are passed to 'plot.window()', 'title()' and\n      'axis'.\nValue:\n A numeric vector (or matrix, when 'beside = TRUE'), say 'mp',\n giving the coordinates of _all_ the bar midpoints drawn, useful\n for adding to the graph.\n\n If 'beside' is true, use 'colMeans(mp)' for the midpoints of each\n _group_ of bars, see example.\nAuthor(s):\n R Core, with a contribution by Arni Magnusson.\nReferences:\n Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S\n Language_.  Wadsworth & Brooks/Cole.\n\n Murrell, P. (2005) _R Graphics_. Chapman & Hall/CRC Press.\nSee Also:\n 'plot(..., type = \"h\")', 'dotchart'; 'hist' for bars of a\n _continuous_ variable.  'mosaicplot()', more sophisticated to\n visualize _several_ categorical variables.\nExamples:\n # Formula method\n barplot(GNP ~ Year, data = longley)\n barplot(cbind(Employed, Unemployed) ~ Year, data = longley)\n \n ## 3rd form of formula - 2 categories :\n op &lt;- par(mfrow = 2:1, mgp = c(3,1,0)/2, mar = .1+c(3,3:1))\n summary(d.Titanic &lt;- as.data.frame(Titanic))\n barplot(Freq ~ Class + Survived, data = d.Titanic,\n         subset = Age == \"Adult\" & Sex == \"Male\",\n         main = \"barplot(Freq ~ Class + Survived, *)\", ylab = \"# {passengers}\", legend.text = TRUE)\n # Corresponding table :\n (xt &lt;- xtabs(Freq ~ Survived + Class + Sex, d.Titanic, subset = Age==\"Adult\"))\n # Alternatively, a mosaic plot :\n mosaicplot(xt[,,\"Male\"], main = \"mosaicplot(Freq ~ Class + Survived, *)\", color=TRUE)\n par(op)\n \n \n # Default method\n require(grDevices) # for colours\n tN &lt;- table(Ni &lt;- stats::rpois(100, lambda = 5))\n r &lt;- barplot(tN, col = rainbow(20))\n #- type = \"h\" plotting *is* 'bar'plot\n lines(r, tN, type = \"h\", col = \"red\", lwd = 2)\n \n barplot(tN, space = 1.5, axisnames = FALSE,\n         sub = \"barplot(..., space= 1.5, axisnames = FALSE)\")\n \n barplot(VADeaths, plot = FALSE)\n barplot(VADeaths, plot = FALSE, beside = TRUE)\n \n mp &lt;- barplot(VADeaths) # default\n tot &lt;- colMeans(VADeaths)\n text(mp, tot + 3, format(tot), xpd = TRUE, col = \"blue\")\n barplot(VADeaths, beside = TRUE,\n         col = c(\"lightblue\", \"mistyrose\", \"lightcyan\",\n                 \"lavender\", \"cornsilk\"),\n         legend.text = rownames(VADeaths), ylim = c(0, 100))\n title(main = \"Death Rates in Virginia\", font.main = 4)\n \n hh &lt;- t(VADeaths)[, 5:1]\n mybarcol &lt;- \"gray20\"\n mp &lt;- barplot(hh, beside = TRUE,\n         col = c(\"lightblue\", \"mistyrose\",\n                 \"lightcyan\", \"lavender\"),\n         legend.text = colnames(VADeaths), ylim = c(0,100),\n         main = \"Death Rates in Virginia\", font.main = 4,\n         sub = \"Faked upper 2*sigma error bars\", col.sub = mybarcol,\n         cex.names = 1.5)\n segments(mp, hh, mp, hh + 2*sqrt(1000*hh/100), col = mybarcol, lwd = 1.5)\n stopifnot(dim(mp) == dim(hh))  # corresponding matrices\n mtext(side = 1, at = colMeans(mp), line = -2,\n       text = paste(\"Mean\", formatC(colMeans(hh))), col = \"red\")\n \n # Bar shading example\n barplot(VADeaths, angle = 15+10*1:5, density = 20, col = \"black\",\n         legend.text = rownames(VADeaths))\n title(main = list(\"Death Rates in Virginia\", font = 4))\n \n # Border color\n barplot(VADeaths, border = \"dark blue\") \n \n # Log scales (not much sense here)\n barplot(tN, col = heat.colors(12), log = \"y\")\n barplot(tN, col = gray.colors(20), log = \"xy\")\n \n # Legend location\n barplot(height = cbind(x = c(465, 91) / 465 * 100,\n                        y = c(840, 200) / 840 * 100,\n                        z = c(37, 17) / 37 * 100),\n         beside = FALSE,\n         width = c(465, 840, 37),\n         col = c(1, 2),\n         legend.text = c(\"A\", \"B\"),\n         args.legend = list(x = \"topleft\"))",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#barplot-example",
    "href": "modules/Module10-DataVisualization.html#barplot-example",
    "title": "Module 10: Data Visualization",
    "section": "barplot() example",
    "text": "barplot() example\nThe function takes the a lot of arguments to control the way the way our data is plotted.\nReminder function signature\nbarplot(height, width = 1, space = NULL,\n        names.arg = NULL, legend.text = NULL, beside = FALSE,\n        horiz = FALSE, density = NULL, angle = 45,\n        col = NULL, border = par(\"fg\"),\n        main = NULL, sub = NULL, xlab = NULL, ylab = NULL,\n        xlim = NULL, ylim = NULL, xpd = TRUE, log = \"\",\n        axes = TRUE, axisnames = TRUE,\n        cex.axis = par(\"cex.axis\"), cex.names = par(\"cex.axis\"),\n        inside = TRUE, plot = TRUE, axis.lty = 0, offset = 0,\n        add = FALSE, ann = !add && par(\"ann\"), args.legend = NULL, ...)\n\nfreq &lt;- table(df$seropos, df$age_group)\nbarplot(freq)\n\n\n\n\n\n\n\nprop.cell.percentages &lt;- prop.table(freq)\nbarplot(prop.cell.percentages)",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#legend",
    "href": "modules/Module10-DataVisualization.html#legend",
    "title": "Module 10: Data Visualization",
    "section": "3. Legend!",
    "text": "3. Legend!\nIn Base R plotting the legend is not automatically generated. This is nice because it gives you a huge amount of control over how your legend looks, but it is also easy to mislabel your colors, symbols, line types, etc. So, basically be careful.\n\n?legend\n\n\n\nAdd Legends to Plots\n\nDescription:\n\n     This function can be used to add legends to plots.  Note that a\n     call to the function 'locator(1)' can be used in place of the 'x'\n     and 'y' arguments.\n\nUsage:\n\n     legend(x, y = NULL, legend, fill = NULL, col = par(\"col\"),\n            border = \"black\", lty, lwd, pch,\n            angle = 45, density = NULL, bty = \"o\", bg = par(\"bg\"),\n            box.lwd = par(\"lwd\"), box.lty = par(\"lty\"), box.col = par(\"fg\"),\n            pt.bg = NA, cex = 1, pt.cex = cex, pt.lwd = lwd,\n            xjust = 0, yjust = 1, x.intersp = 1, y.intersp = 1,\n            adj = c(0, 0.5), text.width = NULL, text.col = par(\"col\"),\n            text.font = NULL, merge = do.lines && has.pch, trace = FALSE,\n            plot = TRUE, ncol = 1, horiz = FALSE, title = NULL,\n            inset = 0, xpd, title.col = text.col[1], title.adj = 0.5,\n            title.cex = cex[1], title.font = text.font[1],\n            seg.len = 2)\n     \nArguments:\n\n    x, y: the x and y co-ordinates to be used to position the legend.\n          They can be specified by keyword or in any way which is\n          accepted by 'xy.coords': See 'Details'.\n\n  legend: a character or expression vector of length &gt;= 1 to appear in\n          the legend.  Other objects will be coerced by\n          'as.graphicsAnnot'.\n\n    fill: if specified, this argument will cause boxes filled with the\n          specified colors (or shaded in the specified colors) to\n          appear beside the legend text.\n\n     col: the color of points or lines appearing in the legend.\n\n  border: the border color for the boxes (used only if 'fill' is\n          specified).\n\nlty, lwd: the line types and widths for lines appearing in the legend.\n          One of these two _must_ be specified for line drawing.\n\n     pch: the plotting symbols appearing in the legend, as numeric\n          vector or a vector of 1-character strings (see 'points').\n          Unlike 'points', this can all be specified as a single\n          multi-character string.  _Must_ be specified for symbol\n          drawing.\n\n   angle: angle of shading lines.\n\n density: the density of shading lines, if numeric and positive. If\n          'NULL' or negative or 'NA' color filling is assumed.\n\n     bty: the type of box to be drawn around the legend.  The allowed\n          values are '\"o\"' (the default) and '\"n\"'.\n\n      bg: the background color for the legend box.  (Note that this is\n          only used if 'bty != \"n\"'.)\n\nbox.lty, box.lwd, box.col: the line type, width and color for the\n          legend box (if 'bty = \"o\"').\n\n   pt.bg: the background color for the 'points', corresponding to its\n          argument 'bg'.\n\n     cex: character expansion factor *relative* to current\n          'par(\"cex\")'.  Used for text, and provides the default for\n          'pt.cex'.\n\n  pt.cex: expansion factor(s) for the points.\n\n  pt.lwd: line width for the points, defaults to the one for lines, or\n          if that is not set, to 'par(\"lwd\")'.\n\n   xjust: how the legend is to be justified relative to the legend x\n          location.  A value of 0 means left justified, 0.5 means\n          centered and 1 means right justified.\n\n   yjust: the same as 'xjust' for the legend y location.\n\nx.intersp: character interspacing factor for horizontal (x) spacing\n          between symbol and legend text.\n\ny.intersp: vertical (y) distances (in lines of text shared above/below\n          each legend entry).  A vector with one element for each row\n          of the legend can be used.\n\n     adj: numeric of length 1 or 2; the string adjustment for legend\n          text.  Useful for y-adjustment when 'labels' are plotmath\n          expressions.\n\ntext.width: the width of the legend text in x ('\"user\"') coordinates.\n          (Should be positive even for a reversed x axis.)  Can be a\n          single positive numeric value (same width for each column of\n          the legend), a vector (one element for each column of the\n          legend), 'NULL' (default) for computing a proper maximum\n          value of 'strwidth(legend)'), or 'NA' for computing a proper\n          column wise maximum value of 'strwidth(legend)').\n\ntext.col: the color used for the legend text.\n\ntext.font: the font used for the legend text, see 'text'.\n\n   merge: logical; if 'TRUE', merge points and lines but not filled\n          boxes.  Defaults to 'TRUE' if there are points and lines.\n\n   trace: logical; if 'TRUE', shows how 'legend' does all its magical\n          computations.\n\n    plot: logical.  If 'FALSE', nothing is plotted but the sizes are\n          returned.\n\n    ncol: the number of columns in which to set the legend items\n          (default is 1, a vertical legend).\n\n   horiz: logical; if 'TRUE', set the legend horizontally rather than\n          vertically (specifying 'horiz' overrides the 'ncol'\n          specification).\n\n   title: a character string or length-one expression giving a title to\n          be placed at the top of the legend.  Other objects will be\n          coerced by 'as.graphicsAnnot'.\n\n   inset: inset distance(s) from the margins as a fraction of the plot\n          region when legend is placed by keyword.\n\n     xpd: if supplied, a value of the graphical parameter 'xpd' to be\n          used while the legend is being drawn.\n\ntitle.col: color for 'title', defaults to 'text.col[1]'.\n\ntitle.adj: horizontal adjustment for 'title': see the help for\n          'par(\"adj\")'.\n\ntitle.cex: expansion factor(s) for the title, defaults to 'cex[1]'.\n\ntitle.font: the font used for the legend title, defaults to\n          'text.font[1]', see 'text'.\n\n seg.len: the length of lines drawn to illustrate 'lty' and/or 'lwd'\n          (in units of character widths).\n\nDetails:\n\n     Arguments 'x', 'y', 'legend' are interpreted in a non-standard way\n     to allow the coordinates to be specified _via_ one or two\n     arguments.  If 'legend' is missing and 'y' is not numeric, it is\n     assumed that the second argument is intended to be 'legend' and\n     that the first argument specifies the coordinates.\n\n     The coordinates can be specified in any way which is accepted by\n     'xy.coords'.  If this gives the coordinates of one point, it is\n     used as the top-left coordinate of the rectangle containing the\n     legend.  If it gives the coordinates of two points, these specify\n     opposite corners of the rectangle (either pair of corners, in any\n     order).\n\n     The location may also be specified by setting 'x' to a single\n     keyword from the list '\"bottomright\"', '\"bottom\"', '\"bottomleft\"',\n     '\"left\"', '\"topleft\"', '\"top\"', '\"topright\"', '\"right\"' and\n     '\"center\"'. This places the legend on the inside of the plot frame\n     at the given location. Partial argument matching is used.  The\n     optional 'inset' argument specifies how far the legend is inset\n     from the plot margins.  If a single value is given, it is used for\n     both margins; if two values are given, the first is used for 'x'-\n     distance, the second for 'y'-distance.\n\n     Attribute arguments such as 'col', 'pch', 'lty', etc, are recycled\n     if necessary: 'merge' is not.  Set entries of 'lty' to '0' or set\n     entries of 'lwd' to 'NA' to suppress lines in corresponding legend\n     entries; set 'pch' values to 'NA' to suppress points.\n\n     Points are drawn _after_ lines in order that they can cover the\n     line with their background color 'pt.bg', if applicable.\n\n     See the examples for how to right-justify labels.\n\n     Since they are not used for Unicode code points, values '-31:-1'\n     are silently omitted, as are 'NA' and '\"\"' values.\n\nValue:\n\n     A list with list components\n\n    rect: a list with components\n\n          'w', 'h' positive numbers giving *w*idth and *h*eight of the\n              legend's box.\n\n          'left', 'top' x and y coordinates of upper left corner of the\n              box.\n\n    text: a list with components\n\n          'x, y' numeric vectors of length 'length(legend)', giving the\n              x and y coordinates of the legend's text(s).\n\n     returned invisibly.\n\nReferences:\n\n     Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S\n     Language_.  Wadsworth & Brooks/Cole.\n\n     Murrell, P. (2005) _R Graphics_. Chapman & Hall/CRC Press.\n\nSee Also:\n\n     'plot', 'barplot' which uses 'legend()', and 'text' for more\n     examples of math expressions.\n\nExamples:\n\n     ## Run the example in '?matplot' or the following:\n     leg.txt &lt;- c(\"Setosa     Petals\", \"Setosa     Sepals\",\n                  \"Versicolor Petals\", \"Versicolor Sepals\")\n     y.leg &lt;- c(4.5, 3, 2.1, 1.4, .7)\n     cexv  &lt;- c(1.2, 1, 4/5, 2/3, 1/2)\n     matplot(c(1, 8), c(0, 4.5), type = \"n\", xlab = \"Length\", ylab = \"Width\",\n             main = \"Petal and Sepal Dimensions in Iris Blossoms\")\n     for (i in seq(cexv)) {\n       text  (1, y.leg[i] - 0.1, paste(\"cex=\", formatC(cexv[i])), cex = 0.8, adj = 0)\n       legend(3, y.leg[i], leg.txt, pch = \"sSvV\", col = c(1, 3), cex = cexv[i])\n     }\n     ## cex *vector* [in R &lt;= 3.5.1 has 'if(xc &lt; 0)' w/ length(xc) == 2]\n     legend(\"right\", leg.txt, pch = \"sSvV\", col = c(1, 3),\n            cex = 1+(-1:2)/8, trace = TRUE)# trace: show computed lengths & coords\n     \n     ## 'merge = TRUE' for merging lines & points:\n     x &lt;- seq(-pi, pi, length.out = 65)\n     for(reverse in c(FALSE, TRUE)) {  ## normal *and* reverse axes:\n       F &lt;- if(reverse) rev else identity\n       plot(x, sin(x), type = \"l\", col = 3, lty = 2,\n            xlim = F(range(x)), ylim = F(c(-1.2, 1.8)))\n       points(x, cos(x), pch = 3, col = 4)\n       lines(x, tan(x), type = \"b\", lty = 1, pch = 4, col = 6)\n       title(\"legend('top', lty = c(2, -1, 1), pch = c(NA, 3, 4), merge = TRUE)\",\n             cex.main = 1.1)\n       legend(\"top\", c(\"sin\", \"cos\", \"tan\"), col = c(3, 4, 6),\n            text.col = \"green4\", lty = c(2, -1, 1), pch = c(NA, 3, 4),\n            merge = TRUE, bg = \"gray90\", trace=TRUE)\n       \n     } # for(..)\n     \n     ## right-justifying a set of labels: thanks to Uwe Ligges\n     x &lt;- 1:5; y1 &lt;- 1/x; y2 &lt;- 2/x\n     plot(rep(x, 2), c(y1, y2), type = \"n\", xlab = \"x\", ylab = \"y\")\n     lines(x, y1); lines(x, y2, lty = 2)\n     temp &lt;- legend(\"topright\", legend = c(\" \", \" \"),\n                    text.width = strwidth(\"1,000,000\"),\n                    lty = 1:2, xjust = 1, yjust = 1, inset = 1/10,\n                    title = \"Line Types\", title.cex = 0.5, trace=TRUE)\n     text(temp$rect$left + temp$rect$w, temp$text$y,\n          c(\"1,000\", \"1,000,000\"), pos = 2)\n     \n     \n     ##--- log scaled Examples ------------------------------\n     leg.txt &lt;- c(\"a one\", \"a two\")\n     \n     par(mfrow = c(2, 2))\n     for(ll in c(\"\",\"x\",\"y\",\"xy\")) {\n       plot(2:10, log = ll, main = paste0(\"log = '\", ll, \"'\"))\n       abline(1, 1)\n       lines(2:3, 3:4, col = 2)\n       points(2, 2, col = 3)\n       rect(2, 3, 3, 2, col = 4)\n       text(c(3,3), 2:3, c(\"rect(2,3,3,2, col=4)\",\n                           \"text(c(3,3),2:3,\\\"c(rect(...)\\\")\"), adj = c(0, 0.3))\n       legend(list(x = 2,y = 8), legend = leg.txt, col = 2:3, pch = 1:2,\n              lty = 1)  #, trace = TRUE)\n     } #      ^^^^^^^ to force lines -&gt; automatic merge=TRUE\n     par(mfrow = c(1,1))\n     \n     ##-- Math expressions:  ------------------------------\n     x &lt;- seq(-pi, pi, length.out = 65)\n     plot(x, sin(x), type = \"l\", col = 2, xlab = expression(phi),\n          ylab = expression(f(phi)))\n     abline(h = -1:1, v = pi/2*(-6:6), col = \"gray90\")\n     lines(x, cos(x), col = 3, lty = 2)\n     ex.cs1 &lt;- expression(plain(sin) * phi,  paste(\"cos\", phi))  # 2 ways\n     utils::str(legend(-3, .9, ex.cs1, lty = 1:2, plot = FALSE,\n                adj = c(0, 0.6)))  # adj y !\n     legend(-3, 0.9, ex.cs1, lty = 1:2, col = 2:3,  adj = c(0, 0.6))\n     \n     require(stats)\n     x &lt;- rexp(100, rate = .5)\n     hist(x, main = \"Mean and Median of a Skewed Distribution\")\n     abline(v = mean(x),   col = 2, lty = 2, lwd = 2)\n     abline(v = median(x), col = 3, lty = 3, lwd = 2)\n     ex12 &lt;- expression(bar(x) == sum(over(x[i], n), i == 1, n),\n                        hat(x) == median(x[i], i == 1, n))\n     utils::str(legend(4.1, 30, ex12, col = 2:3, lty = 2:3, lwd = 2))\n     \n     ## 'Filled' boxes -- see also example(barplot) which may call legend(*, fill=)\n     barplot(VADeaths)\n     legend(\"topright\", rownames(VADeaths), fill = gray.colors(nrow(VADeaths)))\n     \n     ## Using 'ncol'\n     x &lt;- 0:64/64\n     for(R in c(identity, rev)) { # normal *and* reverse x-axis works fine:\n       xl &lt;- R(range(x)); x1 &lt;- xl[1]\n     matplot(x, outer(x, 1:7, function(x, k) sin(k * pi * x)), xlim=xl,\n             type = \"o\", col = 1:7, ylim = c(-1, 1.5), pch = \"*\")\n     op &lt;- par(bg = \"antiquewhite1\")\n     legend(x1, 1.5, paste(\"sin(\", 1:7, \"pi * x)\"), col = 1:7, lty = 1:7,\n            pch = \"*\", ncol = 4, cex = 0.8)\n     legend(\"bottomright\", paste(\"sin(\", 1:7, \"pi * x)\"), col = 1:7, lty = 1:7,\n            pch = \"*\", cex = 0.8)\n     legend(x1, -.1, paste(\"sin(\", 1:4, \"pi * x)\"), col = 1:4, lty = 1:4,\n            ncol = 2, cex = 0.8)\n     legend(x1, -.4, paste(\"sin(\", 5:7, \"pi * x)\"), col = 4:6,  pch = 24,\n            ncol = 2, cex = 1.5, lwd = 2, pt.bg = \"pink\", pt.cex = 1:3)\n     par(op)\n       \n     } # for(..)\n     \n     ## point covering line :\n     y &lt;- sin(3*pi*x)\n     plot(x, y, type = \"l\", col = \"blue\",\n         main = \"points with bg & legend(*, pt.bg)\")\n     points(x, y, pch = 21, bg = \"white\")\n     legend(.4,1, \"sin(c x)\", pch = 21, pt.bg = \"white\", lty = 1, col = \"blue\")\n     \n     ## legends with titles at different locations\n     plot(x, y, type = \"n\")\n     legend(\"bottomright\", \"(x,y)\", pch=1, title= \"bottomright\")\n     legend(\"bottom\",      \"(x,y)\", pch=1, title= \"bottom\")\n     legend(\"bottomleft\",  \"(x,y)\", pch=1, title= \"bottomleft\")\n     legend(\"left\",        \"(x,y)\", pch=1, title= \"left\")\n     legend(\"topleft\",     \"(x,y)\", pch=1, title= \"topleft, inset = .05\", inset = .05)\n     legend(\"top\",         \"(x,y)\", pch=1, title= \"top\")\n     legend(\"topright\",    \"(x,y)\", pch=1, title= \"topright, inset = .02\",inset = .02)\n     legend(\"right\",       \"(x,y)\", pch=1, title= \"right\")\n     legend(\"center\",      \"(x,y)\", pch=1, title= \"center\")\n     \n     # using text.font (and text.col):\n     op &lt;- par(mfrow = c(2, 2), mar = rep(2.1, 4))\n     c6 &lt;- terrain.colors(10)[1:6]\n     for(i in 1:4) {\n        plot(1, type = \"n\", axes = FALSE, ann = FALSE); title(paste(\"text.font =\",i))\n        legend(\"top\", legend = LETTERS[1:6], col = c6,\n               ncol = 2, cex = 2, lwd = 3, text.font = i, text.col = c6)\n     }\n     par(op)\n     \n     # using text.width for several columns\n     plot(1, type=\"n\")\n     legend(\"topleft\", c(\"This legend\", \"has\", \"equally sized\", \"columns.\"),\n            pch = 1:4, ncol = 4)\n     legend(\"bottomleft\", c(\"This legend\", \"has\", \"optimally sized\", \"columns.\"),\n            pch = 1:4, ncol = 4, text.width = NA)\n     legend(\"right\", letters[1:4], pch = 1:4, ncol = 4,\n            text.width = 1:4 / 50)",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#add-legend-to-the-plot",
    "href": "modules/Module10-DataVisualization.html#add-legend-to-the-plot",
    "title": "Module 10: Data Visualization",
    "section": "Add legend to the plot",
    "text": "Add legend to the plot\nReminder function signature\nlegend(x, y = NULL, legend, fill = NULL, col = par(\"col\"),\n       border = \"black\", lty, lwd, pch,\n       angle = 45, density = NULL, bty = \"o\", bg = par(\"bg\"),\n       box.lwd = par(\"lwd\"), box.lty = par(\"lty\"), box.col = par(\"fg\"),\n       pt.bg = NA, cex = 1, pt.cex = cex, pt.lwd = lwd,\n       xjust = 0, yjust = 1, x.intersp = 1, y.intersp = 1,\n       adj = c(0, 0.5), text.width = NULL, text.col = par(\"col\"),\n       text.font = NULL, merge = do.lines && has.pch, trace = FALSE,\n       plot = TRUE, ncol = 1, horiz = FALSE, title = NULL,\n       inset = 0, xpd, title.col = text.col[1], title.adj = 0.5,\n       title.cex = cex[1], title.font = text.font[1],\n       seg.len = 2)\nLet’s practice\n\nbarplot(prop.cell.percentages, col=c(\"darkblue\",\"red\"), ylim=c(0,0.5), main=\"Seropositivity by Age Group\")\nlegend(x=2.5, y=0.5,\n             fill=c(\"darkblue\",\"red\"), \n             legend = c(\"seronegative\", \"seropositive\"))",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#add-legend-to-the-plot-1",
    "href": "modules/Module10-DataVisualization.html#add-legend-to-the-plot-1",
    "title": "Module 10: Data Visualization",
    "section": "Add legend to the plot",
    "text": "Add legend to the plot",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#barplot-example-1",
    "href": "modules/Module10-DataVisualization.html#barplot-example-1",
    "title": "Module 10: Data Visualization",
    "section": "barplot() example",
    "text": "barplot() example\nGetting closer, but what I really want is column proportions (i.e., the proportions should sum to one for each age group). Also, the age groups need more meaningful names.\n\nfreq &lt;- table(df$seropos, df$age_group)\nprop.column.percentages &lt;- prop.table(freq, margin=2)\ncolnames(prop.column.percentages) &lt;- c(\"1-5 yo\", \"6-10 yo\", \"11-15 yo\")\n\nbarplot(prop.column.percentages, col=c(\"darkblue\",\"red\"), ylim=c(0,1.35), main=\"Seropositivity by Age Group\")\naxis(2, at = c(0.2, 0.4, 0.6, 0.8,1))\nlegend(x=2.8, y=1.35,\n             fill=c(\"darkblue\",\"red\"), \n             legend = c(\"seronegative\", \"seropositive\"))",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#barplot-example-2",
    "href": "modules/Module10-DataVisualization.html#barplot-example-2",
    "title": "Module 10: Data Visualization",
    "section": "barplot() example",
    "text": "barplot() example",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#barplot-example-3",
    "href": "modules/Module10-DataVisualization.html#barplot-example-3",
    "title": "Module 10: Data Visualization",
    "section": "barplot() example",
    "text": "barplot() example\nNow, let look at seropositivity by two individual level characteristics in the same plot.\n\npar(mfrow = c(1,2))\nbarplot(prop.column.percentages, col=c(\"darkblue\",\"red\"), ylim=c(0,1.35), main=\"Seropositivity by Age Group\")\naxis(2, at = c(0.2, 0.4, 0.6, 0.8,1))\nlegend(\"topright\",\n             fill=c(\"darkblue\",\"red\"), \n             legend = c(\"seronegative\", \"seropositive\"))\n\nbarplot(prop.column.percentages2, col=c(\"darkblue\",\"red\"), ylim=c(0,1.35), main=\"Seropositivity by Residence\")\naxis(2, at = c(0.2, 0.4, 0.6, 0.8,1))\nlegend(\"topright\", fill=c(\"darkblue\",\"red\"),  legend = c(\"seronegative\", \"seropositive\"))",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#barplot-example-4",
    "href": "modules/Module10-DataVisualization.html#barplot-example-4",
    "title": "Module 10: Data Visualization",
    "section": "barplot() example",
    "text": "barplot() example",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#saving-plots-to-file",
    "href": "modules/Module10-DataVisualization.html#saving-plots-to-file",
    "title": "Module 10: Data Visualization",
    "section": "Saving plots to file",
    "text": "Saving plots to file\nIf you want to include your graphic in a paper or anything else, you need to save it as an image. One limitation of base R graphics is that the process for saving plots is a bit annoying.\n\nOpen a graphics device connection with a graphics function – examples include pdf(), png(), and tiff() for the most useful.\nRun the code that creates your plot.\nUse dev.off() to close the graphics device connection.\n\nLet’s do an example.\n\n# Open the graphics device\npng(\n    \"my-barplot.png\",\n    width = 800,\n    height = 450,\n    units = \"px\"\n)\n# Set the plot layout -- this is an alternative to par(mfrow = ...)\nlayout(matrix(c(1, 2), ncol = 2))\n# Make the plot\nbarplot(prop.column.percentages, col=c(\"darkblue\",\"red\"), ylim=c(0,1.35), main=\"Seropositivity by Age Group\")\naxis(2, at = c(0.2, 0.4, 0.6, 0.8,1))\nlegend(\"topright\",\n             fill=c(\"darkblue\",\"red\"), \n             legend = c(\"seronegative\", \"seropositive\"))\n\nbarplot(prop.column.percentages2, col=c(\"darkblue\",\"red\"), ylim=c(0,1.35), main=\"Seropositivity by Residence\")\naxis(2, at = c(0.2, 0.4, 0.6, 0.8,1))\nlegend(\"topright\", fill=c(\"darkblue\",\"red\"),  legend = c(\"seronegative\", \"seropositive\"))\n# Close the graphics device\ndev.off()\n\npng \n  2 \n\n# Reset the layout\nlayout(1)\n\nNote: after you do an interactive graphics session, it is often helpful to restart R or run the function graphics.off() before opening the graphics connection device.",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#base-r-plots-vs-the-tidyverse-ggplot2-package",
    "href": "modules/Module10-DataVisualization.html#base-r-plots-vs-the-tidyverse-ggplot2-package",
    "title": "Module 10: Data Visualization",
    "section": "Base R plots vs the Tidyverse ggplot2 package",
    "text": "Base R plots vs the Tidyverse ggplot2 package\nIt is good to know both b/c they each have their strengths",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#summary",
    "href": "modules/Module10-DataVisualization.html#summary",
    "title": "Module 10: Data Visualization",
    "section": "Summary",
    "text": "Summary\n\nthe Base R ‘graphics’ package has a ton of graphics options that allow for ultimate flexibility\nBase R plots typically include setting plot options (par()), mapping data to the plot (e.g., plot(), barplot(), points(), lines()), and creating a legend (legend()).\nthe functions points() or lines() add additional points or additional lines to an existing plot, but must be called with a plot()-style function\nin Base R plotting the legend is not automatically generated, so be careful when creating it",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module10-DataVisualization.html#acknowledgements",
    "href": "modules/Module10-DataVisualization.html#acknowledgements",
    "title": "Module 10: Data Visualization",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese are the materials we looked through, modified, or extracted to complete this module’s lecture.\n\n“Base Plotting in R” by Medium\n  [\"Base R margins: a cheatsheet\"](https://r-graph-gallery.com/74-margin-and-oma-cheatsheet.html)",
    "crumbs": [
      "Day 2",
      "Module 10: Data Visualization"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#learning-objectives",
    "href": "modules/Module06-DataSubset.html#learning-objectives",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter module 6, you should be able to…\n\nUse basic functions to get to know you data\nUse three indexing approaches\nRely on indexing to extract part of an object (e.g., subset data) and to replace parts of an object (e.g., rename variables / columns)\nDescribe what logical operators are and how to use them\nUse on the subset() function to subset data",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#getting-to-know-our-data",
    "href": "modules/Module06-DataSubset.html#getting-to-know-our-data",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Getting to know our data",
    "text": "Getting to know our data\nThe dim(), nrow(), and ncol() functions are good options to check the dimensions of your data before moving forward.\nLet’s first read in the data from the previous module.\n\ndf &lt;- read.csv(file = \"data/serodata.csv\") #relative path\n\n\ndim(df) # rows, columns\n\n[1] 651   5\n\nnrow(df) # number of rows\n\n[1] 651\n\nncol(df) # number of columns\n\n[1] 5",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#quick-summary-of-data",
    "href": "modules/Module06-DataSubset.html#quick-summary-of-data",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Quick summary of data",
    "text": "Quick summary of data\nThe colnames(), str() and summary()functions from Base R are great functions to assess the data type and some summary statistics.\n\ncolnames(df)\n\n[1] \"observation_id\"    \"IgG_concentration\" \"age\"              \n[4] \"gender\"            \"slum\"             \n\nstr(df)\n\n'data.frame':   651 obs. of  5 variables:\n $ observation_id   : int  5772 8095 9784 9338 6369 6885 6252 8913 7332 6941 ...\n $ IgG_concentration: num  0.318 3.437 0.3 143.236 0.448 ...\n $ age              : int  2 4 4 4 1 4 4 NA 4 2 ...\n $ gender           : chr  \"Female\" \"Female\" \"Male\" \"Male\" ...\n $ slum             : chr  \"Non slum\" \"Non slum\" \"Non slum\" \"Non slum\" ...\n\nsummary(df)\n\n observation_id IgG_concentration       age            gender         \n Min.   :5006   Min.   :  0.0054   Min.   : 1.000   Length:651        \n 1st Qu.:6306   1st Qu.:  0.3000   1st Qu.: 3.000   Class :character  \n Median :7495   Median :  1.6658   Median : 6.000   Mode  :character  \n Mean   :7492   Mean   : 87.3683   Mean   : 6.606                     \n 3rd Qu.:8749   3rd Qu.:141.4405   3rd Qu.:10.000                     \n Max.   :9982   Max.   :916.4179   Max.   :15.000                     \n                NA's   :10         NA's   :9                          \n     slum          \n Length:651        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\n\nNote, if you have a very large dataset with 15+ variables, summary() is not so efficient.",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#description-of-data",
    "href": "modules/Module06-DataSubset.html#description-of-data",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Description of data",
    "text": "Description of data\nThis is data based on a simulated pathogen X IgG antibody serological survey. The rows represent individuals. Variables include IgG concentrations in IU/mL, age in years, gender, and residence based on slum characterization. We will use this dataset for modules throughout the Workshop.",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#view-the-data-as-a-whole-dataframe",
    "href": "modules/Module06-DataSubset.html#view-the-data-as-a-whole-dataframe",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "View the data as a whole dataframe",
    "text": "View the data as a whole dataframe\nThe View() function, one of the few Base R functions with a capital letter, and can be used to open a new tab in the Console and view the data as you would in excel.\n\nView(df)",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#view-the-data-as-a-whole-dataframe-1",
    "href": "modules/Module06-DataSubset.html#view-the-data-as-a-whole-dataframe-1",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "View the data as a whole dataframe",
    "text": "View the data as a whole dataframe\nYou can also open a new tab of the data by clicking on the data icon beside the object in the Environment pane\n\nYou can also hold down Cmd or CTRL and click on the name of a data frame in your code.",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#indexing",
    "href": "modules/Module06-DataSubset.html#indexing",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Indexing",
    "text": "Indexing\nR contains several operators which allow access to individual elements or subsets through indexing. Indexing can be used both to extract part of an object and to replace parts of an object (or to add parts). There are three basic indexing operators: [, [[ and $.\n\nx[i] #if x is a vector\nx[i, j] #if x is a matrix/data frame\nx[[i]] #if x is a list\nx$a #if x is a data frame or list\nx$\"a\" #if x is a data frame or list",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#vectors-and-multi-dimensional-objects",
    "href": "modules/Module06-DataSubset.html#vectors-and-multi-dimensional-objects",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Vectors and multi-dimensional objects",
    "text": "Vectors and multi-dimensional objects\nTo index a vector, vector[i] select the ith element. To index a multi-dimensional objects such as a matrix, matrix[i, j] selects the element in row i and column j, where as in a three dimensional array[k, i, j] selects the element in matrix k, row i, and column j.\nLet’s practice by first creating the same objects as we did in Module 1.\n\nnumber.object &lt;- 3\ncharacter.object &lt;- \"blue\"\nvector.object1 &lt;- c(2,3,4,5)\nvector.object2 &lt;- c(\"blue\", \"red\", \"yellow\")\nmatrix.object &lt;- matrix(data=vector.object1, nrow=2, ncol=2, byrow=TRUE)\n\nHere is a reminder of what these objects look like.\n\nvector.object1\n\n[1] 2 3 4 5\n\nmatrix.object\n\n     [,1] [,2]\n[1,]    2    3\n[2,]    4    5\n\n\nFinally, let’s use indexing to pull out elements of the objects.\n\nvector.object1[2] #pulling the second element\n\n[1] 3\n\nmatrix.object[1,2] #pulling the element in row 1 column 2\n\n[1] 3",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#list-objects",
    "href": "modules/Module06-DataSubset.html#list-objects",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "List objects",
    "text": "List objects\nFor lists, one generally uses list[[p]] to select any single element p.\nLet’s practice by creating the same list as we did in Module 1.\n\nlist.object &lt;- list(number.object, vector.object2, matrix.object)\nlist.object\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] \"blue\"   \"red\"    \"yellow\"\n\n[[3]]\n     [,1] [,2]\n[1,]    2    3\n[2,]    4    5\n\n\nNow we use indexing to pull out the 3rd element in the list.\n\nlist.object[[3]]\n\n     [,1] [,2]\n[1,]    2    3\n[2,]    4    5\n\n\nWhat happens if we use a single square bracket?\n\nlist.object[3]\n\n[[1]]\n     [,1] [,2]\n[1,]    2    3\n[2,]    4    5\n\n\nThe [[ operator is called the “extract” operator and gives us the element from the list. The [ operator is called the “subset” operator and gives us a subset of the list, that is still a list.",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#for-indexing-for-data-frame",
    "href": "modules/Module06-DataSubset.html#for-indexing-for-data-frame",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "$ for indexing for data frame",
    "text": "$ for indexing for data frame\n$ allows only a literal character string or a symbol as the index. For a data frame it extracts a variable.\n\ndf$IgG_concentration\n\nNote, if you have spaces in your variable name, you will need to use back ticks ` after the $. This is a good reason to not create variables / column names with spaces.",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#for-indexing-with-lists",
    "href": "modules/Module06-DataSubset.html#for-indexing-with-lists",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "$ for indexing with lists",
    "text": "$ for indexing with lists\n$ allows only a literal character string or a symbol as the index. For a list it extracts a named element.\nList elements can be named\n\nlist.object.named &lt;- list(\n  emory = number.object,\n  uga = vector.object2,\n  gsu = matrix.object\n)\nlist.object.named\n\n$emory\n[1] 3\n\n$uga\n[1] \"blue\"   \"red\"    \"yellow\"\n\n$gsu\n     [,1] [,2]\n[1,]    2    3\n[2,]    4    5\n\n\nIf list elements are named, than you can reference data from list using $ or using double square brackets, [[\n\nlist.object.named$uga \n\n[1] \"blue\"   \"red\"    \"yellow\"\n\nlist.object.named[[\"uga\"]] \n\n[1] \"blue\"   \"red\"    \"yellow\"",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#using-indexing-to-rename-columns",
    "href": "modules/Module06-DataSubset.html#using-indexing-to-rename-columns",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Using indexing to rename columns",
    "text": "Using indexing to rename columns\nAs mentioned above, indexing can be used both to extract part of an object and to replace parts of an object (or to add parts).\n\ncolnames(df) \n\n[1] \"observation_id\"    \"IgG_concentration\" \"age\"              \n[4] \"gender\"            \"slum\"             \n\ncolnames(df)[2:3] &lt;- c(\"IgG_concentration_IU/mL\", \"age_year\") # reassigns\ncolnames(df)\n\n[1] \"observation_id\"          \"IgG_concentration_IU/mL\"\n[3] \"age_year\"                \"gender\"                 \n[5] \"slum\"                   \n\n\n\nFor the sake of the module, I am going to reassign them back to the original variable names\n\ncolnames(df)[2:3] &lt;- c(\"IgG_concentration\", \"age\") #reset",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#using-indexing-to-subset-by-columns",
    "href": "modules/Module06-DataSubset.html#using-indexing-to-subset-by-columns",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Using indexing to subset by columns",
    "text": "Using indexing to subset by columns\nWe can also subset data frames and matrices (2-dimensional objects) using the bracket [ row , column ]. We can subset by columns and pull the x column using the index of the column or the column name. Leaving either row or column dimension blank means to select all of them.\nFor example, here I am pulling the 3rd column, which has the variable name age, for all of rows.\n\ndf[ , \"age\"] #same as df[ , 3]\n\nWe can select multiple columns using multiple column names, again this is selecting these variables for all of the rows.\n\ndf[, c(\"age\", \"gender\")] #same as df[ , c(3,4)]\n\n    age gender\n1     2 Female\n2     4 Female\n3     4   Male\n4     4   Male\n5     1   Male\n6     4   Male\n7     4 Female\n8    NA Female\n9     4   Male\n10    2   Male\n11    3   Male\n12   15 Female\n13    8   Male\n14   12   Male\n15   15   Male\n16    9   Male\n17    8   Male\n18    7 Female\n19   11 Female\n20   10   Male\n21    8   Male\n22   11 Female\n23    2   Male\n24    2 Female\n25    3 Female\n26    5   Male\n27    1   Male\n28    3 Female\n29    5 Female\n30    5 Female\n31    3   Male\n32    1   Male\n33    4 Female\n34    3   Male\n35    2 Female\n36   11 Female\n37    7   Male\n38    8   Male\n39    6   Male\n40    6   Male\n41   11 Female\n42   10   Male\n43    6 Female\n44   12   Male\n45   11   Male\n46   10   Male\n47   11   Male\n48   13 Female\n49    3 Female\n50    4 Female\n51    3   Male\n52    1   Male\n53    2 Female\n54    2 Female\n55    4   Male\n56    2   Male\n57    2   Male\n58    3 Female\n59    3 Female\n60    4   Male\n61    1 Female\n62   13 Female\n63   13 Female\n64    6   Male\n65   13   Male\n66    5 Female\n67   13 Female\n68   14   Male\n69   13   Male\n70    8 Female\n71    7   Male\n72    6 Female\n73   13   Male\n74    3   Male\n75    4   Male\n76    2   Male\n77   NA   Male\n78    5 Female\n79    3   Male\n80    3   Male\n81   14   Male\n82   11 Female\n83    7 Female\n84    7   Male\n85   11 Female\n86    9 Female\n87   14   Male\n88   13 Female\n89    1   Male\n90    1   Male\n91    4   Male\n92    1 Female\n93    2   Male\n94    3 Female\n95    2   Male\n96    1   Male\n97    2   Male\n98    2 Female\n99    4 Female\n100   5 Female\n101   5   Male\n102   6 Female\n103  14 Female\n104  14   Male\n105  10   Male\n106   6 Female\n107   6   Male\n108   8   Male\n109   6 Female\n110  12 Female\n111  12   Male\n112  14 Female\n113  15   Male\n114  12 Female\n115   4 Female\n116   4   Male\n117   3 Female\n118  NA   Male\n119   2 Female\n120   3   Male\n121  NA Female\n122   3 Female\n123   3   Male\n124   2 Female\n125   4 Female\n126  10 Female\n127   7 Female\n128  11 Female\n129   6 Female\n130  11   Male\n131   9   Male\n132   6   Male\n133  13 Female\n134  10 Female\n135   6 Female\n136  11 Female\n137   7   Male\n138   6 Female\n139   4 Female\n140   4 Female\n141   4   Male\n142   4 Female\n143   4   Male\n144   4   Male\n145   3   Male\n146   4 Female\n147   3   Male\n148   3   Male\n149  13 Female\n150   7 Female\n151  10   Male\n152   6   Male\n153  10 Female\n154  12 Female\n155  10   Male\n156  10   Male\n157  13   Male\n158  13 Female\n159   5 Female\n160   3 Female\n161   4   Male\n162   1   Male\n163   3 Female\n164   4   Male\n165   4   Male\n166   1   Male\n167   5 Female\n168   6 Female\n169  14 Female\n170   6   Male\n171  13 Female\n172   9   Male\n173  11   Male\n174  10   Male\n175   5 Female\n176  14   Male\n177   7   Male\n178  10   Male\n179   6   Male\n180   5   Male\n181   3 Female\n182   4   Male\n183   2 Female\n184   3   Male\n185   3 Female\n186   2 Female\n187   3   Male\n188   5 Female\n189   2   Male\n190   3 Female\n191  14 Female\n192   9 Female\n193  14 Female\n194   9 Female\n195   8 Female\n196   7   Male\n197  13   Male\n198   8 Female\n199   6   Male\n200  12 Female\n201  14 Female\n202  15 Female\n203   2 Female\n204   4 Female\n205   3   Male\n206   3 Female\n207   3   Male\n208   4 Female\n209   3   Male\n210  14 Female\n211   8   Male\n212   7   Male\n213  14 Female\n214  13 Female\n215  13 Female\n216   7   Male\n217   8 Female\n218  10 Female\n219   9   Male\n220   9 Female\n221   3 Female\n222   4   Male\n223   4 Female\n224   4   Male\n225   2 Female\n226   1 Female\n227   3 Female\n228   2   Male\n229   3   Male\n230   5   Male\n231   2 Female\n232   2   Male\n233   9   Male\n234  13   Male\n235  10 Female\n236   6   Male\n237  13 Female\n238  11   Male\n239  10   Male\n240   8 Female\n241   9 Female\n242  10   Male\n243  14   Male\n244   1 Female\n245   2   Male\n246   3 Female\n247   2   Male\n248   3 Female\n249   2 Female\n250   3 Female\n251   5 Female\n252  10 Female\n253   7   Male\n254  13 Female\n255  15   Male\n256  11 Female\n257  10 Female\n258   3 Female\n259   2   Male\n260   3   Male\n261   3 Female\n262   3 Female\n263   4   Male\n264   3   Male\n265   2   Male\n266   4   Male\n267   2 Female\n268   8   Male\n269  11   Male\n270   6   Male\n271  14 Female\n272  14   Male\n273   5 Female\n274   5   Male\n275  10 Female\n276  13   Male\n277   6   Male\n278   5   Male\n279  12   Male\n280   2   Male\n281   3 Female\n282   1 Female\n283   1   Male\n284   1 Female\n285   2 Female\n286   5 Female\n287   5   Male\n288   4 Female\n289   2   Male\n290  NA Female\n291   6 Female\n292   8   Male\n293  15   Male\n294  11   Male\n295  14   Male\n296   6   Male\n297  10 Female\n298  12   Male\n299  14   Male\n300  10   Male\n301   1 Female\n302   3   Male\n303   2   Male\n304   3 Female\n305   4   Male\n306   3   Male\n307   4 Female\n308   4   Male\n309   1 Female\n310   7   Male\n311  11 Female\n312   7 Female\n313   5 Female\n314  10   Male\n315   9 Female\n316  13   Male\n317  11 Female\n318  13   Male\n319   9 Female\n320  15 Female\n321   7 Female\n322   4   Male\n323   1   Male\n324   1   Male\n325   2 Female\n326   2 Female\n327   3   Male\n328   2   Male\n329   3   Male\n330   4 Female\n331   7 Female\n332  11 Female\n333  10 Female\n334   5   Male\n335   8   Male\n336  15   Male\n337  14   Male\n338   2   Male\n339   2 Female\n340   2   Male\n341   5   Male\n342   4 Female\n343   3   Male\n344   5 Female\n345   4 Female\n346   2 Female\n347   1 Female\n348   7   Male\n349   8 Female\n350  NA   Male\n351   9   Male\n352   8 Female\n353   5   Male\n354  14   Male\n355  14   Male\n356   7 Female\n357  13 Female\n358   2   Male\n359   1 Female\n360   1   Male\n361   4 Female\n362   3   Male\n363   4 Female\n364   3   Male\n365   1   Male\n366   5 Female\n367   4 Female\n368   4 Female\n369   4   Male\n370  11   Male\n371  15 Female\n372  12 Female\n373  11 Female\n374   8 Female\n375  13   Male\n376  10 Female\n377  10 Female\n378  15   Male\n379   8 Female\n380  14   Male\n381   4   Male\n382   1   Male\n383   5 Female\n384   2   Male\n385   2 Female\n386   4   Male\n387   4   Male\n388   2 Female\n389   3   Male\n390  11   Male\n391  10 Female\n392   6   Male\n393  12 Female\n394  10 Female\n395   8   Male\n396   8   Male\n397  13   Male\n398  10   Male\n399  13 Female\n400  10   Male\n401   2   Male\n402   4 Female\n403   3 Female\n404   2 Female\n405   1 Female\n406   3   Male\n407   3 Female\n408   4   Male\n409   5 Female\n410   5 Female\n411   1 Female\n412  11   Male\n413   6   Male\n414  14 Female\n415   8   Male\n416   8 Female\n417   9 Female\n418   7   Male\n419   6   Male\n420  12 Female\n421   8   Male\n422  11 Female\n423  14   Male\n424   3 Female\n425   1 Female\n426   5 Female\n427   2 Female\n428   3 Female\n429   4 Female\n430   2   Male\n431   3 Female\n432   4   Male\n433   1 Female\n434   7 Female\n435  10   Male\n436  11   Male\n437   7 Female\n438  10 Female\n439  14 Female\n440   7 Female\n441  11   Male\n442  12   Male\n443  10 Female\n444   6   Male\n445  13   Male\n446   8 Female\n447   2   Male\n448   3 Female\n449   1 Female\n450   2 Female\n451  NA   Male\n452  NA Female\n453   4   Male\n454   4   Male\n455   1   Male\n456   2 Female\n457   2   Male\n458  12   Male\n459  12 Female\n460   8 Female\n461  14 Female\n462  13 Female\n463   6   Male\n464  11 Female\n465  11   Male\n466  10 Female\n467  12   Male\n468  14 Female\n469  11 Female\n470   1   Male\n471   2 Female\n472   3   Male\n473   3 Female\n474   5 Female\n475   3   Male\n476   1   Male\n477   4 Female\n478   4 Female\n479   4   Male\n480   2 Female\n481   5 Female\n482   7   Male\n483   8   Male\n484  10   Male\n485   6 Female\n486   7   Male\n487  10 Female\n488   6   Male\n489   6 Female\n490  15 Female\n491   5   Male\n492   3   Male\n493   5   Male\n494   3 Female\n495   5   Male\n496   5   Male\n497   1 Female\n498   1   Male\n499   7 Female\n500  14 Female\n501   9   Male\n502  10 Female\n503  10 Female\n504  11   Male\n505  11 Female\n506  12 Female\n507  11 Female\n508  12   Male\n509  12   Male\n510  10 Female\n511   1   Male\n512   2 Female\n513   4   Male\n514   2   Male\n515   3   Male\n516   3 Female\n517   2   Male\n518   4   Male\n519   3   Male\n520   1 Female\n521   4   Male\n522  12 Female\n523   6   Male\n524   7 Female\n525   7   Male\n526  13 Female\n527   8 Female\n528   7   Male\n529   8 Female\n530   8 Female\n531  11 Female\n532  14 Female\n533   3   Male\n534   2 Female\n535   2   Male\n536   3   Male\n537   2   Male\n538   2 Female\n539   3 Female\n540   2   Male\n541   5   Male\n542  10 Female\n543  14   Male\n544   9   Male\n545   6   Male\n546   7   Male\n547  14 Female\n548   7 Female\n549   7   Male\n550   9   Male\n551  14   Male\n552  10 Female\n553  13 Female\n554   5   Male\n555   4 Female\n556   4 Female\n557   5 Female\n558   4 Female\n559   4   Male\n560   4   Male\n561   3 Female\n562   1 Female\n563   4   Male\n564   1   Male\n565   1 Female\n566   7   Male\n567  13 Female\n568  10 Female\n569  14   Male\n570  12 Female\n571  14   Male\n572   8   Male\n573   7   Male\n574  11 Female\n575   8   Male\n576  12   Male\n577   9 Female\n578   5 Female\n579   4   Male\n580   3 Female\n581   2   Male\n582   2   Male\n583   3   Male\n584   4 Female\n585   4   Male\n586   4 Female\n587   5   Male\n588   3 Female\n589   6 Female\n590   3   Male\n591  11 Female\n592  11   Male\n593   7   Male\n594   8   Male\n595   6 Female\n596  10 Female\n597   8 Female\n598   8   Male\n599   9 Female\n600   8   Male\n601  13   Male\n602  11   Male\n603   8 Female\n604   2 Female\n605   4   Male\n606   2   Male\n607   2 Female\n608   4   Male\n609   2   Male\n610   4 Female\n611   2 Female\n612   4 Female\n613   1 Female\n614   4 Female\n615  12 Female\n616   7 Female\n617  11   Male\n618   6   Male\n619   8   Male\n620  14   Male\n621  11   Male\n622   7 Female\n623  14 Female\n624   6   Male\n625  13 Female\n626  13 Female\n627   3   Male\n628   1   Male\n629   3   Male\n630   1 Female\n631   1 Female\n632   2   Male\n633   4   Male\n634   4   Male\n635   2 Female\n636   4 Female\n637   5   Male\n638   3 Female\n639   3   Male\n640   6 Female\n641  11 Female\n642   9 Female\n643   7 Female\n644   8   Male\n645  NA Female\n646   8 Female\n647  14 Female\n648  10   Male\n649  10   Male\n650  11 Female\n651  13 Female\n\n\nWe can remove select columns using indexing as well, OR by simply changing the column to NULL\n\ndf[, -5] #remove column 5, \"slum\" variable\n\n\ndf$slum &lt;- NULL # this is the same as above\n\nWe can also grab the age column using the $ operator, again this is selecting the variable for all of the rows.\n\ndf$age",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#using-indexing-to-subset-by-rows",
    "href": "modules/Module06-DataSubset.html#using-indexing-to-subset-by-rows",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Using indexing to subset by rows",
    "text": "Using indexing to subset by rows\nWe can use indexing to also subset by rows. For example, here we pull the 100th observation/row.\n\ndf[100,] \n\n    observation_id IgG_concentration age gender     slum\n100           8122         0.1818182   5 Female Non slum\n\n\nAnd, here we pull the age of the 100th observation/row.\n\ndf[100,\"age\"] \n\n[1] 5",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#logical-operators",
    "href": "modules/Module06-DataSubset.html#logical-operators",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Logical operators",
    "text": "Logical operators\nLogical operators can be evaluated on object(s) in order to return a binary response of TRUE/FALSE\n\n\n\noperator\noperator option\ndescription\n\n\n\n\n&lt;\n%l%\nless than\n\n\n&lt;=\n%le%\nless than or equal to\n\n\n&gt;\n%g%\ngreater than\n\n\n&gt;=\n%ge%\ngreater than or equal to\n\n\n==\n\nequal to\n\n\n!=\n\nnot equal to\n\n\nx&y\n\nx and y\n\n\nx|y\n\nx or y\n\n\n%in%\n\nmatch\n\n\n%!in%\n\ndo not match",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#logical-operators-examples",
    "href": "modules/Module06-DataSubset.html#logical-operators-examples",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Logical operators examples",
    "text": "Logical operators examples\nLet’s practice. First, here is a reminder of what the number.object contains.\n\nnumber.object\n\n[1] 3\n\n\nNow, we will use logical operators to evaluate the object.\n\nnumber.object&lt;4\n\n[1] TRUE\n\nnumber.object&gt;=3\n\n[1] TRUE\n\nnumber.object!=5\n\n[1] TRUE\n\nnumber.object %in% c(6,7,2)\n\n[1] FALSE\n\n\nWe can use any of these logical operators to subset our data.\n\n# Overall mean\nmean(df$IgG_concentration, na.rm=TRUE)\n\n[1] 87.36826\n\n# Mean for all children who are not age 3\nmean(df$IgG_concentration[df$age != 3], na.rm=TRUE)\n\n[1] 90.32824\n\n# Mean for all children who are between 0 and 3 or between 7 and 10 years old\nmean(df$IgG_concentration[df$age %in% c(0:3, 7:10)], na.rm=TRUE)\n\n[1] 74.0914",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#using-indexing-and-logical-operators-to-rename-columns",
    "href": "modules/Module06-DataSubset.html#using-indexing-and-logical-operators-to-rename-columns",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Using indexing and logical operators to rename columns",
    "text": "Using indexing and logical operators to rename columns\n\nWe can assign the column names from data frame df to an object cn, then we can modify cn directly using indexing and logical operators, finally we reassign the column names, cn, back to the data frame df:\n\n\ncn &lt;- colnames(df)\ncn\n\n[1] \"observation_id\"    \"IgG_concentration\" \"age\"              \n[4] \"gender\"            \"slum\"             \n\ncn==\"IgG_concentration\"\n\n[1] FALSE  TRUE FALSE FALSE FALSE\n\ncn[cn==\"IgG_concentration\"] &lt;-\"IgG_concentration_IU/mL\" #rename cn to \"IgG_concentration_IU\" when cn is \"IgG_concentration\"\ncolnames(df) &lt;- cn\ncolnames(df)\n\n[1] \"observation_id\"          \"IgG_concentration_IU/mL\"\n[3] \"age\"                     \"gender\"                 \n[5] \"slum\"                   \n\n\n\nNote, I am resetting the column name back to the original name for the sake of the rest of the module.\n\ncolnames(df)[colnames(df)==\"IgG_concentration_IU/mL\"] &lt;- \"IgG_concentration\" #reset",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#using-indexing-and-logical-operators-to-subset-data",
    "href": "modules/Module06-DataSubset.html#using-indexing-and-logical-operators-to-subset-data",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Using indexing and logical operators to subset data",
    "text": "Using indexing and logical operators to subset data\nIn this example, we subset by rows and pull only observations with an age of less than or equal to 10 and then saved the subset data to df_lt10. Note that the logical operators df$age&lt;=10 is before the comma because I want to subset by rows (the first dimension).\n\ndf_lte10 &lt;- df[df$age&lt;=10, ]\n\nLets check that my subsets worked using the summary() function.\n\nsummary(df_lte10$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n    1.0     3.0     4.0     4.8     7.0    10.0       9 \n\n\n\nIn the next example, we subset by rows and pull only observations with an age of less than or equal to 5 OR greater than 10.\n\ndf_lte5_gt10 &lt;- df[df$age&lt;=5 | df$age&gt;10, ]\n\nLets check that my subsets worked using the summary() function.\n\nsummary(df_lte5_gt10$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   1.00    2.50    4.00    6.08   11.00   15.00       9",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#missing-values",
    "href": "modules/Module06-DataSubset.html#missing-values",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Missing values",
    "text": "Missing values\nMissing data need to be carefully described and dealt with in data analysis. Understanding the different types of missing data and how you can identify them, is the first step to data cleaning.\nTypes of “missing” values:\n\nNA - Not Applicable general missing data\nNaN - stands for “Not a Number”, happens when you do 0/0.\nInf and -Inf - Infinity, happens when you divide a positive number (or negative number) by 0.\nblank space - sometimes when data is read it, there is a blank space left\nan empty string (e.g., \"\")\nNULL- undefined value that represents something that does not exist",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#logical-operators-to-help-identify-and-missing-data",
    "href": "modules/Module06-DataSubset.html#logical-operators-to-help-identify-and-missing-data",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Logical operators to help identify and missing data",
    "text": "Logical operators to help identify and missing data\n\n\n\noperator\ndescription\n\n\n\n\n\nis.na\nis NAN or NA\n\n\n\nis.nan\nis NAN\n\n\n\n!is.na\nis not NAN or NA\n\n\n\n!is.nan\nis not NAN\n\n\n\nis.infinite\nis infinite\n\n\n\nany\nare any TRUE\n\n\n\nall\nall are TRUE\n\n\n\nwhich\nwhich are TRUE",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#more-logical-operators-examples",
    "href": "modules/Module06-DataSubset.html#more-logical-operators-examples",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "More logical operators examples",
    "text": "More logical operators examples\n\ntest &lt;- c(0,NA, -1)/0\ntest\n\n[1]  NaN   NA -Inf\n\nis.na(test)\n\n[1]  TRUE  TRUE FALSE\n\nis.nan(test)\n\n[1]  TRUE FALSE FALSE\n\nis.infinite(test)\n\n[1] FALSE FALSE  TRUE",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#more-logical-operators-examples-1",
    "href": "modules/Module06-DataSubset.html#more-logical-operators-examples-1",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "More logical operators examples",
    "text": "More logical operators examples\nany(is.na(x)) means do we have any NA’s in the object x?\n\nany(is.na(df$IgG_concentration)) # are there any NAs - YES/TRUE\n\n[1] TRUE\n\nany(is.na(df$slum)) # are there any NAs- NO/FALSE\n\n[1] FALSE\n\n\nwhich(is.na(x)) means which of the elements in object x are NA’s?\n\nwhich(is.na(df$IgG_concentration)) \n\n [1]  13  55  57  72 182 406 414 478 488 595\n\nwhich(is.na(df$slum)) \n\ninteger(0)",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#subset-function",
    "href": "modules/Module06-DataSubset.html#subset-function",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "subset() function",
    "text": "subset() function\nThe Base R subset() function is a slightly easier way to select variables and observations.\n\n?subset\n\nRegistered S3 method overwritten by 'printr':\n  method                from     \n  knit_print.data.frame rmarkdown\nSubsetting Vectors, Matrices and Data Frames\nDescription:\n Return subsets of vectors, matrices or data frames which meet\n conditions.\nUsage:\n subset(x, ...)\n \n ## Default S3 method:\n subset(x, subset, ...)\n \n ## S3 method for class 'matrix'\n subset(x, subset, select, drop = FALSE, ...)\n \n ## S3 method for class 'data.frame'\n subset(x, subset, select, drop = FALSE, ...)\n \nArguments:\n   x: object to be subsetted.\nsubset: logical expression indicating elements or rows to keep: missing values are taken as false.\nselect: expression, indicating columns to select from a data frame.\ndrop: passed on to '[' indexing operator.\n\n ...: further arguments to be passed to or from other methods.\nDetails:\n This is a generic function, with methods supplied for matrices,\n data frames and vectors (including lists).  Packages and users can\n add further methods.\n\n For ordinary vectors, the result is simply 'x[subset &\n !is.na(subset)]'.\n\n For data frames, the 'subset' argument works on the rows.  Note\n that 'subset' will be evaluated in the data frame, so columns can\n be referred to (by name) as variables in the expression (see the\n examples).\n\n The 'select' argument exists only for the methods for data frames\n and matrices.  It works by first replacing column names in the\n selection expression with the corresponding column numbers in the\n data frame and then using the resulting integer vector to index\n the columns.  This allows the use of the standard indexing\n conventions so that for example ranges of columns can be specified\n easily, or single columns can be dropped (see the examples).\n\n The 'drop' argument is passed on to the indexing method for\n matrices and data frames: note that the default for matrices is\n different from that for indexing.\n\n Factors may have empty levels after subsetting; unused levels are\n not automatically removed.  See 'droplevels' for a way to drop all\n unused levels from a data frame.\nValue:\n An object similar to 'x' contain just the selected elements (for a\n vector), rows and columns (for a matrix or data frame), and so on.\nWarning:\n This is a convenience function intended for use interactively.\n For programming it is better to use the standard subsetting\n functions like '[', and in particular the non-standard evaluation\n of argument 'subset' can have unanticipated consequences.\nAuthor(s):\n Peter Dalgaard and Brian Ripley\nSee Also:\n '[', 'transform' 'droplevels'\nExamples:\n subset(airquality, Temp &gt; 80, select = c(Ozone, Temp))\n subset(airquality, Day == 1, select = -Temp)\n subset(airquality, select = Ozone:Wind)\n \n with(airquality, subset(Ozone, Temp &gt; 80))\n \n ## sometimes requiring a logical 'subset' argument is a nuisance\n nm &lt;- rownames(state.x77)\n start_with_M &lt;- nm %in% grep(\"^M\", nm, value = TRUE)\n subset(state.x77, start_with_M, Illiteracy:Murder)\n # but in recent versions of R this can simply be\n subset(state.x77, grepl(\"^M\", nm), Illiteracy:Murder)",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#subsetting-use-the-subset-function",
    "href": "modules/Module06-DataSubset.html#subsetting-use-the-subset-function",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Subsetting use the subset() function",
    "text": "Subsetting use the subset() function\nHere are a few examples using the subset() function\n\ndf_lte10_v2 &lt;- subset(df, df$age&lt;=10, select=c(IgG_concentration, age))\ndf_lt5_f &lt;- subset(df, df$age&lt;=5 & gender==\"Female\", select=c(IgG_concentration, slum))",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#subset-function-vs-logical-operators",
    "href": "modules/Module06-DataSubset.html#subset-function-vs-logical-operators",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "subset() function vs logical operators",
    "text": "subset() function vs logical operators\nsubset() automatically removes NAs, which is a different behavior from doing logical operations on NAs.\n\nsummary(df_lte10$age) #created with indexing\n\n\n\n\nMin.\n1st Qu.\nMedian\nMean\n3rd Qu.\nMax.\nNA’s\n\n\n\n\n1\n3\n4\n4.8\n7\n10\n9\n\n\n\n\nsummary(df_lte10_v2$age) #created with the subset function\n\n\n\n\nMin.\n1st Qu.\nMedian\nMean\n3rd Qu.\nMax.\n\n\n\n\n1\n3\n4\n4.8\n7\n10\n\n\n\n\n\nWe can also see this by looking at the number or rows in each dataset.\n\nnrow(df_lte10)\n\n[1] 504\n\nnrow(df_lte10_v2)\n\n[1] 495",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#summary",
    "href": "modules/Module06-DataSubset.html#summary",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Summary",
    "text": "Summary\n\ncolnames(), str() and summary()functions from Base R are functions to assess the data type and some summary statistics\nThere are three basic indexing syntax: [, [[ and $\nIndexing can be used to extract part of an object (e.g., subset data) and to replace parts of an object (e.g., rename variables / columns)\nLogical operators can be evaluated on object(s) in order to return a binary response of TRUE/FALSE, and are useful for decision rules for indexing\nThere are 7 “types” of missing values, the most common being “NA”\nLogical operators meant to determine missing values are very helpful for data cleaning\nThe Base R subset() function is a slightly easier way to select variables and observations.",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module06-DataSubset.html#acknowledgements",
    "href": "modules/Module06-DataSubset.html#acknowledgements",
    "title": "Module 6: Get to Know Your Data and Subsetting",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese are the materials we looked through, modified, or extracted to complete this module’s lecture.\n\n“Introduction to R for Public Health Researchers” Johns Hopkins University\n“Indexing” CRAN Project\n“Logical operators” CRAN Project",
    "crumbs": [
      "Day 1",
      "Module 6: Get to Know Your Data and Subsetting"
    ]
  },
  {
    "objectID": "modules/Module12-Function.html#learning-objectives",
    "href": "modules/Module12-Function.html#learning-objectives",
    "title": "Module 12: Function",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter module 12, you should be able to:\n\nCreate your own function"
  },
  {
    "objectID": "modules/Module12-Function.html#writing-your-own-functions",
    "href": "modules/Module12-Function.html#writing-your-own-functions",
    "title": "Module 12: Function",
    "section": "Writing your own functions",
    "text": "Writing your own functions\nSo far, we have seen many functions (e.g., c(), class(), mean(), tranform(), aggregate() and many more\nwhy create your own function?\n\nto cut down on repetitive coding\nto organize code into manageable chunks\nto avoid running code unintentionally\nto use names that make sense to you"
  },
  {
    "objectID": "modules/Module12-Function.html#writing-your-own-functions-1",
    "href": "modules/Module12-Function.html#writing-your-own-functions-1",
    "title": "Module 12: Function",
    "section": "Writing your own functions",
    "text": "Writing your own functions\nHere we will write a function that multiplies some number (x) by 2:\n\ntimes_2 &lt;- function(x) x*2\n\nWhen you run the line of code above, you make it ready to use (no output yet!) Let’s test it!\n\ntimes_2(x=10)\n\n[1] 20"
  },
  {
    "objectID": "modules/Module12-Function.html#writing-your-own-functions-2",
    "href": "modules/Module12-Function.html#writing-your-own-functions-2",
    "title": "Module 12: Function",
    "section": "Writing your own functions:",
    "text": "Writing your own functions:\nAdding the curly brackets - { } - allows you to use functions spanning multiple lines:\n\ntimes_3 &lt;- function(x) {\n  x*3\n}\ntimes_3(x=10)\n\n[1] 30"
  },
  {
    "objectID": "modules/Module12-Function.html#writing-your-own-functions-return",
    "href": "modules/Module12-Function.html#writing-your-own-functions-return",
    "title": "Module 12: Function",
    "section": "Writing your own functions: return",
    "text": "Writing your own functions: return\nIf we want something specific for the function’s output, we use return(). Note, if you want to return more than one object, you need to put it into a list using the list() function.\n\ntimes_4 &lt;- function(x) {\n  output &lt;- x * 4\n  return(list(output, x))\n}\ntimes_4(x = 10)\n\n[[1]]\n[1] 40\n\n[[2]]\n[1] 10"
  },
  {
    "objectID": "modules/Module12-Function.html#function-syntax",
    "href": "modules/Module12-Function.html#function-syntax",
    "title": "Module 12: Function",
    "section": "Function Syntax",
    "text": "Function Syntax\nThis is a brief introduction. The syntax is:\nfunctionName = function(inputs) {\n&lt; function body &gt;\nreturn(list(value1, value2))\n}\nNote to create the function for use you need to\n\nCode/type the function\nExecute/run the lines of code\n\nOnly then will the function be available in the Environment pane and ready to use."
  },
  {
    "objectID": "modules/Module12-Function.html#writing-your-own-functions-multiple-arguments",
    "href": "modules/Module12-Function.html#writing-your-own-functions-multiple-arguments",
    "title": "Module 12: Function",
    "section": "Writing your own functions: multiple arguments",
    "text": "Writing your own functions: multiple arguments\nFunctions can take multiple arguments / inputs. Here the function has two arguments x and y\n\ntimes_2_plus_y &lt;- function(x, y) {\n  out &lt;- x * 2 + y\n  return(out)\n}\ntimes_2_plus_y(x = 10, y = 3)\n\n[1] 23"
  },
  {
    "objectID": "modules/Module12-Function.html#writing-your-own-functions-arugment-defaults",
    "href": "modules/Module12-Function.html#writing-your-own-functions-arugment-defaults",
    "title": "Module 12: Function",
    "section": "Writing your own functions: arugment defaults",
    "text": "Writing your own functions: arugment defaults\nFunctions can have default arguments. This lets us use the function without specifying the arguments\n\ntimes_2_plus_y &lt;- function(x = 10, y = 3) {\n  out &lt;- x * 2 + y\n  return(out)\n}\ntimes_2_plus_y()\n\n[1] 23\n\n\nWe got an answer b/c we put defaults into the function arguments."
  },
  {
    "objectID": "modules/Module12-Function.html#writing-a-simple-function",
    "href": "modules/Module12-Function.html#writing-a-simple-function",
    "title": "Module 12: Function",
    "section": "Writing a simple function",
    "text": "Writing a simple function\nLet’s write a function, sqdif, that:\n\ntakes two numbers x and y with default values of 2 and 3.\ntakes the difference\nsquares this difference\nthen returns the final value\n\nfunctionName = function(inputs) {\n&lt; function body &gt;\nreturn(list(value1, value2))\n}\n\nsqdif &lt;- function(x=2,y=3){\n     output &lt;- (x-y)^2\n     return(output)\n}\n\nsqdif()\n\n[1] 1\n\nsqdif(x=10,y=5)\n\n[1] 25\n\nsqdif(10,5)\n\n[1] 25"
  },
  {
    "objectID": "modules/Module12-Function.html#writing-your-own-functions-characters",
    "href": "modules/Module12-Function.html#writing-your-own-functions-characters",
    "title": "Module 12: Function",
    "section": "Writing your own functions: characters",
    "text": "Writing your own functions: characters\nFunctions can have any kind of data type input. For example, here is a function with characters:\n\nloud &lt;- function(word) {\n  output &lt;- rep(toupper(word), 5)\n  return(output)\n}\nloud(word = \"hooray!\")\n\n[1] \"HOORAY!\" \"HOORAY!\" \"HOORAY!\" \"HOORAY!\" \"HOORAY!\""
  },
  {
    "objectID": "modules/Module12-Function.html#using-functions-with-aggregate",
    "href": "modules/Module12-Function.html#using-functions-with-aggregate",
    "title": "Module 12: Function",
    "section": "Using functions with aggregate()",
    "text": "Using functions with aggregate()\nYou can apply functions easily to groups with aggregate(). As a reminder, we learned aggregate() yesterday in Module 9. We will take a quick look at the data.\n\nhead(df)\n\n  observation_id IgG_concentration age gender     slum age_group seropos\n1           5772        0.31768953   2 Female Non slum     young       0\n2           8095        3.43682311   4 Female Non slum     young       0\n3           9784        0.30000000   4   Male Non slum     young       0\n4           9338      143.23630140   4   Male Non slum     young       1\n5           6369        0.44765343   1   Male Non slum     young       0\n6           6885        0.02527076   4   Male Non slum     young       0\n\n\nThen, we used the following code to estimate the standard deviation of IgG_concentration for each unique combination of age_group and slum variables.\n\naggregate(\n    IgG_concentration ~ age_group + slum,\n    data = df,\n    FUN = sd # standard deviation\n)\n\n  age_group     slum IgG_concentration\n1     young    Mixed         174.89797\n2    middle    Mixed         162.08188\n3       old    Mixed         150.07063\n4     young Non slum         114.68422\n5    middle Non slum         177.62113\n6       old Non slum         141.22330\n7     young     Slum          61.85705\n8    middle     Slum         202.42018\n9       old     Slum          74.75217"
  },
  {
    "objectID": "modules/Module12-Function.html#using-functions-with-aggregate-1",
    "href": "modules/Module12-Function.html#using-functions-with-aggregate-1",
    "title": "Module 12: Function",
    "section": "Using functions with aggregate()",
    "text": "Using functions with aggregate()\nBut, lets say we want to do something different. Rather than taking the standard deviation and using a function that already exists (sd()), lets take the natural log of IgG_concentration and then get the mean. To do this, we can create our own function and this plug it into the FUN argument.\nStep 1 - code/type our own function\n\nlog_mean_function &lt;- function(x){\n    output &lt;- mean(log(x))\n    return(output)\n}\n\n\nStep 2 - execute our function (i.e., run the lines of code), and you would not be able to see it in you Environment pane.\n\n\nStep 3 - use the function by plugging it in the aggregate() function in order to complete our task\n\naggregate(\n    IgG_concentration ~ age_group + slum,\n    data = df,\n    FUN = log_mean_function\n)\n\n  age_group     slum IgG_concentration\n1     young    Mixed        0.50082888\n2    middle    Mixed        2.85916401\n3       old    Mixed        3.13971163\n4     young Non slum        0.14060433\n5    middle Non slum        2.30717077\n6       old Non slum        3.77021233\n7     young     Slum       -0.04611508\n8    middle     Slum        2.46490973\n9       old     Slum        3.52357989"
  },
  {
    "objectID": "modules/Module12-Function.html#example-from-module-12",
    "href": "modules/Module12-Function.html#example-from-module-12",
    "title": "Module 12: Function",
    "section": "Example from Module 12",
    "text": "Example from Module 12\nIn the last Module 12, we used loops to loop through every country in the dataset, and get the median, first and third quartiles, and range for each country and stored those summary statistics in a data frame.\n\nfor (i in 1:length(countries)) {\n    # Get the data for the current country only\n    country_data &lt;- subset(meas, country == countries[i])\n    \n    # Get the summary statistics for this country\n    country_cases &lt;- country_data$Cases\n    country_quart &lt;- quantile(\n        country_cases, na.rm = TRUE, probs = c(0.25, 0.5, 0.75)\n    )\n    country_range &lt;- range(country_cases, na.rm = TRUE)\n    \n    # Save the summary statistics into a data frame\n    country_summary &lt;- data.frame(\n        country = countries[[i]],\n        min = country_range[[1]],\n        Q1 = country_quart[[1]],\n        median = country_quart[[2]],\n        Q3 = country_quart[[3]],\n        max = country_range[[2]]\n    )\n    \n    # Save the results to our container\n    res[[i]] &lt;- country_summary\n}"
  },
  {
    "objectID": "modules/Module12-Function.html#function-instead-of-loop",
    "href": "modules/Module12-Function.html#function-instead-of-loop",
    "title": "Module 12: Function",
    "section": "Function instead of Loop",
    "text": "Function instead of Loop\nHere we are going to set up a function that takes our data frame and outputs the median, first and third quartiles, and range of measles cases for a specified country.\nStep 1 - code/type our own function. We specify two arguments, the first argument is our data frame and the second is one country’s iso3 code. Notice, I included common documentation for\n\nget_country_stats &lt;- function(df, iso3_code){\n    \n    country_data &lt;- subset(df, iso3c == iso3_code)\n    \n    # Get the summary statistics for this country\n    country_cases &lt;- country_data$Cases\n    country_quart &lt;- quantile(\n        country_cases, na.rm = TRUE, probs = c(0.25, 0.5, 0.75)\n    )\n    country_range &lt;- range(country_cases, na.rm = TRUE)\n    \n    country_name &lt;- unique(country_data$country)\n    \n    country_summary &lt;- data.frame(\n        country = country_name,\n        min = country_range[[1]],\n        Q1 = country_quart[[1]],\n        median = country_quart[[2]],\n        Q3 = country_quart[[3]],\n        max = country_range[[2]]\n    )\n    \n    return(country_summary)\n}\n\nStep 2 - execute our function (i.e., run the lines of code), and you would not be able to see it in you Environment pane.\n\nStep 3 - use the function by pulling out stats for India and Pakistan\n\nget_country_stats(df=meas, iso3_code=\"IND\")\n\n  country  min    Q1 median      Q3    max\n1   India 3305 30813  47072 74828.5 252940\n\nget_country_stats(df=meas, iso3_code=\"PAK\")\n\n   country min   Q1 median      Q3   max\n1 Pakistan 386 2065   3903 13860.5 55543"
  },
  {
    "objectID": "modules/Module12-Function.html#summary",
    "href": "modules/Module12-Function.html#summary",
    "title": "Module 12: Function",
    "section": "Summary",
    "text": "Summary\n\nSimple functions take the form:\n\nfunctionName = function(arguments) {\n    &lt; function body &gt;\n    return(list(outputs))\n}\n\nWe can specify arguments defaults when you create the function"
  },
  {
    "objectID": "modules/Module12-Function.html#mini-exercise",
    "href": "modules/Module12-Function.html#mini-exercise",
    "title": "Module 12: Function",
    "section": "Mini Exercise",
    "text": "Mini Exercise\nCreate your own function that saves a line plot of a time series of measles cases for a specified country.\nStep 1. Determine your arguments, which are the same as the last example\nStep 2. Begin your function by subsetting the data to include only the country specified in the arguments (i.e, country_data), this is the same as the first line of code in the last example.\nStep 3. Return to Module 10 to remember how to use the plot() function. Hint you will need to specify the argument `type=“l” to make it a line plot.\nStep 4. Return to your function and add code to create a new plot using the country_data object. Note you will need to use the png() function before the plot() function and end it with dev.off() in order to save the file.\nStep 5. Use the function to generate a plot for India and Pakistan"
  }
]