---
title: "Module 9: Data Analysis"
format: 
  revealjs:
    scrollable: true
    smaller: true
    toc: false
---

## Learning Objectives

After module 9, you should be able to...

-	Descriptively assess association between two variables
-	Compute basic statistics 
-	Fit a generalized linear model

## Import data for this module

Let's read in our data (again) and take a quick look.

```{r echo=TRUE}
df <- read.csv(file = "data/serodata.csv") #relative path
head(x=df, n=3)
```

## Prep data

Create `age_group` three level factor variable
```{r echo=TRUE}
df$age_group <- ifelse(df$age <= 5, "young", 
                       ifelse(df$age<=10 & df$age>5, "middle", "old"))
df$age_group <- factor(df$age_group, levels=c("young", "middle", "old"))
```

Create `seropos` binary variable representing seropositivity if antibody concentrations are >10 IU/mL.
```{r echo=TRUE}
df$seropos <- ifelse(df$IgG_concentration<10, 0, 1)
```


## 2 variable contingency tables

We use `table()` prior to look at one variable, now we can generate frequency tables for 2 plus variables.  To get cell percentages, the `prop.table()` is useful.  

```{r echo=TRUE, eval=FALSE}
?prop.table
```

```{r echo=TRUE}
library(printr)
?prop.table
```

## 2 variable contingency tables

Let's practice
```{r echo=TRUE}
freq <- table(df$age_group, df$seropos)
freq
```

Now, lets move to percentages
```{r echo=TRUE}
prop.cell.percentages <- prop.table(freq)
prop.cell.percentages
prop.column.percentages <- prop.table(freq, margin=2)
prop.column.percentages
```


## Chi-Square test

The `chisq.test()` function test of independence of factor variables from `stats` package.

```{r echo=TRUE, eval=FALSE}
?chisq.test
```

```{r, echo = FALSE, results = "asis"}
library(printr)
?chisq.test
```


## Chi-Square test

```{r}
chisq.test(freq)
```

We reject the null hypothesis that the proportion of seropositive individuals in the young, middle, and old age groups are the same.


## Correlation

First, we compute correlation by providing two vectors.

Like other functions, if there are `NA`s, you get `NA` as the result. But if you specify use only the complete observations, then it will give you correlation using the non-missing data.

```{r echo=TRUE}
cor(df$age, df$IgG_concentration, method="pearson")
cor(df$age, df$IgG_concentration, method="pearson", use = "complete.obs") #IF have missing data
```

Small positive correlation between IgG concentration and age.

## Correlation confidence interval

The function `cor.test()` also gives you the confidence interval of the correlation statistic. Note, it uses complete observations by default. 

```{r echo=TRUE}
cor.test(df$age, df$IgG_concentration, method="pearson")
```


## T-test

The commonly used are:

-   **one-sample t-test** -- used to test mean of a variable in one group (to the null hypothesis mean)
-   **two-sample t-test** -- used to test difference in means of a variable between two groups (null hypothesis - the group means are the *same*)

## T-test

We can use the `t.test()` function from the `stats` package.


```{r echo=TRUE, eval=FALSE}
?t.test
```

```{r, echo = FALSE, results = "asis"}
library(printr)
?t.test
```

## Running two-sample t-test

The **base R** - `t.test()` function from the `stats` package. It tests test difference in means of a variable between two groups. By default:

-   tests whether difference in means of a variable is equal to 0 (default `mu=0`)
-   uses "two sided" alternative (`alternative = "two.sided"`)
-   returns result assuming confidence level 0.95 (`conf.level = 0.95`)
-   assumes data are not paired (`paired = FALSE`)
-   assumes true variance in the two groups is not equal (`var.equal = FALSE`)

## Running two-sample t-test

```{r}
IgG_young <- df$IgG_concentration[df$age_group=="young"]
IgG_old <- df$IgG_concentration[df$age_group=="old"]

t.test(IgG_young, IgG_old)
```

The mean IgG concenration of young and old is 45.05 and 129.35 IU/mL, respectively. We reject null hypothesis that the difference in the mean IgG concentration of young and old is 0 IU/mL.

## Linear regression fit in R

To fit regression models in R, we use the function `glm()` (Generalized Linear Model).


```{r echo=TRUE, eval=FALSE}
?glm
```

```{r, echo = FALSE, results = "asis"}
library(printr)
?glm
```

## Linear regression fit in R

We tend to focus on three arguments:

- `formula` -- model formula written using names of columns in our data
- `data` -- our data frame
- `family` -- error distribution and link function

```{r echo=TRUE}
fit1 <- glm(IgG_concentration~age+gender+slum, data=df, family=gaussian())
fit2 <- glm(seropos~age_group+gender+slum, data=df, family = binomial(link = "logit"))
```

## `summary.glm()`

The `summary()` function when applied to a fit object based on a glm is technically the `summary.glm()` function and produces details of the model fit. Note on object oriented code.

```{r, out.width = "200%", echo = FALSE}
knitr::include_graphics("images/rstudio_script.png")
```

```{r, echo = FALSE, results = "asis"}
library(printr)
?summary.glm
```


## Linear regression fit in R

Lets look at the output...

```{r echo=TRUE}
summary(fit1)
summary(fit2)
```



## Summary

-	Use `cor()` or `cor.test()` to calculate correlation between two numeric vectors.
- `t.test()` tests the mean compared to null or difference in means between two groups
-		... xxamy more

## Acknowledgements

These are the materials we looked through, modified, or extracted to complete this module's lecture.

-   ["Introduction to R for Public Health Researchers" Johns Hopkins University](https://jhudatascience.org/intro_to_r/)
